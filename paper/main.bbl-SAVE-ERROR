% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/apasortcite//global/global}
    \entry{abdel-hamid_applying_2012}{article}{}
      \name{author}{4}{}{%
        {{hash=9288aa6499433fb7e731959bc9ee8a76}{%
           family={Abdel-Hamid},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Ossama},
           giveni={O\bibinitperiod}}}%
        {{hash=0d87a656f9bdc99e921c45f73da515b8}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdel-rahman},
           giveni={A\bibinithyphendelim r\bibinitperiod}}}%
        {{hash=bb419d444235494b58481c9171c8e164}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Hui},
           giveni={H\bibinitperiod}}}%
        {{hash=aa1c6a2b41f82ec174c886dc4fdd967c}{%
           family={Penn},
           familyi={P\bibinitperiod},
           given={Gerald},
           giveni={G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Kyoto, Japan}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{412cf9e3d443eb6a2495eccae53adb28}
      \strng{fullhash}{5645f28fee3e09f76f17360082057ced}
      \strng{bibnamehash}{5645f28fee3e09f76f17360082057ced}
      \strng{authorbibnamehash}{5645f28fee3e09f76f17360082057ced}
      \strng{authornamehash}{412cf9e3d443eb6a2495eccae53adb28}
      \strng{authorfullhash}{5645f28fee3e09f76f17360082057ced}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eventtitle}{{ICASSP} 2012 - 2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing}
      \field{isbn}{978-1-4673-0046-9 978-1-4673-0045-2 978-1-4673-0044-5}
      \field{journaltitle}{2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{month}{3}
      \field{title}{Applying Convolutional Neural Networks concepts to hybrid {NN}-{HMM} model for speech recognition}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4277\bibrangedash 4280}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICASSP.2012.6288864
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/pawel/Zotero/storage/Z5P9C3WR/Abdel-Hamid et al. - 2012 - Applying Convolutional Neural Networks concepts to.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6288864/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6288864/
      \endverb
    \endentry
    \entry{algazi_cipic_2001}{article}{}
      \name{author}{4}{}{%
        {{hash=06749bbf7d283e05c10d1841491e3449}{%
           family={Algazi},
           familyi={A\bibinitperiod},
           given={V.R.},
           giveni={V\bibinitperiod}}}%
        {{hash=b487da43284ea0ffefe3481b023777b0}{%
           family={Duda},
           familyi={D\bibinitperiod},
           given={R.O.},
           giveni={R\bibinitperiod}}}%
        {{hash=6e8237ec5d708e2bc9d23660e4c4d0d2}{%
           family={Thompson},
           familyi={T\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod}}}%
        {{hash=1952cf9096ab291f3989ac1584600c50}{%
           family={Avendano},
           familyi={A\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{8f09378186bc4879fc1bce3e3cc4dbfd}
      \strng{fullhash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{bibnamehash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{authorbibnamehash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{authornamehash}{8f09378186bc4879fc1bce3e3cc4dbfd}
      \strng{authorfullhash}{6afac7a32e3369071c9397ce0f3fa259}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes a public-domain database of high-spatial-resolution head-related transfer functions measured at the {UC} Davis {CIPIC} Interface Laboratory and the methods used to collect the data.. Release 1.0 (see http://interface.cipic.ucdavis.edu) includes head-related impulse responses for 45 subjects at 25 different azimuths and 50 different elevations (1250 directions) at approximately 5/spl deg/ angular increments. In addition, the database contains anthropometric measurements for each subject. Statistics of anthropometric parameters and correlations between anthropometry and some temporal and spectral features of the {HRTFs} are reported.}
      \field{eventtitle}{Proceedings of the 2001 {IEEE} Workshop on the Applications of Signal Processing to Audio and Acoustics (Cat. No.01TH8575)}
      \field{journaltitle}{Proceedings of the 2001 {IEEE} Workshop on the Applications of Signal Processing to Audio and Acoustics (Cat. No.01TH8575)}
      \field{month}{10}
      \field{title}{The {CIPIC} {HRTF} database}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2001}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{99\bibrangedash 102}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ASPAA.2001.969552
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/8YD4T6PV/969552.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/969552
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/969552
      \endverb
      \keyw{Acoustic scattering,Anthropometry,Azimuth,Ear,Laboratories,Microphones,Position measurement,Spatial databases,Statistics,Transfer functions}
    \endentry
    \entry{andreopoulou_inter-laboratory_2015}{article}{}
      \name{author}{3}{}{%
        {{hash=55dc7e67d0b42710d35285483e206c74}{%
           family={Andreopoulou},
           familyi={A\bibinitperiod},
           given={Areti},
           giveni={A\bibinitperiod}}}%
        {{hash=dfa51aad6297c09b374cdb5db24c39cd}{%
           family={Begault},
           familyi={B\bibinitperiod},
           given={Durand\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=e6171c131f25cca08030c538161a1e89}{%
           family={Katz},
           familyi={K\bibinitperiod},
           given={Brian\bibnamedelimb F.\bibnamedelimi G.},
           giveni={B\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{4339c7aeafbe2d556b29128f9f5791cf}
      \strng{fullhash}{bec448d0391c56f2442780d28de1ed80}
      \strng{bibnamehash}{bec448d0391c56f2442780d28de1ed80}
      \strng{authorbibnamehash}{bec448d0391c56f2442780d28de1ed80}
      \strng{authornamehash}{4339c7aeafbe2d556b29128f9f5791cf}
      \strng{authorfullhash}{bec448d0391c56f2442780d28de1ed80}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Head-Related Transfer Function ({HRTF}) measurements underlie the signal processing used in binaural auditory displays, but measurement techniques, equipment, and post-processing vary substantially between laboratories. This variation can result in significant differences in measured spectral and timing data taken from the same subject for the same sound source locations. An ongoing project for comparing databases from laboratories across the world (colloquially titled “Club Fritz”) employs a single dummy head microphone for measurements (Neumann {KU}-100) at various sites. The current study examines magnitude and timing differences between left and right ear data from 12 different {HRTF} sets taken from 10 different laboratories. Results revealed spectral magnitude variations up to 12.5 {dB} for frequency bands below 6 {kHz} and up to 23 {dB} above that, as well as large spectral left/right asymmetries (dcorr ≤ 0.4) for high-frequency content. Further subjective studies are necessary to determine the perceptual relevance of these findings. Nevertheless, the observed {ITD} variations of up to 235 μsec are alarming as they often exceeded reported {JND} values. Such findings highlight the potential impact of physical spaces, measurement routines, and equipment types on the collected {HRTF} data.}
      \field{issn}{1941-0484}
      \field{journaltitle}{{IEEE} Journal of Selected Topics in Signal Processing}
      \field{month}{8}
      \field{note}{Conference Name: {IEEE} Journal of Selected Topics in Signal Processing}
      \field{number}{5}
      \field{title}{Inter-Laboratory Round Robin {HRTF} Measurement Comparison}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{9}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{895\bibrangedash 906}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/JSTSP.2015.2400417
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/S29TAY72/7031925.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7031925
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7031925
      \endverb
      \keyw{Current measurement,Databases,Ear,{HRTF}/{HRIR},{ITD} variations,Laboratories,measurement,Microphones,Position measurement,repeatability,Spatial resolution,spatial symmetry,spectral variations}
    \endentry
    \entry{antoniuk_software_2024}{online}{}
      \name{author}{1}{}{%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{fullhash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{bibnamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authorbibnamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authornamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authorfullhash}{6fd073df32a3491aff57beee7b376a5b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Software Repository: Estimating Ensemble Location and Width in Binaural Recordings of Music with Convolutional Neural Networks}
      \field{titleaddon}{{GitHub}}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://github.com/pawel-antoniuk/ensemble-width-cnn
      \endverb
      \verb{url}
      \verb https://github.com/pawel-antoniuk/ensemble-width-cnn
      \endverb
    \endentry
    \entry{antoniuk_blind_2023}{article}{}
      \name{author}{2}{}{%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{fullhash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{bibnamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authorbibnamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authornamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authorfullhash}{26dc0a365ecebb9e459841e8ed96c709}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Audio Engineering Society Conference: {AES} 2023 International Conference on Spatial and Immersive Audio}
      \field{month}{8}
      \field{title}{Blind estimation of ensemble width in binaural music recordings using ‘spatiograms’ under simulated anechoic conditions}
      \field{year}{2023}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=22203
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=22203
      \endverb
    \endentry
    \entry{armstrong_perceptual_2018}{article}{}
      \name{author}{4}{}{%
        {{hash=449b95deb7c92d6bae29642ceb26dc5e}{%
           family={Armstrong},
           familyi={A\bibinitperiod},
           given={Cal},
           giveni={C\bibinitperiod}}}%
        {{hash=cb50f92abb883437070abbef360527c9}{%
           family={Thresh},
           familyi={T\bibinitperiod},
           given={Lewis},
           giveni={L\bibinitperiod}}}%
        {{hash=87b7036648a4c8fbe903ee80e70271eb}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Damian},
           giveni={D\bibinitperiod}}}%
        {{hash=dab5abd81d8bb1f9db64d94c6bc03919}{%
           family={Kearney},
           familyi={K\bibinitperiod},
           given={Gavin},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{c61cace23ee2e710a415978552a6ad52}
      \strng{fullhash}{d5ea80979379f293fe29841fd9f24265}
      \strng{bibnamehash}{d5ea80979379f293fe29841fd9f24265}
      \strng{authorbibnamehash}{d5ea80979379f293fe29841fd9f24265}
      \strng{authornamehash}{c61cace23ee2e710a415978552a6ad52}
      \strng{authorfullhash}{d5ea80979379f293fe29841fd9f24265}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{As binaural audio continues to permeate immersive technologies, it is vital to develop a detailed understanding of the perceptual relevance of {HRTFs}. Previous research has explored the benefit of individual {HRTFs} with respect to localisation. However, localisation is only one metric with which it is possible to rate spatial audio. This paper evaluates the perceived timbral and spatial characteristics of both individual and non-individual {HRTFs} and compares the results to overall preference. To that end, the measurement and evaluation of a high-resolution multi-environment binaural Impulse Response database is presented for 20 subjects, including the {KU}100 and {KEMAR} binaural mannequins. Post-processing techniques, including low frequency compensation and diffuse field equalisation are discussed in relation to the 8802 unique {HRTFs} measured for each mannequin and 2818/2114 {HRTFs} measured for each human. Listening test results indicate that particular {HRTF} sets are preferred more generally by subjects over their own individual measurements.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{11}
      \field{note}{Number: 11 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{11}
      \field{shorttitle}{A Perceptual Evaluation of Individual and Non-Individual {HRTFs}}
      \field{title}{A Perceptual Evaluation of Individual and Non-Individual {HRTFs}: A Case Study of the {SADIE} {II} Database}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{8}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2029}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app8112029
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/JUFP5BZ5/Armstrong et al. - 2018 - A Perceptual Evaluation of Individual and Non-Indi.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/8/11/2029
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/8/11/2029
      \endverb
      \keyw{binaural,database,evaluation,{HRTF},measurement,perception,spatial audio,timbre}
    \endentry
    \entry{arthi_spatiogram_2021}{article}{}
      \name{author}{2}{}{%
        {{hash=822d8daa7259d9322d2f3b089f249eee}{%
           family={Arthi},
           familyi={A\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=fa990077dcba214931346c504a586a96}{%
           family={Sreenivas},
           familyi={S\bibinitperiod},
           given={Thippur\bibnamedelima V.},
           giveni={T\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{fullhash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{bibnamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authorbibnamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authornamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authorfullhash}{46ad25080ab1a6754b00ff3fe619eb57}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Spatiogram: A phase based directional angular measure and perceptual weighting for ensemble source width}
      \field{volume}{abs/2112.07216}
      \field{year}{2021}
      \field{dateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/IRU2Y2LJ/S and T V - 2021 - Spatiogram A phase based directional angular meas.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:245131510
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:245131510
      \endverb
    \endentry
    \entry{benaroya_binaural_2018}{article}{}
      \name{author}{6}{}{%
        {{hash=3a604688c1793716f5fe6c3fbd26773d}{%
           family={Benaroya},
           familyi={B\bibinitperiod},
           given={Elie\bibnamedelima Laurent},
           giveni={E\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=65528959cd45c0dd00fa184216842d23}{%
           family={Obin},
           familyi={O\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=0d687f9ad924001bf48b16f37f767d76}{%
           family={Liuni},
           familyi={L\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
        {{hash=88a4a4281b192bf9abbdd5a5d27ca33b}{%
           family={Roebel},
           familyi={R\bibinitperiod},
           given={Axel},
           giveni={A\bibinitperiod}}}%
        {{hash=1da39a02a80a901382d4f7019d24107a}{%
           family={Raumel},
           familyi={R\bibinitperiod},
           given={Wilson},
           giveni={W\bibinitperiod}}}%
        {{hash=dbb8a822f42d7807b9fb1d66c5be15ab}{%
           family={Argentieri},
           familyi={A\bibinitperiod},
           given={Sylvain},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{c7f483dd5309c8d8b0e969b04de1b6cd}
      \strng{fullhash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{bibnamehash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{authorbibnamehash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{authornamehash}{c7f483dd5309c8d8b0e969b04de1b6cd}
      \strng{authorfullhash}{434bbd30f8bcba4350feac4726358cf8}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents non-negative factorization of audio signals for the binaural localization of multiple sound sources within realistic and unknown sound environments. Non-negative tensor factorization (NTF) provides a sparse representation of multichannel audio signals in time, frequency, and space that can be exploited in computational audio scene analysis and robot audition for the separation and localization of sound sources. In the proposed formulation, each sound source is represented by means of spectral dictionaries, temporal activation, and its distribution within each channel (here, left and right ears). This distribution, being dependent on the frequency, can be interpreted as an explicit estimation of the Head-Related Transfer Function (HRTF) of a binaural head which can then be converted into the estimated sound source position. Moreover, the semisupervised formulation of the non-negative factorization allows us to integrate prior knowledge about some sound sources of interest whose dictionaries can be learned in advance, whereas the remaining sources are considered as background sound, which remains unknown and is estimated on the fly. The proposed NTF-based sound source localization is applied here to binaural sound source localization of multiple speakers within realistic sound environments.}
      \field{issn}{2329-9304}
      \field{journaltitle}{IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{month}{6}
      \field{note}{Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{number}{6}
      \field{title}{Binaural {Localization} of {Multiple} {Sound} {Sources} by {Non}-{Negative} {Tensor} {Factorization}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{1072\bibrangedash 1082}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TASLP.2018.2806745
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/AGTH4VGH/8294267.html:text/html;Submitted Version:/Users/pawel/Zotero/storage/TERC7QZT/Benaroya et al. - 2018 - Binaural Localization of Multiple Sound Sources by.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8294267
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8294267
      \endverb
      \keyw{Binaural localization,computational audio scene analysis,Ear,Image analysis,non-negative tensor factorization,robot audition,Robot kinematics,Speech,Speech processing,Tensile stress}
    \endentry
    \entry{blauert_spatial_1996}{book}{}
      \name{author}{1}{}{%
        {{hash=72eeeae6cc10aacbef1120ffab7b6f6e}{%
           family={Blauert},
           familyi={B\bibinitperiod},
           given={Jens},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {The MIT Press}%
      }
      \strng{namehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{fullhash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{bibnamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authorbibnamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authornamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authorfullhash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The field of spatial hearing has exploded in the decade or so since Jens Blauert's classic work on acoustics was first published in English. This revised edition adds a new chapter that describes developments in such areas as auditory virtual reality (an important field of application that is based mainly on the physics of spatial hearing), binaural technology (modeling speech enhancement by binaural hearing), and spatial sound-field mapping. The chapter also includes recent research on the precedence effect that provides clear experimental evidence that cognition plays a significant role in spatial hearing. The remaining four chapters in this comprehensive reference cover auditory research procedures and psychometric methods, spatial hearing with one sound source, spatial hearing with multiple sound sources and in enclosed spaces, and progress and trends from 1972 (the first German edition) to 1983 (the first English edition)—work that includes research on the physics of the external ear, and the application of signal processing theory to modeling the spatial hearing process. There is an extensive bibliography of more than 900 items.}
      \field{isbn}{978-0-262-26868-4}
      \field{month}{10}
      \field{title}{Spatial {Hearing}: {The} {Psychophysics} of {Human} {Sound} {Localization}}
      \field{year}{1996}
      \verb{doi}
      \verb 10.7551/mitpress/6391.001.0001
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.7551/mitpress/6391.001.0001
      \endverb
      \verb{url}
      \verb https://doi.org/10.7551/mitpress/6391.001.0001
      \endverb
    \endentry
    \entry{branke_evolutionary_1995}{article}{}
      \name{author}{1}{}{%
        {{hash=d9e8de881fe2db78bf10c2e152430ab7}{%
           family={Branke},
           familyi={B\bibinitperiod},
           given={Jürgen},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{fullhash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{bibnamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authorbibnamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authornamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authorfullhash}{d9e8de881fe2db78bf10c2e152430ab7}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Neural networks and genetic algorithms are two relatively young research areas that were subject to a steadily growing interest during the past years. Both models are inspired by nature, but whereas neural networks are concerned with learning of an individual (phenotypic learning), evolutionary algorithms deal with a population’s adaptation to a changing environment (genotypic learning). This paper focuses on the intersection of neural networks and evolutionary computation, namely on how evolutionary algorithms can be used to assist neural network design and training. The purpose of the paper is to set forth the general considerations that have to be made when designing an algorithm in this area and to give an overview on how researchers addressed these issues in the past.}
      \field{journaltitle}{Proceedings of the First Nordic Workshop on Genetic Algorithms and its Application}
      \field{title}{Evolutionary Algorithms for Neural Network Design and Training}
      \field{urlday}{23}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{1995}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{145\bibrangedash 163}
      \range{pages}{19}
      \verb{file}
      \verb Branke - 1995 - Evolutionary Algorithms for Neural Network Design .pdf:/home/pawel/Zotero/storage/H4Y8MXEH/Branke - 1995 - Evolutionary Algorithms for Neural Network Design .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.semanticscholar.org/paper/Evolutionary-Algorithms-for-Neural-Network-Design-Branke/af9612b51f0bcab7013b239c333d17cf398d20b8
      \endverb
      \verb{url}
      \verb https://www.semanticscholar.org/paper/Evolutionary-Algorithms-for-Neural-Network-Design-Branke/af9612b51f0bcab7013b239c333d17cf398d20b8
      \endverb
    \endentry
    \entry{braren_high-resolution_2020}{article}{}
      \name{author}{2}{}{%
        {{hash=1a7e6a0f3b97288c71c6a736c42124a7}{%
           family={Braren},
           familyi={B\bibinitperiod},
           given={Hark\bibnamedelima Simon},
           giveni={H\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=8c38bbd25743680ce3100d8b7ad619a0}{%
           family={Fels},
           familyi={F\bibinitperiod},
           given={Janina},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{fullhash}{7cee2f7474d4479b291b7271a5266846}
      \strng{bibnamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authorbibnamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authornamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authorfullhash}{7cee2f7474d4479b291b7271a5266846}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{A High-Resolution Individual 3D Adult Head and Torso Model for {HRTF} Simulation and Validation: {HRTF} Measurement}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Braren and Fels - 2020 - A High-Resolution Individual 3D Adult Head and Tor.pdf:/home/pawel/Zotero/storage/KKR3ZBZ8/Braren and Fels - 2020 - A High-Resolution Individual 3D Adult Head and Tor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:234998299
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:234998299
      \endverb
    \endentry
    \entry{bregman_auditory_1990}{inbook}{}
      \name{author}{1}{}{%
        {{hash=51930ef3803ace57c0abead7f63071c3}{%
           family={Bregman},
           familyi={B\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{fullhash}{51930ef3803ace57c0abead7f63071c3}
      \strng{bibnamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authorbibnamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authornamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authorfullhash}{51930ef3803ace57c0abead7f63071c3}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Scitation is the online home of leading journals and conference proceedings from AIP Publishing and AIP Member Societies}
      \field{booktitle}{Journal of {The} {Acoustical} {Society} of {America} - {J} {ACOUST} {SOC} {AMER}}
      \field{month}{1}
      \field{note}{Journal Abbreviation: Journal of The Acoustical Society of America - J ACOUST SOC AMER}
      \field{shorttitle}{Auditory {Scene} {Analysis}}
      \field{title}{Auditory {Scene} {Analysis}: {The} {Perceptual} {Organization} of {Sound}}
      \field{volume}{95}
      \field{year}{1990}
      \verb{doi}
      \verb 10.1121/1.408434
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SR53ZIS7/Bregman - 1990 - Auditory Scene Analysis The Perceptual Organizati.pdf:application/pdf
      \endverb
    \endentry
    \entry{brinkmann_high_2017}{article}{}
      \name{author}{7}{}{%
        {{hash=ddaa65ee961b81796f483236881c13e8}{%
           family={Brinkmann},
           familyi={B\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=d0754317d63a192dfdbc01acd3559f86}{%
           family={Lindau},
           familyi={L\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=efead5602621f126b0f182f07582af77}{%
           family={Weinzerl},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=190a306c874262a3e25d2b92b2154bb7}{%
           family={Van\bibnamedelimb De\bibnamedelima Par},
           familyi={V\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=fc40aa5bf87724bfe7682ef1214c921a}{%
           family={Müller-Trapet},
           familyi={M\bibinithyphendelim T\bibinitperiod},
           given={Markus},
           giveni={M\bibinitperiod}}}%
        {{hash=9bff6d4192fd48fd0b4c02a2b7f8edb9}{%
           family={Opdam},
           familyi={O\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod}}}%
        {{hash=d272335dbc7a4ad64546aa36b3c32fe9}{%
           family={Vorländer},
           familyi={V\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{fullhash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{bibnamehash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{authorbibnamehash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{authornamehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{authorfullhash}{de5dead1c533929de6de8ce13e8b5a35}
      \field{extraname}{1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{30}
      \field{issn}{15494950}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{J. Audio Eng. Soc.}
      \field{title}{A High Resolution and Full-Spherical Head-Related Transfer Function Database for Different Head-Above-Torso Orientations}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{65}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{841\bibrangedash 848}
      \range{pages}{8}
      \verb{doi}
      \verb 10.17743/jaes.2017.0033
      \endverb
      \verb{file}
      \verb Brinkmann et al. - 2017 - A High Resolution and Full-Spherical Head-Related .pdf:/Users/pawel/Zotero/storage/GZFNE9CA/Brinkmann et al. - 2017 - A High Resolution and Full-Spherical Head-Related .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=19357
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=19357
      \endverb
    \endentry
    \entry{brinkmann_cross-evaluated_2019}{article}{}
      \name{author}{6}{}{%
        {{hash=ddaa65ee961b81796f483236881c13e8}{%
           family={Brinkmann},
           familyi={B\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=2fa348a6d87989d08218a99ed62290a4}{%
           family={Dinakaran},
           familyi={D\bibinitperiod},
           given={Manoj},
           giveni={M\bibinitperiod}}}%
        {{hash=072760f8145043507a447376c63fc5f6}{%
           family={Pelzer},
           familyi={P\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=797477a22ebb0c22bad97baeb0d02e6a}{%
           family={Grosche},
           familyi={G\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=f1a97300823078cc309d88918a011b60}{%
           family={Voss},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=7f6677631454c7c9baa854e96f9a6f6f}{%
           family={Weinzierl},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{fullhash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{bibnamehash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{authorbibnamehash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{authornamehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{authorfullhash}{68e288c0bed28cadd3b4d83316b7b32d}
      \field{extraname}{2}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{21}
      \field{issn}{15494950}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{J. Audio Eng. Soc.}
      \field{title}{A Cross-Evaluated Database of Measured and Simulated {HRTFs} Including 3D Head Meshes, Anthropometric Features, and Headphone Impulse Responses}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{67}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{705\bibrangedash 718}
      \range{pages}{14}
      \verb{doi}
      \verb 10.17743/jaes.2019.0024
      \endverb
      \verb{file}
      \verb Brinkmann et al. - 2019 - A Cross-Evaluated Database of Measured and Simulat.pdf:/Users/pawel/Zotero/storage/8RIN3L7T/Brinkmann et al. - 2019 - A Cross-Evaluated Database of Measured and Simulat.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=20546
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=20546
      \endverb
    \endentry
    \entry{cherry_experiments_1953}{article}{}
      \name{author}{1}{}{%
        {{hash=c293bf3e2995baf349c18c7ac49b63b3}{%
           family={Cherry},
           familyi={C\bibinitperiod},
           given={E.\bibnamedelimi Colin},
           giveni={E\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{fullhash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{bibnamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authorbibnamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authornamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authorfullhash}{c293bf3e2995baf349c18c7ac49b63b3}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Experiments are described which examine the separation of two speech signals by human operators. 3 procedures were employed: presentation of both messages to both ears; presentation of one message to one ear with simultaneous presentation of the second message to the other ear; and presentation of a single message alternately to the two ears. Of particular current interest is the second procedure. Here, a listener is able to separate the messages exceedingly well despite the fact that he can only identify the general statistical properties of the rejected message. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)}
      \field{issn}{0001-4966(Print)}
      \field{journaltitle}{Journal of the Acoustical Society of America}
      \field{note}{Place: {US} Publisher: Acoustical Society of American}
      \field{title}{Some experiments on the recognition of speech, with one and with two ears.}
      \field{volume}{25}
      \field{year}{1953}
      \field{dateera}{ce}
      \field{pages}{975\bibrangedash 979}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1121/1.1907229
      \endverb
    \endentry
    \entry{chollet_keras_2015}{online}{}
      \true{moreauthor}
      \true{morelabelname}
      \name{author}{1}{}{%
        {{hash=5836fc1fa037e340c8b5591da3207608}{%
           family={Chollet},
           familyi={C\bibinitperiod},
           given={Francois},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{94f467118488a03ed3386af37a329f60}
      \strng{fullhash}{94f467118488a03ed3386af37a329f60}
      \strng{bibnamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authorbibnamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authornamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authorfullhash}{94f467118488a03ed3386af37a329f60}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Keras}
      \field{titleaddon}{{GitHub}}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://github.com/fchollet/keras
      \endverb
      \verb{url}
      \verb https://github.com/fchollet/keras
      \endverb
    \endentry
    \entry{chung_sound_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=d2858cf75bbc599eb93e546fdba33a88}{%
           family={Chung},
           familyi={C\bibinitperiod},
           given={Ming-An},
           giveni={M\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=32595a352be28d8357df4725616e62c6}{%
           family={Chou},
           familyi={C\bibinitperiod},
           given={Hung-Chi},
           giveni={H\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=77470cfec474923e449b355144ae5dd8}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Chia-Wei},
           giveni={C\bibinithyphendelim W\bibinitperiod}}}%
      }
      \strng{namehash}{029fc3f27f14ea1c30a940310b130bd4}
      \strng{fullhash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{bibnamehash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{authorbibnamehash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{authornamehash}{029fc3f27f14ea1c30a940310b130bd4}
      \strng{authorfullhash}{7389c3168ed5a652eb147d04e2dc5c65}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound signals have been widely applied in various fields. One of the popular applications is sound localization, where the location and direction of a sound source are determined by analyzing the sound signal. In this study, two microphone linear arrays were used to locate the sound source in an indoor environment. The {TDOA} is also designed to deal with the problem of delay in the reception of sound signals from two microphone arrays by using the generalized cross-correlation algorithm to calculate the {TDOA}. The proposed microphone array system with the algorithm can successfully estimate the sound source’s location. The test was performed in a standardized chamber. This experiment used two microphone arrays, each with two microphones. The experimental results prove that the proposed method can detect the sound source and obtain good performance with a position error of about 2.0{\textasciitilde}2.3 cm and angle error of about 0.74 degrees. Therefore, the experimental results demonstrate the feasibility of the system.}
      \field{issn}{2079-9292}
      \field{journaltitle}{Electronics}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 6 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{6}
      \field{title}{Sound Localization Based on Acoustic Source Using Multiple Microphone Array in an Indoor Environment}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{11}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{890}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/electronics11060890
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/PX2QWICQ/Chung et al. - 2022 - Sound Localization Based on Acoustic Source Using .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2079-9292/11/6/890
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2079-9292/11/6/890
      \endverb
      \keyw{generalized cross-correlation algorithm,indoor localization,microphone array,sound localization,time difference of arrival}
    \endentry
    \entry{clifton_growth_1988}{article}{}
      \name{author}{5}{}{%
        {{hash=8ac910b18e1b6168ee4c16a81d68b5b6}{%
           family={Clifton},
           familyi={C\bibinitperiod},
           given={Rachel\bibnamedelima K.},
           giveni={R\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=7229b8690c40458b03fd3db56e888d52}{%
           family={Gwiazda},
           familyi={G\bibinitperiod},
           given={Jane},
           giveni={J\bibinitperiod}}}%
        {{hash=521b21ff6f925397afdeb4b6d2f148b6}{%
           family={Bauer},
           familyi={B\bibinitperiod},
           given={Joseph\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=1982c5e92a52a19a8a2eacc28a4a1b67}{%
           family={Clarkson},
           familyi={C\bibinitperiod},
           given={Marsha\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=804c09dda541271d714048d366f165c6}{%
           family={Held},
           familyi={H\bibinitperiod},
           given={Richard\bibnamedelima M.},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{6ebfe47222fc454662a799e5e49a6be5}
      \strng{fullhash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{bibnamehash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{authorbibnamehash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{authornamehash}{6ebfe47222fc454662a799e5e49a6be5}
      \strng{authorfullhash}{f9e6d52df029b6d57972eab5cc617347}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We measured head circumference and interaural distance in infants between birth and 22 weeks of age. A small sample of preschool children and adults were measured for comparison over the life span. We used these data to calculate changing interaural time differences across ages. Large shifts in this important binaural cue suggest that an ongoing developmental process recalibrates the association between interaural time differences and spatial location. These new data confirmed the sex differences in head circumference described in the Berkeley Growth Study (Eichorn \& Bailey, 1962) and found no secular trend in this measure in the 60 years since the earlier data were collected. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)}
      \field{issn}{1939-0599(Electronic),0012-1649(Print)}
      \field{journaltitle}{Developmental Psychology}
      \field{note}{Place: {US} Publisher: American Psychological Association}
      \field{number}{4}
      \field{title}{Growth in head size during infancy: Implications for sound localization.}
      \field{volume}{24}
      \field{year}{1988}
      \field{dateera}{ce}
      \field{pages}{477\bibrangedash 483}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1037/0012-1649.24.4.477
      \endverb
      \keyw{*Auditory Localization,*Age Differences,*Head (Anatomy),*Human Sex Differences,Physical Development}
    \endentry
    \entry{dietz_auditory_2011}{article}{}
      \name{author}{3}{}{%
        {{hash=0fff3eaffb14ecf4d97558717c928bb0}{%
           family={Dietz},
           familyi={D\bibinitperiod},
           given={Mathias},
           giveni={M\bibinitperiod}}}%
        {{hash=050737b9308ff0c4cb360df0537314a5}{%
           family={Ewert},
           familyi={E\bibinitperiod},
           given={Stephan\bibnamedelima D.},
           giveni={S\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=9b5db11c0c442086b33b5c9b37a78d15}{%
           family={Hohmann},
           familyi={H\bibinitperiod},
           given={Volker},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{3f58be53a6babc8796060fe8ff170067}
      \strng{fullhash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{bibnamehash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{authorbibnamehash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{authornamehash}{3f58be53a6babc8796060fe8ff170067}
      \strng{authorfullhash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Humans show a very robust ability to localize sounds in adverse conditions. Computational models of binaural sound localization and technical approaches of direction-of-arrival (DOA) estimation also show good performance, however, both their binaural feature extraction and the strategies for further analysis partly differ from what is currently known about the human auditory system. This study investigates auditory model based DOA estimation emphasizing known features and limitations of the auditory binaural processing such as (i) high temporal resolution, (ii) restricted frequency range to exploit temporal fine-structure, (iii) use of temporal envelope disparities, and (iv) a limited range to compensate for interaural time delay. DOA estimation performance was investigated for up to five concurrent speakers in free field and for up to three speakers in the presence of noise. The DOA errors in these conditions were always smaller than 5°. A condition with moving speakers was also tested and up to three moving speakers could be tracked simultaneously. Analysis of DOA performance as a function of the binaural temporal resolution showed that short time constants of about 5ms employed by the auditory model were crucial for robustness against concurrent sources.}
      \field{issn}{0167-6393}
      \field{journaltitle}{Speech Communication}
      \field{month}{5}
      \field{number}{5}
      \field{series}{Perceptual and {Statistical} {Audition}}
      \field{title}{Auditory model based direction estimation of concurrent speakers from binaural signals}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{53}
      \field{year}{2011}
      \field{urldateera}{ce}
      \field{pages}{592\bibrangedash 605}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1016/j.specom.2010.05.006
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/Users/pawel/Zotero/storage/B6MXZWGK/S016763931000097X.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S016763931000097X
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S016763931000097X
      \endverb
      \keyw{Auditory modeling,Binaural processing,Direction estimation}
    \endentry
    \entry{eisenman_check-n-run_2020}{article}{}
      \name{author}{8}{}{%
        {{hash=7340ee2f132a35281d3204fd988c70fe}{%
           family={Eisenman},
           familyi={E\bibinitperiod},
           given={Assaf},
           giveni={A\bibinitperiod}}}%
        {{hash=e13c63d4e13df53825c3bde8ed13bab2}{%
           family={Matam},
           familyi={M\bibinitperiod},
           given={Kiran\bibnamedelima Kumar},
           giveni={K\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=52983ec4513ef39b59ca37c0fefe5415}{%
           family={Ingram},
           familyi={I\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=7665aa4c66ae17e55251a67c635e7ad3}{%
           family={Mudigere},
           familyi={M\bibinitperiod},
           given={Dheevatsa},
           giveni={D\bibinitperiod}}}%
        {{hash=4a691df37485846988162c4f0639d2f0}{%
           family={Krishnamoorthi},
           familyi={K\bibinitperiod},
           given={Raghuraman},
           giveni={R\bibinitperiod}}}%
        {{hash=a0d10d48172f7b207c6fffcddb1db844}{%
           family={Annavaram},
           familyi={A\bibinitperiod},
           given={Murali},
           giveni={M\bibinitperiod}}}%
        {{hash=4266fa41481da32c5f77259e80ca615e}{%
           family={Nair},
           familyi={N\bibinitperiod},
           given={Krishnakumar},
           giveni={K\bibinitperiod}}}%
        {{hash=9e7183ff690cd4bd193b4b725fad9621}{%
           family={Smelyanskiy},
           familyi={S\bibinitperiod},
           given={Mikhail},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{0c10076539d27c95874c9e0b172336ac}
      \strng{fullhash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{bibnamehash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{authorbibnamehash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{authornamehash}{0c10076539d27c95874c9e0b172336ac}
      \strng{authorfullhash}{e57138c5d70975bd51ebe0cb122122a6}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Check-N-Run: A Checkpointing System for Training Recommendation Models}
      \field{volume}{abs/2010.08679}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Eisenman et al. - Check-N-Run a Checkpointing System for Training D.pdf:/Users/pawel/Zotero/storage/LW5BQQ8I/Eisenman et al. - Check-N-Run a Checkpointing System for Training D.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:224704491
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:224704491
      \endverb
    \endentry
    \entry{espi_exploiting_2015}{article}{}
      \name{author}{4}{}{%
        {{hash=3d606aa1ee1673fe0e177588f375cf1d}{%
           family={Espi},
           familyi={E\bibinitperiod},
           given={Miquel},
           giveni={M\bibinitperiod}}}%
        {{hash=7d117fe090853faf976a9b0ea7ea49c9}{%
           family={Fujimoto},
           familyi={F\bibinitperiod},
           given={Masakiyo},
           giveni={M\bibinitperiod}}}%
        {{hash=99b9d0400a15bba8addab471319a8863}{%
           family={Kinoshita},
           familyi={K\bibinitperiod},
           given={Keisuke},
           giveni={K\bibinitperiod}}}%
        {{hash=15ca5c62010c9e66000d4867c877580b}{%
           family={Nakatani},
           familyi={N\bibinitperiod},
           given={Tomohiro},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{dd3bd8dfb91e6e2ae1673829a6f45ad9}
      \strng{fullhash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{bibnamehash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{authorbibnamehash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{authornamehash}{dd3bd8dfb91e6e2ae1673829a6f45ad9}
      \strng{authorfullhash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, deep learning has not only permeated the computer vision and speech recognition research fields but also fields such as acoustic event detection ({AED}). One of the aims of {AED} is to detect and classify non-speech acoustic events occurring in conversation scenes including those produced by both humans and the objects that surround us. In {AED}, deep learning has enabled modeling of detail-rich features, and among these, high resolution spectrograms have shown a significant advantage over existing predefined features (e.g., Mel-filter bank) that compress and reduce detail. In this paper, we further asses the importance of feature extraction for deep learning-based acoustic event detection. {AED}, based on spectrogram-input deep neural networks, exploits the fact that sounds have “global” spectral patterns, but sounds also have “local” properties such as being more transient or smoother in the time-frequency domain. These can be exposed by adjusting the time-frequency resolution used to compute the spectrogram, or by using a model that exploits locality leading us to explore two different feature extraction strategies in the context of deep learning: (1) using multiple resolution spectrograms simultaneously and analyzing the overall and event-wise influence to combine the results, and (2) introducing the use of convolutional neural networks ({CNN}), a state of the art 2D feature extraction model that exploits local structures, with log power spectrogram input for {AED}. An experimental evaluation shows that the approaches we describe outperform our state-of-the-art deep learning baseline with a noticeable gain in the {CNN} case and provides insights regarding {CNN}-based spectrogram characterization for {AED}.}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{1}
      \field{shortjournal}{J {AUDIO} {SPEECH} {MUSIC} {PROC}.}
      \field{title}{Exploiting spectro-temporal locality in deep learning based acoustic event detection}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2015}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{26}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-015-0069-2
      \endverb
      \verb{file}
      \verb Espi et al. - 2015 - Exploiting spectro-temporal locality in deep learn.pdf:/Users/pawel/Zotero/storage/29QSQYTI/Espi et al. - 2015 - Exploiting spectro-temporal locality in deep learn.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-015-0069-2
      \endverb
      \verb{url}
      \verb https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-015-0069-2
      \endverb
    \endentry
    \entry{gardne_hrtf_1994}{online}{}
      \name{author}{2}{}{%
        {{hash=5b1fc211a56a5f1de4b8aef6be7dcb6a}{%
           family={Gardner},
           familyi={G\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod}}}%
        {{hash=2835b0059a28532b6119ec1d156b7506}{%
           family={Martin},
           familyi={M\bibinitperiod},
           given={Keith},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{fullhash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{bibnamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authorbibnamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authornamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authorfullhash}{493d5220c3023f74c46b515c0a0c9699}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{HRTF} Measurements of a {KEMAR} Dummy-Head Microphone}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{1994}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb HRTF Measurements of a KEMAR Dummy-Head Microphone:/Users/pawel/Zotero/storage/4HFJMLXI/KEMAR.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://sound.media.mit.edu/resources/KEMAR.html
      \endverb
      \verb{url}
      \verb https://sound.media.mit.edu/resources/KEMAR.html
      \endverb
    \endentry
    \entry{garofolo_darpa_1993}{article}{}
      \name{author}{6}{}{%
        {{hash=44271afa307ac7503236cffe215ad4fe}{%
           family={Garofolo},
           familyi={G\bibinitperiod},
           given={John\bibnamedelima S.},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=b210b37758f994ece79b9af4c9490e4d}{%
           family={Lamel},
           familyi={L\bibinitperiod},
           given={Lori},
           giveni={L\bibinitperiod}}}%
        {{hash=d8b228b8e55ccb45e125e295cd4ee49d}{%
           family={Fisher},
           familyi={F\bibinitperiod},
           given={William\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=5eb94c7444909f6544dafe84917447f3}{%
           family={Fiscus},
           familyi={F\bibinitperiod},
           given={Jonathan\bibnamedelima G.},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=20067c327d8a12d1e92c1a6023d59672}{%
           family={Pallett},
           familyi={P\bibinitperiod},
           given={David\bibnamedelima S.},
           giveni={D\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=b8370181dc059b845bee035b1aeb583b}{%
           family={Dahlgren},
           familyi={D\bibinitperiod},
           given={Nancy\bibnamedelima L.},
           giveni={N\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{cfe7640d7c6d82aa6b4ba6468064fc6e}
      \strng{fullhash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{bibnamehash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{authorbibnamehash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{authornamehash}{cfe7640d7c6d82aa6b4ba6468064fc6e}
      \strng{authorfullhash}{c9162c13740b8e8387f4cd84f554bb54}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{DARPA} {TIMIT}: acoustic-phonetic continuous speech corpus {CD}-{ROM}, {NIST} speech disc 1-1.1}
      \field{year}{1993}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:60884624
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:60884624
      \endverb
    \endentry
    \entry{hahmann_sound_2022}{article}{}
      \name{author}{4}{}{%
        {{hash=462effa97cee565bbd73d62c8de447f6}{%
           family={Hahmann},
           familyi={H\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod}}}%
        {{hash=7db6887530f3c844ba77d04c48e013e6}{%
           family={Fernandez-Grande},
           familyi={F\bibinithyphendelim G\bibinitperiod},
           given={Efren},
           giveni={E\bibinitperiod}}}%
        {{hash=bbde32c810b210de5d8021fde06c7003}{%
           family={Gunawan},
           familyi={G\bibinitperiod},
           given={Henrry},
           giveni={H\bibinitperiod}}}%
        {{hash=656ee498925f8094095f667d1dea6b55}{%
           family={Gerstoft},
           familyi={G\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{cd1fb091d0ef2ef9a1cd8397d605307b}
      \strng{fullhash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{bibnamehash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{authorbibnamehash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{authornamehash}{cd1fb091d0ef2ef9a1cd8397d605307b}
      \strng{authorfullhash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization is crucial for communication and sound scene analysis. This study uses direction-of-arrival estimates of multiple ad hoc distributed microphone arrays to localize sound sources in a room. An affine mapping between the independent array estimates and the source coordinates is derived from a set of calibration points. Experiments show that the affine model is sufficient to locate a source and can be calibrated to physical dimensions. A projection of the local array estimates increases localization accuracy, particularly further away from the calibrated region. Localization tests in three dimensions compare the affine approach to a nonlinear neural network.}
      \field{issn}{2691-1191}
      \field{journaltitle}{{JASA} Express Letters}
      \field{month}{7}
      \field{number}{7}
      \field{shortjournal}{{JASA} Express Lett}
      \field{title}{Sound source localization using multiple ad hoc distributed microphone arrays}
      \field{volume}{2}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{pages}{074801}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1121/10.0011811
      \endverb
      \verb{file}
      \verb Full Text:/Users/pawel/Zotero/storage/5MD884GP/Hahmann et al. - 2022 - Sound source localization using multiple ad hoc di.pdf:application/pdf
      \endverb
      \keyw{Sound,Acoustics,Sound Localization}
    \endentry
    \entry{han_convolutional_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=4a1e25a86fbcddf1e82056630f705db9}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Yoonchang},
           giveni={Y\bibinitperiod}}}%
        {{hash=3f8b651bfedbe1c637184643e341f410}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Jeongsoon},
           giveni={J\bibinitperiod}}}%
        {{hash=0f47d6f8a9660c5c5bcdb2f43935a120}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kyogu},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{3ef425317d659bd2c2d500f3b514208b}
      \strng{fullhash}{d7241d9dadb27f437922488280c79803}
      \strng{bibnamehash}{d7241d9dadb27f437922488280c79803}
      \strng{authorbibnamehash}{d7241d9dadb27f437922488280c79803}
      \strng{authornamehash}{3ef425317d659bd2c2d500f3b514208b}
      \strng{authorfullhash}{d7241d9dadb27f437922488280c79803}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Workshop on Detection and Classification of Acoustic Scenes and Events}
      \field{title}{Convolutional Neural Networks with Binaural Representations and Background Subtraction for Acoustic Scene Classification}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:52830611
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:52830611
      \endverb
    \endentry
    \entry{hirsh_binaural_1950}{article}{}
      \name{author}{1}{}{%
        {{hash=ba9301dcf14f75a44801567347475e0f}{%
           family={Hirsh},
           familyi={H\bibinitperiod},
           given={Ira\bibnamedelima J.},
           giveni={I\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{fullhash}{ba9301dcf14f75a44801567347475e0f}
      \strng{bibnamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authorbibnamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authornamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authorfullhash}{ba9301dcf14f75a44801567347475e0f}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{issn}{0022-4677, 2163-6184}
      \field{journaltitle}{Journal of Speech and Hearing Disorders}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{2}
      \field{shortjournal}{J Speech Hear Disord}
      \field{shorttitle}{Binaural Hearing Aids}
      \field{title}{Binaural Hearing Aids: A Review Of Some Experiments}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{1950}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{114\bibrangedash 123}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1044/jshd.1502.114
      \endverb
      \verb{file}
      \verb Hirsh - 1950 - Binaural Hearing Aids A Review Of Some Experiment.pdf:/Users/pawel/Zotero/storage/WI3CH9LM/Hirsh - 1950 - Binaural Hearing Aids A Review Of Some Experiment.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://pubs.asha.org/doi/10.1044/jshd.1502.114
      \endverb
      \verb{url}
      \verb http://pubs.asha.org/doi/10.1044/jshd.1502.114
      \endverb
    \endentry
    \entry{noauthor_hrtf-database_2014}{online}{}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{title}{{HRTF}-Database}
      \field{titleaddon}{Austrian Academy of Sciences}
      \field{type}{Acoustic Research Institute}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb HRTF-Database:/Users/pawel/Zotero/storage/F6K6MNKB/hrtf-database.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.oeaw.ac.at/en/ari/das-institut/software/hrtf-database
      \endverb
      \verb{url}
      \verb https://www.oeaw.ac.at/en/ari/das-institut/software/hrtf-database
      \endverb
    \endentry
    \entry{ioffe_batch_2015}{inbook}{}
      \name{author}{2}{}{%
        {{hash=5543e82359e26b035efc009cb3efff9d}{%
           family={Ioffe},
           familyi={I\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
        {{hash=ed568d9c3bb059e6bf22899fbf170f86}{%
           family={Szegedy},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=93da2819ab01d8a5e7bae39ce6f17c1f}{%
           family={Bach},
           familyi={B\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
        {{hash=df034c01f40f9863f7986f0670e3f863}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Lille, France}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{fullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{bibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorbibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authornamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorfullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{editorbibnamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editornamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editorfullhash}{4188f673e8c288b53fdbccdd66b77f3f}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
      \field{booktitle}{Proceedings of the 32nd International Conference on Machine Learning}
      \field{day}{7}
      \field{month}{7}
      \field{series}{Proceedings of Machine Learning Research}
      \field{title}{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}
      \field{volume}{37}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{pages}{448\bibrangedash 456}
      \range{pages}{9}
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v37/ioffe15.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v37/ioffe15.html
      \endverb
    \endentry
    \entry{noauthor_itu-r_2023}{article}{}
      \list{location}{1}{%
        {Geneva, Switzerland}%
      }
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Communications Union}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{{ITU}-R {BS}.1770-5: Algorithms to measure audio programme loudness and true-peak audio level}
      \field{year}{2023}
      \field{dateera}{ce}
      \verb{file}
      \verb Recommendation ITU-R BS.1770-5 (112023) Algorithm.pdf:/Users/pawel/Zotero/storage/KP326E9A/Recommendation ITU-R BS.1770-5 (112023) Algorithm.pdf:application/pdf
      \endverb
    \endentry
    \entry{kaveh_statistical_1986}{article}{}
      \name{author}{2}{}{%
        {{hash=e4dfdb3b9932151e9bc9aab6109e2bd2}{%
           family={Kaveh},
           familyi={K\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=fc0cdaa107f6eb96d3c987343c2b7640}{%
           family={Barabell},
           familyi={B\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{fullhash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{bibnamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authorbibnamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authornamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authorfullhash}{4c571bfbcc0f052f1c3d4d6606191441}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents an asymptotic statistical analysis of the null-spectra of two eigen-assisted methods, {MUSIC} [1] and Minimum-Norm [2], for resolving independent closely spaced plane waves in noise. Particular attention is paid to the average deviation of the null-spectra from zero at the true angles of arrival for the plane waves. These deviations are expressed as functions of signal-to-noise ratios, number of array elements, angular separation of emitters, and the number of snapshots. In the case of {MUSIC}. an approximate expression is derived for the resolution threshold of two plane waves with equal power in noise. This result is validated by Monte Carlo simulations.}
      \field{issn}{0096-3518}
      \field{journaltitle}{{IEEE} Transactions on Acoustics, Speech, and Signal Processing}
      \field{month}{4}
      \field{note}{Conference Name: {IEEE} Transactions on Acoustics, Speech, and Signal Processing}
      \field{number}{2}
      \field{title}{The statistical performance of the {MUSIC} and the minimum-norm algorithms in resolving plane waves in noise}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{34}
      \field{year}{1986}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{331\bibrangedash 341}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TASSP.1986.1164815
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/1164815
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/1164815
      \endverb
      \keyw{Covariance matrix,Direction of arrival estimation,Monte Carlo methods,Multiple signal classification,Narrowband,Signal resolution,Signal to noise ratio,Spatial resolution,Spectral analysis,Statistical analysis}
    \endentry
    \entry{king_how_2001}{article}{}
      \name{author}{6}{}{%
        {{hash=5bebdadef6ad12d7772a2172344d6a1a}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Andrew\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=3abeb505a9a92dab060ba5d85c85609f}{%
           family={Kacelnik},
           familyi={K\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
        {{hash=7dd1fbd28e9d7acb14800c2e7a051498}{%
           family={Mrsic-Flogel},
           familyi={M\bibinithyphendelim F\bibinitperiod},
           given={Thomas\bibnamedelima D.},
           giveni={T\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=8a8cbf404ec598c9aa00c86bd3deb309}{%
           family={Schnupp},
           familyi={S\bibinitperiod},
           given={Jan\bibnamedelima W.H.},
           giveni={J\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=e9e414ad13eeba14f15b1e2aa9a5ecc8}{%
           family={Parsons},
           familyi={P\bibinitperiod},
           given={Carl\bibnamedelima H.},
           giveni={C\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=fde060dbbae04bcf9a34a857c2e89ac2}{%
           family={Moore},
           familyi={M\bibinitperiod},
           given={David\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \strng{namehash}{ba3f375f3114ce6dd193baa68dab40a2}
      \strng{fullhash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{bibnamehash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{authorbibnamehash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{authornamehash}{ba3f375f3114ce6dd193baa68dab40a2}
      \strng{authorfullhash}{95e9cd30031d56a560ad8bc16fad7e28}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The location of a sound source is derived by the auditory system from spatial cues present in the signals at the two ears. These cues include interaural timing and level differences, as well as monaural spectral cues generated by the external ear. The values of these cues vary with individual differences in the shape and dimensions of the head and external ears. We have examined the neurophysiological consequences of these intersubject variations by recording the responses of neurons in ferret primary auditory cortex to virtual sound sources mimicking the animal’s own ears or those of other ferrets. For most neurons, the structure of the spatial response fields changed significantly when acoustic cues measured from another animal were presented. This is consistent with the finding that humans localize less accurately when listening to virtual sounds from other subjects. To examine the role of experience in shaping the ability to localize sound, we have studied the behavioural consequences of altering binaural cues by chronically plugging one ear. Ferrets raised and tested with one ear plugged learned to localize as accurately as control animals, which is consistent with previous findings that the representation of auditory space in the midbrain can accommodate abnormal sensory cues during development. Adaptive changes in behaviour were also observed in adults, particularly if they were provided with regular practice in the localization task. Together, these findings suggest that the neural circuits responsible for sound localization can be recalibrated throughout life.}
      \field{day}{8}
      \field{issn}{1420-3030}
      \field{journaltitle}{Audiology and Neurotology}
      \field{month}{11}
      \field{number}{4}
      \field{shortjournal}{Audiology and Neurotology}
      \field{title}{How Plastic Is Spatial Hearing?}
      \field{urlday}{24}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2001}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{182\bibrangedash 186}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1159/000046829
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1159/000046829
      \endverb
      \verb{url}
      \verb https://doi.org/10.1159/000046829
      \endverb
    \endentry
    \entry{kingma_adam_2014}{article}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{fullhash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{bibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorbibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authornamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorfullhash}{a09df9f123146b8e2c7f1134c9496932}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{CoRR}}
      \field{title}{Adam: A Method for Stochastic Optimization}
      \field{volume}{abs/1412.6980}
      \field{year}{2014}
      \field{dateera}{ce}
      \verb{file}
      \verb Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/home/pawel/Zotero/storage/78ZYK5H2/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:6628106
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:6628106
      \endverb
    \endentry
    \entry{krizhevsky_imagenet_2012}{article}{}
      \name{author}{3}{}{%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=813bd95fe553e6079cd53a567b238287}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey\bibnamedelima E},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{dd291871bfa8ee64447232f1cca429aa}
      \strng{fullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{bibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authorbibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authornamehash}{dd291871bfa8ee64447232f1cca429aa}
      \strng{authorfullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{title}{{ImageNet} Classification with Deep Convolutional Neural Networks}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/NKTH38ND/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
    \endentry
    \entry{kuhn_applied_2013}{book}{}
      \name{author}{2}{}{%
        {{hash=3305789acf03200ed22f154007d4fab9}{%
           family={Kuhn},
           familyi={K\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
        {{hash=8506bc0799a0f764e71f60c7bb5b7fd9}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Kjell},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}}%
      }
      \list{publisher}{1}{%
        {Springer New York}%
      }
      \strng{namehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{fullhash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{bibnamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authorbibnamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authornamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authorfullhash}{87ef0f02906001a3dbac62a9064e9c1e}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-4614-6848-6 978-1-4614-6849-3}
      \field{langid}{english}
      \field{title}{Applied Predictive Modeling}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-1-4614-6849-3
      \endverb
      \verb{file}
      \verb Kuhn and Johnson - 2013 - Applied Predictive Modeling.pdf:/Users/pawel/Zotero/storage/5S7BX9K4/Kuhn and Johnson - 2013 - Applied Predictive Modeling.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-1-4614-6849-3
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-1-4614-6849-3
      \endverb
    \endentry
    \entry{lecun_handwritten_1989}{article}{}
      \name{author}{7}{}{%
        {{hash=6a1aa6b7eab12b931ca7c7e3f927231d}{%
           family={{LeCun}},
           familyi={L\bibinitperiod},
           given={Yann},
           giveni={Y\bibinitperiod}}}%
        {{hash=824ee0660bd2a40e283a9b8266f0868b}{%
           family={Boser},
           familyi={B\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=2e06fda0238979cad0d24113daf80ed5}{%
           family={Denker},
           familyi={D\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0444ce878492140cb17d6d4f19c2b24d}{%
           family={Henderson},
           familyi={H\bibinitperiod},
           given={Donnie},
           giveni={D\bibinitperiod}}}%
        {{hash=09c5a94a3b4d44c65e19cea92a351737}{%
           family={Howard},
           familyi={H\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=494b3ee863ae780ea5237c5b09b80c0e}{%
           family={Hubbard},
           familyi={H\bibinitperiod},
           given={Wayne},
           giveni={W\bibinitperiod}}}%
        {{hash=4b8d7e185f2fbc444f33953aa1c0a385}{%
           family={Jackel},
           familyi={J\bibinitperiod},
           given={Lawrence},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan-Kaufmann}%
      }
      \strng{namehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{fullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{bibnamehash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{authorbibnamehash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{authornamehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{authorfullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1 \% error rate and about a 9\% reject rate on zipcode digits provided by the U.S. Postal Service.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{title}{Handwritten Digit Recognition with a Back-Propagation Network}
      \field{urlday}{14}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/LQ2N3GLG/LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagat.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
    \endentry
    \entry{lin_network_2013}{article}{}
      \name{author}{3}{}{%
        {{hash=d2827b813d1d73df44360201e3296bea}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
        {{hash=8b8805250fb5a57cfbae360547a18706}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=7a7a92b64300d6c39c3ae492b9ded385}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Shuicheng},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{8c2ac34b334a3f7f4ccec03dd423b93f}
      \strng{fullhash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{bibnamehash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{authorbibnamehash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{authornamehash}{8c2ac34b334a3f7f4ccec03dd423b93f}
      \strng{authorfullhash}{e1066eda6080c3fe3aab9eb7d6746493}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{CoRR}}
      \field{title}{Network In Network}
      \field{volume}{abs/1312.4400}
      \field{year}{2013}
      \field{dateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/3FFXZK4D/Lin et al. - 2014 - Network In Network.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:16636683
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:16636683
      \endverb
    \endentry
    \entry{noauthor_listen_2023}{online}{}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{title}{{LISTEN} {HRTF} {DATABASE}}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb LISTEN HRTF DATABASE:/Users/pawel/Zotero/storage/66K5BKAI/listen.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://recherche.ircam.fr/equipes/salles/listen/
      \endverb
      \verb{url}
      \verb http://recherche.ircam.fr/equipes/salles/listen/
      \endverb
    \endentry
    \entry{liu_sound_2022}{article}{}
      \name{author}{5}{}{%
        {{hash=4d4148139979b7758963ba11cb70142c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Mengran},
           giveni={M\bibinitperiod}}}%
        {{hash=180fcc4a2bd4ddf6d1cec5f764615e72}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Junhao},
           giveni={J\bibinitperiod}}}%
        {{hash=cbc415fc36c599555cb13b0e962f1c25}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=ebe4da51d11cda6425b1b66ec3051050}{%
           family={Jian},
           familyi={J\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod}}}%
        {{hash=f1f055060e271e0e54de057aad92a0df}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{d41c630f43e49f649bdfae6533c60aed}
      \strng{fullhash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{bibnamehash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{authorbibnamehash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{authornamehash}{d41c630f43e49f649bdfae6533c60aed}
      \strng{authorfullhash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Beamforming and its applications in steered-response power ({SRP}) technology, such as steered-response power delay and sum ({SRP}-{DAS}) and steered-response power phase transform ({SRP}-{PHAT}), are widely used in sound source localization. However, their resolution and accuracy still need improvement. A novel beamforming method combining {SRP} and multi-channel cross-correlation coefficient ({MCCC}), {SRP}-{MCCC}, is proposed in this paper to improve the accuracy of direction of arrival ({DOA}). Directional weight ({DW}) is obtained by calculating the {MCCC}. Based on {DW}, suppressed the non-incoming wave direction and gained the incoming wave direction to improve the beamforming capabilities. Then, sound source localizations based on the dual linear array under different conditions were simulated. Compared with {SRP}-{PHAT}, {SRP}-{MCCC} has the advantages of high positioning accuracy, strong spatial directivity and robustness under the different signal–noise ratios ({SNRs}). When the {SNR} is −10 {dB}, the average positioning error of the single-frequency sound source at different coordinates decreases by 5.69\%, and that of the mixed frequency sound sources at the same coordinate decreases by 5.77\%. Finally, the experimental verification was carried out. The results show that the average error of {SRP}-{MCCC} has been reduced by 8.14\% and the positioning accuracy has been significantly improved, which is consistent with the simulation results. This research provides a new idea for further engineering applications of sound source localization based on beamforming.}
      \field{issn}{2072-666X}
      \field{journaltitle}{Micromachines}
      \field{langid}{english}
      \field{month}{7}
      \field{note}{Number: 7 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{7}
      \field{title}{Sound Source Localization Based on Multi-Channel Cross-Correlation Weighted Beamforming}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{13}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1010}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/mi13071010
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/J597NXKN/Liu et al. - 2022 - Sound Source Localization Based on Multi-Channel C.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2072-666X/13/7/1010
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2072-666X/13/7/1010
      \endverb
      \keyw{beamforming,microphone array,multi-channel cross-correlation coefficient,sound source localization}
    \endentry
    \entry{liu_multiple_2018}{article}{}
      \name{author}{5}{}{%
        {{hash=7d8ff4df69095548fd14c2e6e040dfd2}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qingju},
           giveni={Q\bibinitperiod}}}%
        {{hash=8be7c3820bf2af64ef6797042404933a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wenwu},
           giveni={W\bibinitperiod}}}%
        {{hash=28441c007bd61b6db752461d573f2a74}{%
           family={Campos},
           familyi={C\bibinitperiod},
           given={Teófilo},
           giveni={T\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
        {{hash=f32004081bcf11ee769cd92302b54823}{%
           family={Jackson},
           familyi={J\bibinitperiod},
           given={Philip\bibnamedelimb J.\bibnamedelimi B.},
           giveni={P\bibinitperiod\bibinitdelim J\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=5dea3144ba12b0f069a5735888879d6d}{%
           family={Hilton},
           familyi={H\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{97431020ac7db7ff55462430cba5b36e}
      \strng{fullhash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{bibnamehash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{authorbibnamehash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{authornamehash}{97431020ac7db7ff55462430cba5b36e}
      \strng{authorfullhash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In the object-based spatial audio system, positions of the audio objects (e.g., speakers/talkers or voices) presented in the sound scene are required as important metadata attributes for object acquisition and reproduction. Binaural microphones are often used as a physical device to mimic human hearing and to monitor and analyze the scene, including localization and tracking of multiple speakers. The binaural audio tracker, however, is usually prone to the errors caused by room reverberation and background noise. To address this limitation, we present a multimodal tracking method by fusing the binaural audio with depth information (from a depth sensor, e.g., Kinect). More specifically, the probability hypothesis density ({PHD}) filtering framework is first applied to the depth stream, and a novel clutter intensity model is proposed to improve the robustness of the {PHD} filter when an object is occluded either by other objects or due to the limited field of view of the depth sensor. To compensate misdetections in the depth stream, a novel gap filling technique is presented to map audio azimuths obtained from the binaural audio tracker to 3D positions, using speaker-dependent spatial constraints learned from the depth stream. With our proposed method, both the errors in the binaural tracker and the misdetections in the depth tracker can be significantly reduced. Real-room recordings are used to show the improved performance of the proposed method in removing outliers and reducing misdetections.}
      \field{issn}{1941-0077}
      \field{journaltitle}{{IEEE} Transactions on Multimedia}
      \field{month}{7}
      \field{note}{Conference Name: {IEEE} Transactions on Multimedia}
      \field{number}{7}
      \field{title}{Multiple Speaker Tracking in Spatial Audio via {PHD} Filtering and Depth-Audio Fusion}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1767\bibrangedash 1780}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TMM.2017.2777671
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/ETBEG7F9/8119824.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8119824
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8119824
      \endverb
      \keyw{Azimuth,binaural microphones,Clutter,depth and audio,depth sensor,Metadata,Microphones,Multi-person tracking,{PHD} filtering,spatial audio,Target tracking,Three-dimensional displays,Trajectory}
    \endentry
    \entry{ma16c_interspeech}{article}{}
      \name{author}{2}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{fullhash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{bibnamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authorbibnamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authornamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authorfullhash}{9f93af7b144e77f1b4559cf7d976b821}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2308-457X}
      \field{journaltitle}{Proc. Interspeech 2016}
      \field{title}{{Speech Localisation in a Multitalker Mixture by Humans and Machines}}
      \field{year}{2016}
      \field{pages}{3359\bibrangedash 3363}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2016-1149
      \endverb
    \endentry
    \entry{ma_exploiting_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{fullhash}{c581f172961308c31ced8958a27e3765}
      \strng{bibnamehash}{c581f172961308c31ced8958a27e3765}
      \strng{authorbibnamehash}{c581f172961308c31ced8958a27e3765}
      \strng{authornamehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{authorfullhash}{c581f172961308c31ced8958a27e3765}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents a novel machine-hearing system that exploits deep neural networks (DNNs) and head movements for robust binaural localisation of multiple sources in reverberant environments. DNNs are used to learn the relationship between the source azimuth and binaural cues, consisting of the complete cross-correlation function (CCF) and interaural level differences (ILDs). In contrast to many previous binaural hearing systems, the proposed approach is not restricted to localisation of sound sources in the frontal hemifield. Due to the similarity of binaural cues in the frontal and rear hemifields, front-back confusions often occur. To address this, a head movement strategy is incorporated in the localisation model to help reduce the front-back errors. The proposed DNN system is compared to a Gaussian mixture model (GMM) based system that employs interaural time differences (ITDs) and ILDs as localisation features. Our experiments show that the DNN is able to exploit information in the CCF that is not available in the ITD cue, which together with head movements substantially improves localisation accuracies under challenging acoustic scenarios in which multiple talkers and room reverberation are present.}
      \field{annotation}{Comment: 10 pages}
      \field{issn}{2329-9290, 2329-9304}
      \field{journaltitle}{IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{month}{12}
      \field{note}{arXiv:1904.03001 [cs, eess]}
      \field{number}{12}
      \field{title}{Exploiting {Deep} {Neural} {Networks} and {Head} {Movements} for {Robust} {Binaural} {Localisation} of {Multiple} {Sources} in {Reverberant} {Environments}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{2444\bibrangedash 2453}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASLP.2017.2750760
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/pawel/Zotero/storage/Q8KYT7PT/Ma et al. - 2017 - Exploiting Deep Neural Networks and Head Movements.pdf:application/pdf;arXiv.org Snapshot:/Users/pawel/Zotero/storage/NXKLQ8NH/1904.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1904.03001
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1904.03001
      \endverb
      \keyw{Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{ma_robust_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=1230365d4e7c053d32ee1ce21caab89b}{%
           family={Gonzalez},
           familyi={G\bibinitperiod},
           given={Jose\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{fullhash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{bibnamehash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{authorbibnamehash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{authornamehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{authorfullhash}{10ef4aab764bb9514a44369ebdd82e1e}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Despite there being a clear evidence for top-down (e.g., attentional) effects in biological spatial hearing, relatively few machine hearing systems exploit the top-down model-based knowledge in sound localization. This paper addresses this issue by proposing a novel framework for the binaural sound localization that combines the model-based information about the spectral characteristics of sound sources and deep neural networks ({DNNs}). A target source model and a background source model are first estimated during a training phase using spectral features extracted from sound signals in isolation. When the identity of the background source is not available, a universal background model can be used. During testing, the source models are used jointly to explain the mixed observations and improve the localization process by selectively weighting source azimuth posteriors output by a {DNN}-based localization system. To address the possible mismatch between the training and testing, a model adaptation process is further employed the on-the-fly during testing, which adapts the background model parameters directly from the noisy observations in an iterative manner. The proposed system, therefore, combines the model-based and data-driven information flow within a single computational framework. The evaluation task involved localization of a target speech source in the presence of an interfering source and room reverberation. Our experiments show that by exploiting the model-based information in this way, the sound localization performance can be improved substantially under various noisy and reverberant conditions.}
      \field{issn}{2329-9304}
      \field{journaltitle}{{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{month}{11}
      \field{note}{Conference Name: {IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{number}{11}
      \field{title}{Robust Binaural Localization of a Target Sound Source by Combining Spectral Source Models and Deep Neural Networks}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2122\bibrangedash 2131}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASLP.2018.2855960
      \endverb
      \verb{file}
      \verb Accepted Version:/Users/pawel/Zotero/storage/LZQN43AY/Ma et al. - 2018 - Robust Binaural Localization of a Target Sound Sou.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8410799
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8410799
      \endverb
      \keyw{Adaptation models,Auditory system,Azimuth,Binaural source localisation,Biological system modeling,Computational modeling,machine hearing,masking,reverberation,sound source combination,Speech processing,Time-frequency analysis}
    \endentry
    \entry{may_probabilistic_2011}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=0973c5121defb9080da8617ef19641f2}{%
           family={Kohlrausch},
           familyi={K\bibinitperiod},
           given={Armin},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{fa2cd709d65b45f32c673018401a4171}
      \strng{bibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authorbibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{fa2cd709d65b45f32c673018401a4171}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Although extensive research has been done in the field of machine-based localization, the degrading effect of reverberation and the presence of multiple sources on localization performance has remained a major problem. Motivated by the ability of the human auditory system to robustly analyze complex acoustic scenes, the associated peripheral stage is used in this paper as a front-end to estimate the azimuth of sound sources based on binaural signals. One classical approach to localize an acoustic source in the horizontal plane is to estimate the interaural time difference (ITD) between both ears by searching for the maximum in the cross-correlation function. Apart from ITDs, the interaural level difference (ILD) can contribute to localization, especially at higher frequencies where the wavelength becomes smaller than the diameter of the head, leading to ambiguous ITD information. The interdependency of ITD and ILD on azimuth is a complex pattern that depends also on the room acoustics, and is therefore learned by azimuth-dependent Gaussian mixture models (GMMs). Multiconditional training is performed to take into account the variability of the binaural features which results from multiple sources and the effect of reverberation. The proposed localization model outperforms state-of-the-art localization techniques in simulated adverse acoustic conditions.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{1}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{1}
      \field{title}{A {Probabilistic} {Model} for {Robust} {Localization} {Based} on a {Binaural} {Auditory} {Front}-{End}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2011}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 13}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TASL.2010.2042128
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/5406118
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/5406118
      \endverb
      \keyw{auditory scene analysis (ASA),Auditory system,Azimuth,binaural,Degradation,Ear,Frequency,Humans,interaural level difference (ILD),interaural time difference (ITD),Layout,Localization,reverberation,Reverberation,Robustness,Signal analysis}
    \endentry
    \entry{may_binaural_2012}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=0973c5121defb9080da8617ef19641f2}{%
           family={Kohlrausch},
           familyi={K\bibinitperiod},
           given={Armin},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{fa2cd709d65b45f32c673018401a4171}
      \strng{bibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authorbibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{fa2cd709d65b45f32c673018401a4171}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this study, we present a binaural scene analyzer that is able to simultaneously localize, detect and identify a known number of target speakers in the presence of spatially positioned noise sources and reverberation. In contrast to many other binaural cocktail party processors, the proposed system does not require a priori knowledge about the azimuth position of the target speakers. The proposed system consists of three main building blocks: binaural localization, speech source detection, and automatic speaker identification. First, a binaural front-end is used to robustly localize relevant sound source activity. Second, a speech detection module based on missing data classification is employed to determine whether detected sound source activity corresponds to a speaker or to an interfering noise source using a binary mask that is based on spatial evidence supplied by the binaural front-end. Third, a second missing data classifier is used to recognize the speaker identities of all detected speech sources. The proposed system is systematically evaluated in simulated adverse acoustic scenarios. Compared to state-of-the art MFCC recognizers, the proposed model achieves significant speaker recognition accuracy improvements.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{9}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{7}
      \field{title}{A {Binaural} {Scene} {Analyzer} for {Joint} {Localization} and {Recognition} of {Speakers} in the {Presence} of {Interfering} {Noise} {Sources} and {Reverberation}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{2016\bibrangedash 2030}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TASL.2012.2193391
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6178270
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6178270
      \endverb
      \keyw{Acoustics,Auditory system,Automatic speaker recognition,binaural processing,computational auditory scene analysis (CASA),Humans,mask estimation,missing data,Noise,Speech,Speech recognition,Target recognition}
    \endentry
    \entry{may_robust_2015}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{bibnamehash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{authorbibnamehash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{240fedddeebda9c63ac23acdd7cdedf0}
      \field{extraname}{3}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper addresses the problem of localising multiple competing speakers in the presence of room reverberation, where sound sources can be positioned at any azimuth on the horizontal plane. To reduce the amount of front-back confusions which can occur due to the similarity of interaural time differences (ITDs) and interaural level differences (ILDs) in the front and rear hemifield, a machine hearing system is presented which combines supervised learning of binaural cues using multi-conditional training (MCT) with a head movement strategy. A systematic evaluation showed that this approach substantially reduced the amount of front-back confusions in challenging acoustic scenarios. Moreover, the system was able to generalise to a variety of different acoustic conditions not seen during training.}
      \field{journaltitle}{2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})}
      \field{month}{4}
      \field{note}{ISSN: 2379-190X}
      \field{title}{Robust localisation of multiple speakers exploiting head movements and multi-conditional training of binaural cues}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{2679\bibrangedash 2683}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2015.7178457
      \endverb
      \verb{file}
      \verb Accepted Version:/Users/pawel/Zotero/storage/UUF7ABAN/May et al. - 2015 - Robust localisation of multiple speakers exploitin.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/VAZXWS4I/7178457.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7178457
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7178457
      \endverb
      \keyw{Acoustics,Auditory system,Azimuth,binaural sound source localisation,generalisation,head movements,Magnetic heads,multi-conditional training,Robustness,Speech,Training}
    \endentry
    \entry{miikkulainen_evolving_2017}{article}{}
      \name{author}{11}{}{%
        {{hash=70ad9af6f97993f2ea5c1f65e1985520}{%
           family={Miikkulainen},
           familyi={M\bibinitperiod},
           given={Risto},
           giveni={R\bibinitperiod}}}%
        {{hash=1b3f44c190a77da248d20f1e934c0ccf}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Jason\bibnamedelima Zhi},
           giveni={J\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=b3dd11e9d67e706e42c999b4bdcef69c}{%
           family={Meyerson},
           familyi={M\bibinitperiod},
           given={Elliot},
           giveni={E\bibinitperiod}}}%
        {{hash=f3b9c9f26d0a6f42c13be4baf0a5ab3c}{%
           family={Rawal},
           familyi={R\bibinitperiod},
           given={Aditya},
           giveni={A\bibinitperiod}}}%
        {{hash=b7b839a822e2d965311274b4623951a4}{%
           family={Fink},
           familyi={F\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=414eef3c9431b90ce30abb176cbdf974}{%
           family={Francon},
           familyi={F\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
        {{hash=568757b2b2f5c93108afb3d702bdccc7}{%
           family={Raju},
           familyi={R\bibinitperiod},
           given={Bala\bibnamedelima Eshwar},
           giveni={B\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=05d587b2e6ac4c141ba1cbfa4ccc8c8a}{%
           family={Shahrzad},
           familyi={S\bibinitperiod},
           given={Hormoz},
           giveni={H\bibinitperiod}}}%
        {{hash=445863110210846e31553e61b5964e2e}{%
           family={Navruzyan},
           familyi={N\bibinitperiod},
           given={Arshak},
           giveni={A\bibinitperiod}}}%
        {{hash=566d63cf439fdbdbad68beef36f1442d}{%
           family={Duffy},
           familyi={D\bibinitperiod},
           given={Nigel\bibnamedelima P.},
           giveni={N\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=2a778911b7c85660920d24cb845b1b54}{%
           family={Hodjat},
           familyi={H\bibinitperiod},
           given={Babak},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{4c5a30e5bf8c182a99cfb6fa672b76e0}
      \strng{fullhash}{41d1285cb5f435886098946b6735d74b}
      \strng{bibnamehash}{41d1285cb5f435886098946b6735d74b}
      \strng{authorbibnamehash}{41d1285cb5f435886098946b6735d74b}
      \strng{authornamehash}{4c5a30e5bf8c182a99cfb6fa672b76e0}
      \strng{authorfullhash}{41d1285cb5f435886098946b6735d74b}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Evolving Deep Neural Networks}
      \field{volume}{abs/1703.00548}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{file}
      \verb Miikkulainen et al. - 2017 - Evolving Deep Neural Networks.pdf:/home/pawel/Zotero/storage/HMMY2GVB/Miikkulainen et al. - 2017 - Evolving Deep Neural Networks.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:215763844
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:215763844
      \endverb
    \endentry
    \entry{morgan_generalization_1989}{article}{}
      \name{author}{2}{}{%
        {{hash=bc51862d34f106d30f6213c8de089806}{%
           family={Morgan},
           familyi={M\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
        {{hash=0fd43d8b190039eeb3ca2aec409bc50b}{%
           family={Bourlard},
           familyi={B\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan-Kaufmann}%
      }
      \strng{namehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{fullhash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{bibnamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authorbibnamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authornamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authorfullhash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We have done an empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization perfor(cid:173) mance. Two experiments are reported. In one, we use simulated data sets with well-controlled parameters, such as the signal-to-noise ratio of continuous-valued data. In the second, we train the network on vector-quantized mel cepstra from real speech samples. In each case, we use back-propagation to train the feedforward net to discriminate in a multiple class pattern classification problem. We report the results of these studies, and show the application of cross-validation techniques to prevent overfitting.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{shorttitle}{Generalization and Parameter Estimation in Feedforward Nets}
      \field{title}{Generalization and Parameter Estimation in Feedforward Nets: Some Experiments}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SZJLY474/Morgan and Bourlard - 1989 - Generalization and Parameter Estimation in Feedfor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://papers.nips.cc/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html
      \endverb
      \verb{url}
      \verb https://papers.nips.cc/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html
      \endverb
    \endentry
    \entry{pan_multi-tone_2021}{article}{}
      \name{author}{5}{}{%
        {{hash=3e268f8b3015c8c1e15220388b8e6695}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Zihan},
           giveni={Z\bibinitperiod}}}%
        {{hash=3dac66e08d525d33721786bb7c8dc77b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Malu},
           giveni={M\bibinitperiod}}}%
        {{hash=dc50f1bbfa42a577b5868615c7c55ade}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jibin},
           giveni={J\bibinitperiod}}}%
        {{hash=b98fe8d59bba1ea85e482bb0551e165e}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jiadong},
           giveni={J\bibinitperiod}}}%
        {{hash=f397ee85433a25b75738faa0b764e496}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haizhou},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{0ec26c86fdd002eb74f730668321f7b8}
      \strng{fullhash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{bibnamehash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{authorbibnamehash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{authornamehash}{0ec26c86fdd002eb74f730668321f7b8}
      \strng{authorfullhash}{66ca05c73e797af3bf13ea2862f044c4}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mammals exhibit remarkable capability of detecting and localizing sound sources in complex acoustic environments by using binaural cues in the spiking manner. Emulating the auditory process for sound source localization ({SSL}) by mammals, we propose a computational model for accurate and robust {SSL} under the neuromorphic spiking neural network ({SNN}) framework. The center of this model is a Multi-Tone Phase Coding ({MTPC}) scheme, which encodes the interaural time difference ({ITD}) between binaural pure tones into discriminative spike patterns that can be directly classified by {SNNs}. As such, {SSL} can be implemented as an event-driven task on highly efficient, neuromorphic parallel processors. We evaluate the proposed computational model on a directional audio dataset recorded from a microphone array in a realistic acoustic environment with background noise, obstruction, reflection, and other interferences. We report superior localization capability with a mean absolute error ({MAE}) of 1.02° or 100\% classification accuracy with an angle resolution of 5°, which surpasses other {SNN}-based biologically plausible neuromorphic approaches by a relatively large margin and on par with human performance in similar tasks. This study opens up many application opportunities in human-robot interaction where energy efficiency is crucial. As a case study, we successfully deploy the proposed {SSL} system in a robotic platform to track the speaker and orient the robot's attention.}
      \field{issn}{2329-9304}
      \field{journaltitle}{{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{note}{Conference Name: {IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{title}{Multi-Tone Phase Coding of Interaural Time Difference for Sound Source Localization With Spiking Neural Networks}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{29}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2656\bibrangedash 2670}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TASLP.2021.3100684
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/8CJB3YFJ/9502013.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9502013
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9502013
      \endverb
      \keyw{Acoustics,Biological neural networks,Computational modeling,Ear,Encoding,Location awareness,Neural phase coding,Neurons,sound source localization,spiking neural network}
    \endentry
    \entry{pang_multitask_2019}{article}{}
      \name{author}{3}{}{%
        {{hash=1f7d3450b7db4cfe1c10baea8e7141cf}{%
           family={Pang},
           familyi={P\bibinitperiod},
           given={Cheng},
           giveni={C\bibinitperiod}}}%
        {{hash=44a453a69684789133e3b3393f75ef31}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hong},
           giveni={H\bibinitperiod}}}%
        {{hash=4c142d712e762cc45c88046b8de422c0}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xiaofei},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{32b0ccc80983b9263a24724cb08d9504}
      \strng{fullhash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{bibnamehash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{authorbibnamehash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{authornamehash}{32b0ccc80983b9263a24724cb08d9504}
      \strng{authorfullhash}{773549cc332fb20a6c3d29a6ba8cc067}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization (SSL) is an important technique for many audio processing systems, such as speech enhancement/recognition and human-robot interaction. Although many methods have been proposed for SSL, it still remains a challenging task to achieve accurate localization under adverse acoustic scenarios. In this paper, a novel binaural SSL method based on time-frequency convolutional neural network (TF-CNN) with multitask learning is proposed to simultaneously localize azimuth and elevation under unknown acoustic conditions. First, the interaural phase difference and interaural level difference are extracted from the received binaural signals, which are taken as the input of the proposed SSL neural network. Then, an SSL neural network is designed to map the interaural cues to sound direction, which consists of TF-CNN module and multitask neural network. The TF-CNN module learns and combines the time-frequency information of extracted interaural cues to generate the shared feature for multitask SSL. With the shared feature, a multitask neural network is designed to simultaneously estimate azimuth and elevation through multitask learning, which generates the posterior probability for candidate directions. Finally, the candidate direction with the highest probability is taken as the final direction estimation. The experiments based on public head-related transfer function (HRTF) database demonstrate that the proposed method achieves preferable localization performance compared with other popular methods.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{note}{Conference Name: IEEE Access}
      \field{title}{Multitask {Learning} of {Time}-{Frequency} {CNN} for {Sound} {Source} {Localization}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{7}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{40725\bibrangedash 40737}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2905617
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8668414
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8668414
      \endverb
      \keyw{Acoustics,Azimuth,convolutional neural network,Estimation,Feature extraction,multitask learning,Neural networks,Noise measurement,Sound source localization,time-frequency,Time-frequency analysis}
    \endentry
    \entry{pavlidi_real-time_2012}{article}{}
      \name{author}{4}{}{%
        {{hash=ce41077d0c7ff5f13f6ad5950ed7da4f}{%
           family={Pavlidi},
           familyi={P\bibinitperiod},
           given={Despoina},
           giveni={D\bibinitperiod}}}%
        {{hash=309b667b2eb9e7c7ef9729c4627a5bb7}{%
           family={Puigt},
           familyi={P\bibinitperiod},
           given={Matthieu},
           giveni={M\bibinitperiod}}}%
        {{hash=dcabc8007736b7781481c464d9a8d076}{%
           family={Griffin},
           familyi={G\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod}}}%
        {{hash=a7ec2ff0e227539444a272f917e98ca2}{%
           family={Mouchtaris},
           familyi={M\bibinitperiod},
           given={Athanasios},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{222f5e3d5aea109f4e0c1fd142bbf9d9}
      \strng{fullhash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{bibnamehash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{authorbibnamehash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{authornamehash}{222f5e3d5aea109f4e0c1fd142bbf9d9}
      \strng{authorfullhash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a novel real-time adaptative localization approach for multiple sources using a circular array, in order to suppress the localization ambiguities faced with linear arrays, and assuming a weak sound source sparsity which is derived from blind source separation methods. Our proposed method performs very well both in simulations and in real conditions at 50\% real-time.}
      \field{journaltitle}{2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{month}{3}
      \field{note}{{ISSN}: 2379-190X}
      \field{title}{Real-time multiple sound source localization using a circular microphone array based on single-source confidence measures}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2625\bibrangedash 2628}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICASSP.2012.6288455
      \endverb
      \verb{file}
      \verb Full Text:/home/pawel/Zotero/storage/FXAAV3EW/Pavlidi et al. - 2012 - Real-time multiple sound source localization using.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pawel/Zotero/storage/RI3ZVKSY/6288455.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6288455
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6288455
      \endverb
      \keyw{Speech,Microphones,Estimation,Direction of arrival estimation,multiple source localization,Array signal processing,Arrays,direction of arrival estimation,Real time systems,Time frequency analysis}
    \endentry
    \entry{pocock_practical_1989}{article}{}
      \name{author}{2}{}{%
        {{hash=94d45180df1a571f03dcaec9e8bf020a}{%
           family={Pocock},
           familyi={P\bibinitperiod},
           given={Stuart\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=03eaeecba521abd860ab61c902215778}{%
           family={Hughes},
           familyi={H\bibinitperiod},
           given={Michael\bibnamedelima D.},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \strng{namehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{fullhash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{bibnamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authorbibnamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authornamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authorfullhash}{b89283f0ce6f20bd7fb178b367341b4e}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article considers some of the practical problems inherent in interim analyses and stopping rules for randomized clinical trials. Topics covered include group sequential designs, trials with unplanned interim analyses, estimation problems in clinical trials with planned interim analyses, and the balance between individual and collective ethics. Particular attention is paid to the fact that clinical trials that stop early are prone to exaggerate the magnitude of treatment effect. Accordingly, a Bayesian "shrinkage" method of analysis is proposed to help quantify the extent to which surprisingly large point and interval estimates of treatment difference in clinical trials that stop early should be moderated.}
      \field{issn}{01972456}
      \field{journaltitle}{Controlled Clinical Trials}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{Controlled Clinical Trials}
      \field{title}{Practical problems in interim analyses, with particular regard to estimation}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{209\bibrangedash 221}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1016/0197-2456(89)90059-7
      \endverb
      \verb{file}
      \verb Pocock and Hughes - 1989 - Practical problems in interim analyses, with parti.pdf:/Users/pawel/Zotero/storage/QB3HUWB9/Pocock and Hughes - 1989 - Practical problems in interim analyses, with parti.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/0197245689900597
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/0197245689900597
      \endverb
    \endentry
    \entry{porschmann_spherical_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=3f462ed5d0345dfd7827690f8a2f09b0}{%
           family={Pörschmann},
           familyi={P\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=30e04e0e75a0808329faeec6bd13e328}{%
           family={Arend},
           familyi={A\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=3a1c97076f4883503f752159d27936bc}{%
           family={Neidhardt},
           familyi={N\bibinitperiod},
           given={Annika},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{5d7752b4a43e98d9fcd7e4cfe5de4512}
      \strng{fullhash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{bibnamehash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{authorbibnamehash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{authornamehash}{5d7752b4a43e98d9fcd7e4cfe5de4512}
      \strng{authorfullhash}{a7ed40f485293df8c57f781d2d0e0435}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Head-related transfer functions ({HRTFs}) describe the directional filtering caused by the head, pinna, and torso and are an essential component of binaural synthesis systems. Currently most of these systems are based on far-field {HRTFs} and thus do not consider acoustical specifics of nearby sound sources. One reason might be that full spherical near-field {HRTF} sets are rarely available. In this paper we present an {HRTF} set of a Neumann {KU}100 dummy head and a technical evaluation of the set. The set is freely available for download and contains post-processed impulse responses, captured on a circular and full spherical grid at distances between 0.25 m and 1.50 m. It can be used for psychoacoustic research and for applications where nearby virtual sound sources shall be auralized. Engineering Brief 322 http://www.aes.org/e-lib/browse.cfm?elib=18697}
      \field{day}{21}
      \field{month}{5}
      \field{title}{A Spherical Near-Field {HRTF} Set for Auralization and Psychoacoustic Research}
      \field{year}{2017}
      \field{dateera}{ce}
    \endentry
    \entry{raake_computational_2016}{software}{}
      \name{author}{1}{}{%
        {{hash=2ce4c604978ac9c6ebe8ba1ccfbc5115}{%
           family={Raake},
           familyi={R\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{fullhash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{bibnamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authorbibnamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authornamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authorfullhash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{shorttitle}{Two!Eears}
      \field{title}{A computational framework for modelling active exploratory listening that assigns meaning to auditory scenes—reading the world with two ears}
      \field{urlday}{11}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Two!Ears - Project:/Users/pawel/Zotero/storage/ZNPGKEQD/project.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://twoears.eu/project/
      \endverb
      \verb{url}
      \verb http://twoears.eu/project/
      \endverb
    \endentry
    \entry{rumsey_spatial_2002}{article}{}
      \name{author}{1}{}{%
        {{hash=28f5fb444dbefd9ef75d97d49e2e7a11}{%
           family={Rumsey},
           familyi={R\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{fullhash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{bibnamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authorbibnamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authornamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authorfullhash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Spatial quality in reproduced sound is a subset of the broad topic of sound quality. In the past it has been studied less rigorously than other aspects of reproduced sound quality, leading to a lack of clarity in standard definitions of subjective attributes. Rigor in the physical measurement of sound signals should be matched by equal rigor in semantics relating to subjective evaluation. A scene-based paradigm for the description and assessment of spatial quality is described, which enables clear distinctions to be made between elements of a reproduced sound scene and will assist in the search for related physical parameters.}
      \field{day}{1}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{month}{9}
      \field{shortjournal}{Journal of the Audio Engineering Society}
      \field{shorttitle}{Spatial Quality Evaluation for Reproduced Sound}
      \field{title}{Spatial Quality Evaluation for Reproduced Sound: Terminology, Meaning, and a Scene-Based Paradigm}
      \field{volume}{50}
      \field{year}{2002}
      \field{dateera}{ce}
      \field{pages}{651\bibrangedash 666}
      \range{pages}{16}
    \endentry
    \entry{sainath_deep_2013}{article}{}
      \name{author}{4}{}{%
        {{hash=28a3d000e5cd60656250014708db8ec1}{%
           family={Sainath},
           familyi={S\bibinitperiod},
           given={Tara\bibnamedelima N.},
           giveni={T\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=0d87a656f9bdc99e921c45f73da515b8}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdel-rahman},
           giveni={A\bibinithyphendelim r\bibinitperiod}}}%
        {{hash=8f101126b3acf3a5a0f51d86f0fe89b8}{%
           family={Kingsbury},
           familyi={K\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=e958692c2ffac06aacd0b29bb1482fc8}{%
           family={Ramabhadran},
           familyi={R\bibinitperiod},
           given={Bhuvana},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Vancouver, {BC}, Canada}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{217b1453ee030fd4f6f9f33e942041bd}
      \strng{fullhash}{673a11632a92363541f683dee595e107}
      \strng{bibnamehash}{673a11632a92363541f683dee595e107}
      \strng{authorbibnamehash}{673a11632a92363541f683dee595e107}
      \strng{authornamehash}{217b1453ee030fd4f6f9f33e942041bd}
      \strng{authorfullhash}{673a11632a92363541f683dee595e107}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Convolutional Neural Networks ({CNNs}) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, {CNNs} are a more effective model for speech compared to Deep Neural Networks ({DNNs}). In this paper, we explore applying {CNNs} to large vocabulary speech tasks. First, we determine the appropriate architecture to make {CNNs} effective compared to {DNNs} for {LVCSR} tasks. Speciﬁcally, we focus on how many convolutional layers are needed, what is the optimal number of hidden units, what is the best pooling strategy, and the best input feature type for {CNNs}. We then explore the behavior of neural network features extracted from {CNNs} on a variety of {LVCSR} tasks, comparing {CNNs} to {DNNs} and {GMMs}. We ﬁnd that {CNNs} offer between a 13-30\% relative improvement over {GMMs}, and a 4-12\% relative improvement over {DNNs}, on a 400-hr Broadcast News and 300-hr Switchboard task.}
      \field{eventtitle}{{ICASSP} 2013 - 2013 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{isbn}{978-1-4799-0356-6}
      \field{journaltitle}{2013 {IEEE} International Conference on Acoustics, Speech and Signal Processing}
      \field{langid}{english}
      \field{month}{5}
      \field{title}{Deep convolutional neural networks for {LVCSR}}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{8614\bibrangedash 8618}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2013.6639347
      \endverb
      \verb{file}
      \verb Sainath et al. - 2013 - Deep convolutional neural networks for LVCSR.pdf:/Users/pawel/Zotero/storage/VPCY5FCK/Sainath et al. - 2013 - Deep convolutional neural networks for LVCSR.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6639347/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6639347/
      \endverb
    \endentry
    \entry{senior_mixing_2023}{online}{}
      \name{author}{1}{}{%
        {{hash=9e061e8b013f909e23acd61a09283bba}{%
           family={Senior},
           familyi={S\bibinitperiod},
           given={Mike},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{fullhash}{9e061e8b013f909e23acd61a09283bba}
      \strng{bibnamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authorbibnamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authornamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authorfullhash}{9e061e8b013f909e23acd61a09283bba}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Music recording repository}
      \field{title}{The 'Mixing Secrets' Free Multitrack Download Library}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb The 'Mixing Secrets' Free Multitrack Download Library:/home/pawel/Zotero/storage/C6X26KMY/mtk.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://cambridge-mt.com/ms/mtk/
      \endverb
      \verb{url}
      \verb https://cambridge-mt.com/ms/mtk/
      \endverb
    \endentry
    \entry{shafiee_deep_2016}{article}{}
      \name{author}{3}{}{%
        {{hash=ef3a8fc81a4a7c94dc7f847b2acaac7a}{%
           family={Shafiee},
           familyi={S\bibinitperiod},
           given={Mohammad\bibnamedelima Javad},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=c26b812b70e0f680cfd787bce19ce677}{%
           family={Mishra},
           familyi={M\bibinitperiod},
           given={Akshaya\bibnamedelima Kumar},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=323f171aa619b4a38b71f29bc7608261}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{f39b83ba0ced09aa5f98c27216da1625}
      \strng{fullhash}{dadca4a43c74d58400fd62408e726275}
      \strng{bibnamehash}{dadca4a43c74d58400fd62408e726275}
      \strng{authorbibnamehash}{dadca4a43c74d58400fd62408e726275}
      \strng{authornamehash}{f39b83ba0ced09aa5f98c27216da1625}
      \strng{authorfullhash}{dadca4a43c74d58400fd62408e726275}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Neural Processing Letters}
      \field{title}{Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks}
      \field{volume}{48}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{pages}{603\bibrangedash 613}
      \range{pages}{11}
      \verb{file}
      \verb Shafiee et al. - 2017 - Deep Learning with Darwin Evolutionary Synthesis .pdf:/home/pawel/Zotero/storage/8DVHJEJP/Shafiee et al. - 2017 - Deep Learning with Darwin Evolutionary Synthesis .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:8106771
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:8106771
      \endverb
    \endentry
    \entry{spagnol_viking_2019}{article}{}
      \name{author}{4}{}{%
        {{hash=8f15119fd3a0cd98fd0a5caa95280a64}{%
           family={Spagnol},
           familyi={S\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
        {{hash=84e308ec54121553762a47530bfc1049}{%
           family={Purkhús},
           familyi={P\bibinitperiod},
           given={Kristján\bibnamedelima Bjarki},
           giveni={K\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=3113cf33f941597ff346efc2ebdbeb6a}{%
           family={Unnthórsson},
           familyi={U\bibinitperiod},
           given={Rúnar},
           giveni={R\bibinitperiod}}}%
        {{hash=d12aa906b87c8ab46f44480f545bf962}{%
           family={Björnsson},
           familyi={B\bibinitperiod},
           given={Sverrir\bibnamedelima Karl},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{fullhash}{76cac25650a0a227f54918f87b8f930b}
      \strng{bibnamehash}{76cac25650a0a227f54918f87b8f930b}
      \strng{authorbibnamehash}{76cac25650a0a227f54918f87b8f930b}
      \strng{authornamehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{authorfullhash}{76cac25650a0a227f54918f87b8f930b}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes the Viking {HRTF} dataset, a collection of head-related transfer functions ({HRTFs}) measured at the University of Iceland. The dataset includes fullsphere {HRTFs} measured on a dense spatial grid (1513 positions) with a {KEMAR} mannequin with 20 different artiﬁcial left pinnae attached, one at a time. The artiﬁcial pinnae were previously obtained through a custom molding procedure from 20 different lifelike human heads. The analyses of results reported here suggest that the collected acoustical measurements are robust, reproducible, and faithful to reference {KEMAR} {HRTFs}, and that material hardness has a negligible impact on the measurements compared to pinna shape. The purpose of the present collection, which is available for free download, is to provide accurate input data for future investigations on the relation between {HRTFs} and anthropometric data through machine learning techniques or other state-of-the-art methodologies.}
      \field{langid}{english}
      \field{title}{{THE} {VIKING} {HRTF} {DATASET}}
      \field{year}{2019}
      \field{dateera}{ce}
      \verb{file}
      \verb Spagnol et al. - THE VIKING HRTF DATASET.pdf:/Users/pawel/Zotero/storage/58JKR5Y6/Spagnol et al. - THE VIKING HRTF DATASET.pdf:application/pdf
      \endverb
    \endentry
    \entry{spagnol_viking_2020}{article}{}
      \name{author}{3}{}{%
        {{hash=8f15119fd3a0cd98fd0a5caa95280a64}{%
           family={Spagnol},
           familyi={S\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
        {{hash=d25396b244a57d3e2dc694a2ea4583dc}{%
           family={Miccini},
           familyi={M\bibinitperiod},
           given={Riccardo},
           giveni={R\bibinitperiod}}}%
        {{hash=7199e3a9f216c59a5316c586e01ce692}{%
           family={Unnthorsson},
           familyi={U\bibinitperiod},
           given={Runar},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{fullhash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{bibnamehash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{authorbibnamehash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{authornamehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{authorfullhash}{91e03d1b7af2b20377effa7aa2f3d450}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{The Viking {HRTF} Dataset v2}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Spagnol et al. - The Viking HRTF Dataset v2.pdf:/Users/pawel/Zotero/storage/HSJ5D7ZM/Spagnol et al. - The Viking HRTF Dataset v2.pdf:application/pdf
      \endverb
    \endentry
    \entry{srivastava_dropout_2014}{article}{}
      \name{author}{5}{}{%
        {{hash=6a147afa4569ce6cf23c0436e65d8486}{%
           family={Srivastava},
           familyi={S\bibinitperiod},
           given={Nitish},
           giveni={N\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{fullhash}{2850768171a28ccacd146c300f66f57d}
      \strng{bibnamehash}{2850768171a28ccacd146c300f66f57d}
      \strng{authorbibnamehash}{2850768171a28ccacd146c300f66f57d}
      \strng{authornamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorfullhash}{2850768171a28ccacd146c300f66f57d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{56}
      \field{title}{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}
      \field{volume}{15}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{pages}{1929\bibrangedash 1958}
      \range{pages}{30}
      \verb{urlraw}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
    \endentry
    \entry{stanley_evolving_2002}{article}{}
      \name{author}{2}{}{%
        {{hash=cd20c341249f4e0cd9cb16431e439823}{%
           family={Stanley},
           familyi={S\bibinitperiod},
           given={Kenneth\bibnamedelima O.},
           giveni={K\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=70ad9af6f97993f2ea5c1f65e1985520}{%
           family={Miikkulainen},
           familyi={M\bibinitperiod},
           given={Risto},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{fullhash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{bibnamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authorbibnamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authornamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authorfullhash}{3546041f24ccbba148011c7ca7e4a95c}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, {NeuroEvolution} of Augmenting Topologies ({NEAT}), which outperforms the best ﬁxed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efﬁciency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is signiﬁcantly faster learning. {NEAT} is also an important contribution to {GAs} because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.}
      \field{issn}{1063-6560, 1530-9304}
      \field{journaltitle}{Evolutionary Computation}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{2}
      \field{shortjournal}{Evolutionary Computation}
      \field{title}{Evolving Neural Networks through Augmenting Topologies}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2002}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{99\bibrangedash 127}
      \range{pages}{29}
      \verb{doi}
      \verb 10.1162/106365602320169811
      \endverb
      \verb{file}
      \verb Stanley and Miikkulainen - 2002 - Evolving Neural Networks through Augmenting Topolo.pdf:/Users/pawel/Zotero/storage/TWUN8YPM/Stanley and Miikkulainen - 2002 - Evolving Neural Networks through Augmenting Topolo.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://direct.mit.edu/evco/article/10/2/99-127/1123
      \endverb
      \verb{url}
      \verb https://direct.mit.edu/evco/article/10/2/99-127/1123
      \endverb
    \endentry
    \entry{MATLAB_Audio_Toolbox}{software}{}
      \name{author}{1}{}{%
        {{hash=8687eae34a3830fc0c113d9d65382e90}{%
           family={{The MathWorks Inc.}},
           familyi={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Natick, Massachusetts, United States}%
      }
      \strng{namehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{fullhash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{bibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorbibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authornamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorfullhash}{8687eae34a3830fc0c113d9d65382e90}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradate}{1}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Audio Toolbox version: 9.13.0 (R2022b)}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.mathworks.com
      \endverb
      \verb{url}
      \verb https://www.mathworks.com
      \endverb
    \endentry
    \entry{MATLAB}{software}{}
      \name{author}{1}{}{%
        {{hash=8687eae34a3830fc0c113d9d65382e90}{%
           family={{The MathWorks Inc.}},
           familyi={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Natick, Massachusetts, United States}%
      }
      \strng{namehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{fullhash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{bibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorbibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authornamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorfullhash}{8687eae34a3830fc0c113d9d65382e90}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradate}{2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{MATLAB version: 9.13.0 (R2022b)}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.mathworks.com
      \endverb
      \verb{url}
      \verb https://www.mathworks.com
      \endverb
    \endentry
    \entry{thiemann_speech_2016}{article}{}
      \name{author}{5}{}{%
        {{hash=1f5ffdd0f478e16fd042ef7d550cc264}{%
           family={Thiemann},
           familyi={T\bibinitperiod},
           given={Joachim},
           giveni={J\bibinitperiod}}}%
        {{hash=28c765657da3a93ef91cad6817ebab3f}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Menno},
           giveni={M\bibinitperiod}}}%
        {{hash=fc3f4e6ea75c65c0ab0fbe963d608418}{%
           family={Marquardt},
           familyi={M\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=dd004cfd0c0feeb261ad0f703e2bbc8c}{%
           family={Doclo},
           familyi={D\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
      }
      \strng{namehash}{b6c6be5145f8265399211b85b86f06d3}
      \strng{fullhash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{bibnamehash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{authorbibnamehash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{authornamehash}{b6c6be5145f8265399211b85b86f06d3}
      \strng{authorfullhash}{617c87d8c04985002c1c4d5a637ed37b}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Modern binaural hearing aids utilize multimicrophone speech enhancement algorithms to enhance signals in terms of signal-to-noise ratio, but they may distort the interaural cues that allow the user to localize sources, in particular, suppressed interfering sources or background noise. In this paper, we present a novel algorithm that enhances the target signal while aiming to maintain the correct spatial rendering of both the target signal as well as the background noise. We use a bimodal approach, where a signal-to-noise ratio (SNR) estimator controls a binary decision mask, switching between the output signals of a binaural minimum variance distortionless response (MVDR) beamformer and scaled reference microphone signals. We show that the proposed selective binaural beamformer (SBB) can enhance the target signal while maintaining the overall spatial rendering of the acoustic scene.}
      \field{issn}{1687-6180}
      \field{journaltitle}{EURASIP Journal on Advances in Signal Processing}
      \field{month}{2}
      \field{number}{1}
      \field{title}{Speech enhancement for multimicrophone binaural hearing aids aiming to preserve the spatial auditory scene}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2016}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{12}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13634-016-0314-6
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/HK2UGN3E/Thiemann et al. - 2016 - Speech enhancement for multimicrophone binaural he.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/MPJJ7SUT/s13634-016-0314-6.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13634-016-0314-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13634-016-0314-6
      \endverb
      \keyw{Bilateral hearing aids,Binaural hearing aids,Binaural MVDR,Hearing aids}
    \endentry
    \entry{thomas_analyzing_2014}{article}{}
      \name{author}{4}{}{%
        {{hash=0a327007a0b097a2d8bfa1b4eb2086d1}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod}}}%
        {{hash=e8ffe1c362ac7ce7c88ccafa53a92285}{%
           family={Ganapathy},
           familyi={G\bibinitperiod},
           given={Sriram},
           giveni={S\bibinitperiod}}}%
        {{hash=ce2fc3785ea81b5ffeca97427d45bbab}{%
           family={Saon},
           familyi={S\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=b20d63e6bf6d2e637b4f5915a4accb2f}{%
           family={Soltau},
           familyi={S\bibinitperiod},
           given={Hagen},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Florence, Italy}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{7c9d94120dea55e4ba058bbef333f39d}
      \strng{fullhash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{bibnamehash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{authorbibnamehash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{authornamehash}{7c9d94120dea55e4ba058bbef333f39d}
      \strng{authorfullhash}{c1dc657ec4b58b8289ba2098adba0488}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Convolutional neural networks ({CNN}) are extensions to deep neural networks ({DNN}) which are used as alternate acoustic models with state-of-the-art performances for speech recognition. In this paper, {CNNs} are used as acoustic models for speech activity detection ({SAD}) on data collected over noisy radio communication channels. When these {SAD} models are tested on audio recorded from radio channels not seen during training, there is severe performance degradation. We attribute this degradation to mismatches between the two dimensional ﬁlters learnt in the initial {CNN} layers and the novel channel data. Using a small amount of supervised data from the novel channels, the ﬁlters can be adapted to provide signiﬁcant improvements in {SAD} performance. In mismatched acoustic conditions, the adapted models provide signiﬁcant improvements (about 10-25\%) relative to conventional {DNN}-based {SAD} systems. These results illustrate that {CNNs} have a considerable advantage in fast adaptation for acoustic modeling in these settings.}
      \field{eventtitle}{{ICASSP} 2014 - 2014 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{isbn}{978-1-4799-2893-4}
      \field{journaltitle}{2014 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{langid}{english}
      \field{month}{5}
      \field{title}{Analyzing convolutional neural networks for speech activity detection in mismatched acoustic conditions}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2519\bibrangedash 2523}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2014.6854054
      \endverb
      \verb{file}
      \verb Thomas et al. - 2014 - Analyzing convolutional neural networks for speech.pdf:/Users/pawel/Zotero/storage/RAIR3LKP/Thomas et al. - 2014 - Analyzing convolutional neural networks for speech.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6854054/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6854054/
      \endverb
    \endentry
    \entry{python}{book}{}
      \name{author}{2}{}{%
        {{hash=e504145eff12cd8803c227c919ccfacd}{%
           family={Van\bibnamedelima Rossum},
           familyi={V\bibinitperiod\bibinitdelim R\bibinitperiod},
           given={Guido},
           giveni={G\bibinitperiod}}}%
        {{hash=0b735fb6ad359aa95b3bac4d5567af6f}{%
           family={Drake},
           familyi={D\bibinitperiod},
           given={Fred\bibnamedelima L.},
           giveni={F\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Scotts Valley, CA}%
      }
      \list{publisher}{1}{%
        {CreateSpace}%
      }
      \strng{namehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{fullhash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{bibnamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authorbibnamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authornamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authorfullhash}{190e2e6e0d73bf5671d8927d221674e7}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{1441412697}
      \field{title}{Python 3 Reference Manual}
      \field{year}{2009}
    \endentry
    \entry{vecchiotti_end--end_2019}{article}{}
      \name{author}{4}{}{%
        {{hash=dd2688b271dbbecf993a80c6a385c9b2}{%
           family={Vecchiotti},
           familyi={V\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=a2f00650504fc0bb5efb1ec394adbaa4}{%
           family={Squartini},
           familyi={S\bibinitperiod},
           given={Stefano},
           giveni={S\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{c41b65bcb2cf677a54f2d74dc2937514}
      \strng{fullhash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{bibnamehash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{authorbibnamehash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{authornamehash}{c41b65bcb2cf677a54f2d74dc2937514}
      \strng{authorfullhash}{cc087543c1a49a288ee1cffbe889f286}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{title}{End-to-end Binaural Sound Localisation from the Raw Waveform}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{pages}{451\bibrangedash 455}
      \range{pages}{5}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/73M9MTKE/Vecchiotti et al. - 2019 - End-to-end Binaural Sound Localisation from the Ra.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:102481341
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:102481341
      \endverb
    \endentry
    \entry{vera-diaz_towards_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=2f436749ac56ef83f981f1f136ac6ab8}{%
           family={Vera-Diaz},
           familyi={V\bibinithyphendelim D\bibinitperiod},
           given={Juan\bibnamedelima Manuel},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=688214d07bf58f2c70a1687eb96b152c}{%
           family={Pizarro},
           familyi={P\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=da7e2e93106543998c55fdde339f7460}{%
           family={Macias-Guarasa},
           familyi={M\bibinithyphendelim G\bibinitperiod},
           given={Javier},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{c4883035c38b3126265735ffe52e988a}
      \strng{fullhash}{66cad649c3e2462c3be1928092d78848}
      \strng{bibnamehash}{66cad649c3e2462c3be1928092d78848}
      \strng{authorbibnamehash}{66cad649c3e2462c3be1928092d78848}
      \strng{authornamehash}{c4883035c38b3126265735ffe52e988a}
      \strng{authorfullhash}{66cad649c3e2462c3be1928092d78848}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a novel approach for indoor acoustic source localization using microphone arrays, based on a Convolutional Neural Network ({CNN}). In the proposed solution, the {CNN} is designed to directly estimate the three-dimensional position of a single acoustic source using the raw audio signal as the input information and avoiding the use of hand-crafted audio features. Given the limited amount of available localization data, we propose, in this paper, a training strategy based on two steps. We first train our network using semi-synthetic data generated from close talk speech recordings. We simulate the time delays and distortion suffered in the signal that propagate from the source to the array of microphones. We then fine tune this network using a small amount of real data. Our experimental results, evaluated on a publicly available dataset recorded in a real room, show that this approach is able to produce networks that significantly improve existing localization methods based on {SRP}-{PHAT} strategies and also those presented in very recent proposals based on Convolutional Recurrent Neural Networks ({CRNN}). In addition, our experiments show that the performance of our {CNN} method does not show a relevant dependency on the speaker’s gender, nor on the size of the signal window being used.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{langid}{english}
      \field{month}{10}
      \field{note}{Number: 10 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{10}
      \field{shorttitle}{Towards End-to-End Acoustic Localization Using Deep Learning}
      \field{title}{Towards End-to-End Acoustic Localization Using Deep Learning: From Audio Signals to Source Position Coordinates}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{18}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3418}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/s18103418
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/QWRE2HZA/Vera-Diaz et al. - 2018 - Towards End-to-End Acoustic Localization Using Dee.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/18/10/3418
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/18/10/3418
      \endverb
      \keyw{convolutional neural networks,deep learning,acoustic source localization,microphone arrays}
    \endentry
    \entry{2020SciPy-NMeth}{article}{}
      \name{author}{35}{}{%
        {{hash=18703a2bb6a62484483c193a212da2f8}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Pauli},
           giveni={P\bibinitperiod}}}%
        {{hash=646fbfe08374cc41c2f9bd971d8c4725}{%
           family={Gommers},
           familyi={G\bibinitperiod},
           given={Ralf},
           giveni={R\bibinitperiod}}}%
        {{hash=d500f4849030f34359cdb3e1513acf83}{%
           family={Oliphant},
           familyi={O\bibinitperiod},
           given={Travis\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=35bb9c71f55048509a3e9018c349ed73}{%
           family={Haberland},
           familyi={H\bibinitperiod},
           given={Matt},
           giveni={M\bibinitperiod}}}%
        {{hash=fbb0c40f5d70be8ce47ce9daafdf5749}{%
           family={Reddy},
           familyi={R\bibinitperiod},
           given={Tyler},
           giveni={T\bibinitperiod}}}%
        {{hash=9fd9ed8466bbb96364ae008f2a665e6e}{%
           family={Cournapeau},
           familyi={C\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=09a667aa6a26526bfcccb2676a494e55}{%
           family={Burovski},
           familyi={B\bibinitperiod},
           given={Evgeni},
           giveni={E\bibinitperiod}}}%
        {{hash=3d6efaaa3d9682e20787eb06ff70a3d7}{%
           family={Peterson},
           familyi={P\bibinitperiod},
           given={Pearu},
           giveni={P\bibinitperiod}}}%
        {{hash=4c7e4c94b846fa41e2fc0a88e0dc656d}{%
           family={Weckesser},
           familyi={W\bibinitperiod},
           given={Warren},
           giveni={W\bibinitperiod}}}%
        {{hash=7447cb057596bc2645d3980bb04f5c78}{%
           family={Bright},
           familyi={B\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=1b5d87f5a394ee92a6edb4c1de058cab}{%
           family={{van der Walt}},
           familyi={v\bibinitperiod},
           given={Stéfan\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=626cc151613864abeb653c0d8172d98c}{%
           family={Brett},
           familyi={B\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=57849e8550281b202bd611bf6f11e14b}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Joshua},
           giveni={J\bibinitperiod}}}%
        {{hash=b053969d2c6a9ec8689980fb6463cd56}{%
           family={Millman},
           familyi={M\bibinitperiod},
           given={K.\bibnamedelimi Jarrod},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=fbaf80580622bd40577f4a6d38021c0a}{%
           family={Mayorov},
           familyi={M\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod}}}%
        {{hash=7bcf847eaccba039f7a4523540673aea}{%
           family={Nelson},
           familyi={N\bibinitperiod},
           given={Andrew\bibnamedelimb R.\bibnamedelimi J.},
           giveni={A\bibinitperiod\bibinitdelim R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=4b3d26f886661aa723985bcfd835ba18}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=9ad1d38817acd2f00cb7f324ec7d37ea}{%
           family={Kern},
           familyi={K\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=8d336f110675c46226ece1db501ce712}{%
           family={Larson},
           familyi={L\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=65b1934a87acb0abe09c469aaf11c326}{%
           family={Carey},
           familyi={C\bibinitperiod},
           given={C\bibnamedelima J},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=9989e8a18827e34b15112d671f52bd35}{%
           family={Polat},
           familyi={P\bibinitperiod},
           given={İlhan},
           giveni={İ\bibinitperiod}}}%
        {{hash=b8b88d61c79de60e6e1b5d44e03f5dec}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=bf4be16325cb4f641345ca394443fd18}{%
           family={Moore},
           familyi={M\bibinitperiod},
           given={Eric\bibnamedelima W.},
           giveni={E\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=0fd9a0e34f1b2adda41357c948d14986}{%
           family={{VanderPlas}},
           familyi={V\bibinitperiod},
           given={Jake},
           giveni={J\bibinitperiod}}}%
        {{hash=c6a95a8ced3b86b4e7e60a74bc6ebf5a}{%
           family={Laxalde},
           familyi={L\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod}}}%
        {{hash=85242652d69220e83cf71ceb8d90a8cb}{%
           family={Perktold},
           familyi={P\bibinitperiod},
           given={Josef},
           giveni={J\bibinitperiod}}}%
        {{hash=5bca159e697db439e23b8947dfa4b614}{%
           family={Cimrman},
           familyi={C\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=70b659f5067a8a2efbee66f770681598}{%
           family={Henriksen},
           familyi={H\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=fa5163c76600eb11a4d07a28f0701cb0}{%
           family={Quintero},
           familyi={Q\bibinitperiod},
           given={E.\bibnamedelimi A.},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=db2b4761cc46be347b418e68660c9554}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Charles\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=7d86aea5ad1f2b4e27f2f014c71712c2}{%
           family={Archibald},
           familyi={A\bibinitperiod},
           given={Anne\bibnamedelima M.},
           giveni={A\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=3876f7c3dbbb1a17823dcd135d07cfc6}{%
           family={Ribeiro},
           familyi={R\bibinitperiod},
           given={Antônio\bibnamedelima H.},
           giveni={A\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=bab4e5caee2d67831e464ce575022b37}{%
           family={Pedregosa},
           familyi={P\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=8928c27c900ec0b05492cbba126c5196}{%
           family={{van Mulbregt}},
           familyi={v\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=aa8bf7a30651c7bc3d20ff02fc843dd9}{%
           family={{SciPy 1.0 Contributors}},
           familyi={S\bibinitperiod}}}%
      }
      \strng{namehash}{f252038edd7f112d75da3bf0c1edecbc}
      \strng{fullhash}{371a3f5cdbab4f8c68cab2e17d157950}
      \strng{bibnamehash}{0cdbee7bc557397e3e6f406a603f21f7}
      \strng{authorbibnamehash}{0cdbee7bc557397e3e6f406a603f21f7}
      \strng{authornamehash}{f252038edd7f112d75da3bf0c1edecbc}
      \strng{authorfullhash}{371a3f5cdbab4f8c68cab2e17d157950}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Nature Methods}
      \field{title}{{{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in Python}}
      \field{volume}{17}
      \field{year}{2020}
      \field{pages}{261\bibrangedash 272}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1038/s41592-019-0686-2
      \endverb
    \endentry
    \entry{wang_binaural_2020}{article}{}
      \name{author}{5}{}{%
        {{hash=49a19e08791a3dc09c932ff975949361}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod}}}%
        {{hash=57cf8531003f9d0c22b8a30358523ffc}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jin},
           giveni={J\bibinitperiod}}}%
        {{hash=81e718542697d8cb9b28022566aa3a73}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
        {{hash=e6a4eb28abe7c87f188cdfbca1e0d60b}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=74f843d34d0fc73c4784f6fb01462125}{%
           family={Kuang},
           familyi={K\bibinitperiod},
           given={Jingming},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{bb255b96d1bb6f677f7841b684efd08c}
      \strng{fullhash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{bibnamehash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{authorbibnamehash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{authornamehash}{bb255b96d1bb6f677f7841b684efd08c}
      \strng{authorfullhash}{9b8aa841b860cee3f7ee3708c718fd42}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Binaural sound source localization is an important and widely used perceptually based method and it has been applied to machine learning studies by many researchers based on head-related transfer function ({HRTF}). Because the {HRTF} is closely related to human physiological structure, the {HRTFs} vary between individuals. Related machine learning studies to date tend to focus on binaural localization in reverberant or noisy environments, or in conditions with multiple simultaneously active sound sources. In contrast, mismatched {HRTF} condition, in which the {HRTFs} used to generate the training and test sets are different, is rarely studied. This mismatch leads to a degradation of localization performance. A basic solution to this problem is to introduce more data to improve generalization performance, which requires a lot. However, simply increasing the data volume will result in data-inefficiency. In this paper, we propose a data-efficient method based on deep neural network ({DNN}) and clustering to improve binaural localization performance in the mismatched {HRTF} condition. Firstly, we analyze the relationship between binaural cues and the sound source localization with a classification {DNN}. Different {HRTFs} are used to generate training and test sets, respectively. On this basis, we study the localization performance of {DNN} model trained by each training set on different test sets. The result shows that the localization performance of the same model on different test sets is different, while the localization performance of different models on the same test set may be similar. The result also shows a clustering trend. Secondly, different {HRTFs} are divided into several clusters. Finally, the corresponding {HRTFs} of each cluster center are selected to generate a new training set and to train a more generalized {DNN} model. The experimental results show that the proposed method achieves better generalization performance than the baseline methods in the mismatched {HRTF} condition and has almost equal performance to the {DNN} trained with a large number of {HRTFs}, which means the proposed method is data-efficient.}
      \field{day}{10}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{month}{2}
      \field{number}{1}
      \field{shortjournal}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{title}{Binaural sound localization based on deep neural network and affinity propagation clustering in mismatched {HRTF} condition}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2020}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-020-0171-y
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/AXJ7NQJI/Wang et al. - 2020 - Binaural sound localization based on deep neural n.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/HXP2Q4IJ/s13636-020-0171-y.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13636-020-0171-y
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13636-020-0171-y
      \endverb
      \keyw{Affinity propagation,Binaural localization,Clustering,Deep neural network}
    \endentry
    \entry{watanabe_dataset_2014}{article}{}
      \name{author}{5}{}{%
        {{hash=e2cddc8be765eeab771c7cee269f7a0c}{%
           family={Watanabe},
           familyi={W\bibinitperiod},
           given={Kanji},
           giveni={K\bibinitperiod}}}%
        {{hash=100e04c7fb95463997399ecb8faf93ea}{%
           family={Iwaya},
           familyi={I\bibinitperiod},
           given={Yukio},
           giveni={Y\bibinitperiod}}}%
        {{hash=8746e9aeb5407651bfca91873dcf4d66}{%
           family={Suzuki},
           familyi={S\bibinitperiod},
           given={Yôiti},
           giveni={Y\bibinitperiod}}}%
        {{hash=2a79543e343d481672d9ce4aae3b248b}{%
           family={Takane},
           familyi={T\bibinitperiod},
           given={Shouichi},
           giveni={S\bibinitperiod}}}%
        {{hash=cf330fd18c81c9b809b81f5380e424ea}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Sojun},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{85f27c56550690dcdab68eeec123a1d7}
      \strng{fullhash}{ed1ff829f95686106003ddf865222379}
      \strng{bibnamehash}{ed1ff829f95686106003ddf865222379}
      \strng{authorbibnamehash}{ed1ff829f95686106003ddf865222379}
      \strng{authornamehash}{85f27c56550690dcdab68eeec123a1d7}
      \strng{authorfullhash}{ed1ff829f95686106003ddf865222379}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we describe a dataset of head-related transfer functions ({HRTFs}) measured at the Research Institute of Electrical Communications, Tohoku University. The current dataset includes {HRTFs} for 105 subjects at 72 azimuths Â 13 elevations of spherical coordinates. Anthropometric data for 39 subjects are also included. The measurement and postprocessing methods are outlined in this paper. These data will be freely accessible for nonproﬁt academic purposes via the Internet. Moreover, this dataset will be included in an international joint project to gather several {HRTF} datasets in a uniﬁed data format.}
      \field{issn}{1346-3969, 1347-5177}
      \field{journaltitle}{Acoustical Science and Technology}
      \field{langid}{english}
      \field{number}{3}
      \field{shortjournal}{Acoust. Sci. \& Tech.}
      \field{title}{Dataset of head-related transfer functions measured with a circular loudspeaker array}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{35}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{159\bibrangedash 165}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1250/ast.35.159
      \endverb
      \verb{file}
      \verb Watanabe et al. - 2014 - Dataset of head-related transfer functions measure.pdf:/Users/pawel/Zotero/storage/5TRRD52B/Watanabe et al. - 2014 - Dataset of head-related transfer functions measure.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.jstage.jst.go.jp/article/ast/35/3/35_E1368/_article
      \endverb
      \verb{url}
      \verb https://www.jstage.jst.go.jp/article/ast/35/3/35_E1368/_article
      \endverb
    \endentry
    \entry{wierstorf_free_2011}{article}{}
      \name{author}{4}{}{%
        {{hash=ea78b534b437498b9114de2c16a7bc2c}{%
           family={Wierstorf},
           familyi={W\bibinitperiod},
           given={Hagen},
           giveni={H\bibinitperiod}}}%
        {{hash=d747d219bd1d7019668b2219cf5f8bb2}{%
           family={Geier},
           familyi={G\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=2ce4c604978ac9c6ebe8ba1ccfbc5115}{%
           family={Raake},
           familyi={R\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=f9f8c9d3d45c27b5bb486e79b41d175a}{%
           family={Spors},
           familyi={S\bibinitperiod},
           given={Sascha},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{08484feb6b130f3073d0342d895a30ea}
      \strng{fullhash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{bibnamehash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{authorbibnamehash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{authornamehash}{08484feb6b130f3073d0342d895a30ea}
      \strng{authorfullhash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A freely available collection of Head-Related Impulse Response ({HRIR}) measurements is introduced. The impulse responses were acquired in an anechoic chamber using a {KEMAR} manikin at four diﬀerent loudspeaker distances – 3 m, 2 m, 1 m and 0.5 m – reaching from the far ﬁeld to the near ﬁeld. The loudspeaker was positioned at ear height and the manikin was rotated with a high-precision stepper motor in one degree increments. Besides the raw {HRIRs} also datasets are available which have been compensated for the use with speciﬁc headphone models.}
      \field{langid}{english}
      \field{title}{A Free Database of Head-Related Impulse Response Measurements in the Horizontal Plane with Multiple Distances}
      \field{year}{2011}
      \field{dateera}{ce}
      \verb{file}
      \verb Wierstorf et al. - 2011 - A Free Database of Head-Related Impulse Response M.pdf:/Users/pawel/Zotero/storage/A66C4WXR/Wierstorf et al. - 2011 - A Free Database of Head-Related Impulse Response M.pdf:application/pdf
      \endverb
    \endentry
    \entry{woodruff_binaural_2012}{article}{}
      \name{author}{2}{}{%
        {{hash=7d546bf7dc4d1dd29f8aa15f0a06bbff}{%
           family={Woodruff},
           familyi={W\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0a1bd97b59cb3cf65dc849873adf0d25}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={DeLiang},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{fullhash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{bibnamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authorbibnamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authornamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authorfullhash}{04534bf25b92e9e93d01c70d4417fda2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization from a binaural input is a challenging problem, particularly when multiple sources are active simultaneously and reverberation or background noise are present. In this work, we investigate a multi-source localization framework in which monaural source segregation is used as a mechanism to increase the robustness of azimuth estimates from a binaural input. We demonstrate performance improvement relative to binaural only methods assuming a known number of spatially stationary sources. We also propose a flexible azimuth-dependent model of binaural features that independently captures characteristics of the binaural setup and environmental conditions, allowing for adaptation to new environments or calibration to an unseen binaural setup. Results with both simulated and recorded impulse responses show that robust performance can be achieved with limited prior training.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{7}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{5}
      \field{title}{Binaural {Localization} of {Multiple} {Sources} in {Reverberant} and {Noisy} {Environments}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{1503\bibrangedash 1512}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASL.2012.2183869
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/9CW9FT7X/6129395.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6129395
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6129395
      \endverb
      \keyw{Adaptation models,Azimuth,Binaural sound localization,computational auditory scene analysis (CASA),Estimation,Feature extraction,monaural grouping,Noise measurement,reverberation,Reverberation,Time frequency analysis}
    \endentry
    \entry{yang_deepear_2022}{article}{}
      \name{author}{2}{}{%
        {{hash=55242d2a60270145342841e4d4238da0}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=124d6abeaddbcd28f90e637a266faed6}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Yuanqing},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{fullhash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{bibnamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authorbibnamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authornamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authorfullhash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Binaural microphones, referring to two microphones with artificial human-shaped ears, are pervasively used in humanoid robots and hearing aids improving sound quality. In many applications, it is crucial for such robots to interact with humans by finding the voice direction. However, sound source localization with binaural microphones remains challenging, especially in multi-source scenarios. Prior works utilize microphone arrays to deal with the multi-source localization problem. Extra arrays yet incur higher deployment costs and take up more space. However, human brains have evolved to locate multiple sound sources with only two ears. Inspired by this fact, we propose DeepEar, a binaural microphone-based localization system that can locate multiple sounds. To this end, we develop a neural network to mimic the acoustic signal processing pipeline of the human auditory system. Different from hand-crafted features used in prior works, DeepEar can automatically extract useful features for localization. More importantly, the trained neural networks can be extended and adapted to new environments with a minimum amount of extra training data. Experiment results show that DeepEar can substantially outperform the state-of-the-art deep learning approach, with a sound detection accuracy of 93.3\% and an azimuth estimation error of 7.4 degrees in multisource scenarios.}
      \field{journaltitle}{{IEEE} {INFOCOM} 2022 - {IEEE} {Conference} on {Computer} {Communications}}
      \field{month}{5}
      \field{note}{ISSN: 2641-9874}
      \field{shorttitle}{{DeepEar}}
      \field{title}{{DeepEar}: {Sound} {Localization} with {Binaural} {Microphones}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \field{pages}{960\bibrangedash 969}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/INFOCOM48880.2022.9796850
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/IN9CQI5D/9796850.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9796850
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9796850
      \endverb
      \keyw{Auditory system,Binaural localization,Deep learning,Ear,Earable computing,Feature extraction,Location awareness,Multi-source localization,Training data,Transfer learning}
    \endentry
    \entry{yu_near-field_2018}{article}{}
      \name{author}{4}{}{%
        {{hash=6d7b4f7bd9d585630f805592564163ea}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Guangzheng},
           giveni={G\bibinitperiod}}}%
        {{hash=de022b50859cc45f0a667828b655f5a9}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Ruixing},
           giveni={R\bibinitperiod}}}%
        {{hash=93c82128aca25c57cfb17e90d02136d5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=6a7c0aeaee82d36dc36bda3cbe6df178}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Bosun},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{e2925dc79d25212c49ec479f617e3db7}
      \strng{fullhash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{bibnamehash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{authorbibnamehash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{authornamehash}{e2925dc79d25212c49ec479f617e3db7}
      \strng{authorfullhash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Near-ﬁeld head-related transfer functions ({HRTFs}) of human subjects are essential to those researching spatial hearing. By using a carefully designed measurement system, near-ﬁeld {HRTFs} of human subjects were measured and a database was constructed. The database includes 56 Chinese human subjects, seven source distances from 0.2 to 1.0 m, and 685 directions at each distance for each subject. In the present work, the technique of near-ﬁeld {HRTF} measurement is outlined, the performance of the measurement system is assessed and validated, and the resultant database is reported. The database can provide fundamental data for future research.}
      \field{day}{1}
      \field{issn}{0001-4966, 1520-8524}
      \field{journaltitle}{The Journal of the Acoustical Society of America}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{3}
      \field{title}{Near-field head-related transfer-function measurement and database of human subjects}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{143}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{EL194\bibrangedash EL198}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1121/1.5027019
      \endverb
      \verb{file}
      \verb Yu et al. - 2018 - Near-field head-related transfer-function measurem.pdf:/Users/pawel/Zotero/storage/U66CIAPL/Yu et al. - 2018 - Near-field head-related transfer-function measurem.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://pubs.aip.org/jasa/article/143/3/EL194/609761/Near-field-head-related-transfer-function
      \endverb
      \verb{url}
      \verb https://pubs.aip.org/jasa/article/143/3/EL194/609761/Near-field-head-related-transfer-function
      \endverb
    \endentry
    \entry{zhang_finding_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=ebc15088b58cb9590a0800452d89d813}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Honglei},
           giveni={H\bibinitperiod}}}%
        {{hash=88fcbfc7f3b82fa8bcc91190c133d9f0}{%
           family={Kiranyaz},
           familyi={K\bibinitperiod},
           given={Serkan},
           giveni={S\bibinitperiod}}}%
        {{hash=db18464e8dc36880c4cad237f133c939}{%
           family={Gabbouj},
           familyi={G\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{390ff0787732875904593a9006891cf1}
      \strng{fullhash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{bibnamehash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{authorbibnamehash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{authornamehash}{390ff0787732875904593a9006891cf1}
      \strng{authorfullhash}{d33aed6d23ec7a975cf5c1279adc6076}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Finding Better Topologies for Deep Convolutional Neural Networks by Evolution}
      \field{volume}{abs/1809.03242}
      \field{year}{2018}
      \field{dateera}{ce}
      \verb{file}
      \verb Zhang et al. - 2018 - Finding Better Topologies for Deep Convolutional N.pdf:/home/pawel/Zotero/storage/VEYS75L8/Zhang et al. - 2018 - Finding Better Topologies for Deep Convolutional N.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:52182383
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:52182383
      \endverb
    \endentry
    \entry{zhang_surround_2017}{article}{}
      \name{author}{4}{}{%
        {{hash=3fa0b98bdb0330cc0ea22e655fd964c2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod}}}%
        {{hash=9ade3cb1e0a7e8284fca38d3e90135c2}{%
           family={Samarasinghe},
           familyi={S\bibinitperiod},
           given={Parasanga\bibnamedelima N.},
           giveni={P\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=71fbb76b73ac3e704b70533e80605c2e}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Hanchi},
           giveni={H\bibinitperiod}}}%
        {{hash=63baacfeb0128db6195531efd5b55099}{%
           family={Abhayapala},
           familyi={A\bibinitperiod},
           given={Thushara\bibnamedelima D.},
           giveni={T\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{6842b5fbca42689fb0276e5d0ca4a2a4}
      \strng{fullhash}{13f666b838cdf981966802da926757e8}
      \strng{bibnamehash}{13f666b838cdf981966802da926757e8}
      \strng{authorbibnamehash}{13f666b838cdf981966802da926757e8}
      \strng{authornamehash}{6842b5fbca42689fb0276e5d0ca4a2a4}
      \strng{authorfullhash}{13f666b838cdf981966802da926757e8}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this article, a systematic overview of various recording and reproduction techniques for spatial audio is presented. While binaural recording and rendering is designed to resemble the human two-ear auditory system and reproduce sounds specifically for a listener’s two ears, soundfield recording and reproduction using a large number of microphones and loudspeakers replicate an acoustic scene within a region. These two fundamentally different types of techniques are discussed in the paper. A recent popular area, multi-zone reproduction, is also briefly reviewed in the paper. The paper is concluded with a discussion of the current state of the field and open problems.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{month}{5}
      \field{note}{Number: 5 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{5}
      \field{shorttitle}{Surround by {Sound}}
      \field{title}{Surround by {Sound}: {A} {Review} of {Spatial} {Audio} {Recording} and {Reproduction}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{7}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{532}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app7050532
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/8AJ5DLMH/Zhang et al. - 2017 - Surround by Sound A Review of Spatial Audio Recor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/7/5/532
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/7/5/532
      \endverb
      \keyw{binaural recording,binaural rendering,multi-zone reproduction,soundfield recording,soundfield reproduction,spatial audio}
    \endentry
    \entry{zielinski_comparison_2020}{article}{}
      \name{author}{4}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=4646616032fe7363c0b456e94407a61f}{%
           family={Dadan},
           familyi={D\bibinitperiod},
           given={Oskar},
           giveni={O\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{bibnamehash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{authorbibnamehash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{24da28f4ac8efc816b4e64b8ba826d17}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The purpose of this paper is to compare the performance of human listeners against the selected machine learning algorithms in the task of the classification of spatial audio scenes in binaural recordings of music under practical conditions. The three scenes were subject to classification: (1) music ensemble (a group of musical sources) located in the front, (2) music ensemble located at the back, and (3) music ensemble distributed around a listener. In the listening test, undertaken remotely over the Internet, human listeners reached the classification accuracy of 42.5\%. For the listeners who passed the post-screening test, the accuracy was greater, approaching 60\%. The above classification task was also undertaken automatically using four machine learning algorithms: convolutional neural network, support vector machines, extreme gradient boosting framework, and logistic regression. The machine learning algorithms substantially outperformed human listeners, with the classification accuracy reaching 84\%, when tested under the binaural-room-impulse-response ({BRIR}) matched conditions. However, when the algorithms were tested under the {BRIR} mismatched scenario, the accuracy obtained by the algorithms was comparable to that exhibited by the listeners who passed the post-screening test, implying that the machine learning algorithms capability to perform in unknown electro-acoustic conditions needs to be further improved.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 17 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{17}
      \field{title}{A Comparison of Human against Machine-Classification of Spatial Audio Scenes in Binaural Recordings of Music}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5956}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app10175956
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SC5RHNYP/Zieliński et al. - 2020 - A Comparison of Human against Machine-Classificati.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/10/17/5956
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/10/17/5956
      \endverb
      \keyw{convolutional neural networks,deep learning,spatial audio information retrieval,spatial audio scene classification}
    \endentry
    \entry{zielinski_spatial_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{bibnamehash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{authorbibnamehash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradate}{1}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The automatic localization of audio sources distributed symmetrically with respect to coronal or transverse planes using binaural signals still poses a challenging task, due to the front–back and up–down confusion effects. This paper demonstrates that the convolutional neural network ({CNN}) can be used to automatically localize music ensembles panned to the front, back, up, or down positions. The network was developed using the repository of the binaural excerpts obtained by the convolution of multi-track music recordings with the selected sets of head-related transfer functions ({HRTFs}). They were generated in such a way that a music ensemble (of circular shape in terms of its boundaries) was positioned in one of the following four locations with respect to the listener: front, back, up, and down. According to the obtained results, {CNN} identified the location of the ensembles with the average accuracy levels of 90.7\% and 71.4\% when tested under the {HRTF}-dependent and {HRTF}-independent conditions, respectively. For {HRTF}-dependent tests, the accuracy decreased monotonically with the increase in the ensemble size. A modified image occlusion sensitivity technique revealed selected frequency bands as being particularly important in terms of the localization process. These frequency bands are largely in accordance with the psychoacoustical literature.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 3 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{3}
      \field{shorttitle}{Spatial Audio Scene Characterization ({SASC})}
      \field{title}{Spatial Audio Scene Characterization ({SASC}): Automatic Localization of Front-, Back-, Up-, and Down-Positioned Music Ensembles in Binaural Recordings}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{12}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1569}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app12031569
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/HDGFITDN/Zieliński et al. - 2022 - Spatial Audio Scene Characterization (SASC) Autom.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/12/3/1569
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/12/3/1569
      \endverb
      \keyw{convolutional neural networks,deep learning,spatial audio information retrieval,spatial audio scene characterization}
    \endentry
    \entry{zielinski_automatic_2022}{article}{}
      \name{author}{4}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
        {{hash=cd0916f500f4baa33b5d6ef4873ac6a7}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Dale},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{c2290f4156a242be9065e01da047598f}
      \strng{bibnamehash}{c2290f4156a242be9065e01da047598f}
      \strng{authorbibnamehash}{c2290f4156a242be9065e01da047598f}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{c2290f4156a242be9065e01da047598f}
      \field{extraname}{3}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradate}{2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{One of the greatest challenges in the development of binaural machine audition systems is the disambiguation between front and back audio sources, particularly in complex spatial audio scenes. The goal of this work was to develop a method for discriminating between front and back located ensembles in binaural recordings of music. To this end, 22, 496 binaural excerpts, representing either front or back located ensembles, were synthesized by convolving multi-track music recordings with 74 sets of head-related transfer functions ({HRTF}). The discrimination method was developed based on the traditional approach, involving hand-engineering of features, as well as using a deep learning technique incorporating the convolutional neural network ({CNN}). According to the results obtained under {HRTF}-dependent test conditions, {CNN} showed a very high discrimination accuracy (99.4\%), slightly outperforming the traditional method. However, under the {HRTF}-independent test scenario, {CNN} performed worse than the traditional algorithm, highlighting the importance of testing the algorithms under {HRTF}-independent conditions and indicating that the traditional method might be more generalizable than {CNN}. A minimum of 20 {HRTFs} are required to achieve a satisfactory generalization performance for the traditional algorithm and 30 {HRTFs} for {CNN}. The minimum duration of audio excerpts required by both the traditional and {CNN}-based methods was assessed as 3 s. Feature importance analysis, based on a gradient attribution mapping technique, revealed that for both the traditional and the deep learning methods, a frequency band between 5 and 6 {kHz} is particularly important in terms of the discrimination between front and back ensemble locations. Linear-frequency cepstral coefficients, interaural level differences, and audio bandwidth were identified as the key descriptors facilitating the discrimination process using the traditional approach.}
      \field{day}{15}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{title}{Automatic discrimination between front and back ensemble locations in {HRTF}-convolved binaural recordings of music}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2022}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-021-00235-2
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/4G5WL8AM/Zieliński et al. - 2022 - Automatic discrimination between front and back en.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/SI2K4EJ6/s13636-021-00235-2.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13636-021-00235-2
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13636-021-00235-2
      \endverb
      \keyw{Binaural recordings,Feature engineering,{HRTF},Spatial audio information retrieval}
    \endentry
  \enddatalist
  \datalist[entry]{apa/global//global/global}
    \entry{abdel-hamid_applying_2012}{article}{}
      \name{author}{4}{}{%
        {{hash=9288aa6499433fb7e731959bc9ee8a76}{%
           family={Abdel-Hamid},
           familyi={A\bibinithyphendelim H\bibinitperiod},
           given={Ossama},
           giveni={O\bibinitperiod}}}%
        {{hash=0d87a656f9bdc99e921c45f73da515b8}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdel-rahman},
           giveni={A\bibinithyphendelim r\bibinitperiod}}}%
        {{hash=bb419d444235494b58481c9171c8e164}{%
           family={Jiang},
           familyi={J\bibinitperiod},
           given={Hui},
           giveni={H\bibinitperiod}}}%
        {{hash=aa1c6a2b41f82ec174c886dc4fdd967c}{%
           family={Penn},
           familyi={P\bibinitperiod},
           given={Gerald},
           giveni={G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Kyoto, Japan}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{412cf9e3d443eb6a2495eccae53adb28}
      \strng{fullhash}{5645f28fee3e09f76f17360082057ced}
      \strng{bibnamehash}{5645f28fee3e09f76f17360082057ced}
      \strng{authorbibnamehash}{5645f28fee3e09f76f17360082057ced}
      \strng{authornamehash}{412cf9e3d443eb6a2495eccae53adb28}
      \strng{authorfullhash}{5645f28fee3e09f76f17360082057ced}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eventtitle}{{ICASSP} 2012 - 2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing}
      \field{isbn}{978-1-4673-0046-9 978-1-4673-0045-2 978-1-4673-0044-5}
      \field{journaltitle}{2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{month}{3}
      \field{title}{Applying Convolutional Neural Networks concepts to hybrid {NN}-{HMM} model for speech recognition}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4277\bibrangedash 4280}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICASSP.2012.6288864
      \endverb
      \verb{file}
      \verb Submitted Version:/Users/pawel/Zotero/storage/Z5P9C3WR/Abdel-Hamid et al. - 2012 - Applying Convolutional Neural Networks concepts to.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6288864/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6288864/
      \endverb
    \endentry
    \entry{algazi_cipic_2001}{article}{}
      \name{author}{4}{}{%
        {{hash=06749bbf7d283e05c10d1841491e3449}{%
           family={Algazi},
           familyi={A\bibinitperiod},
           given={V.R.},
           giveni={V\bibinitperiod}}}%
        {{hash=b487da43284ea0ffefe3481b023777b0}{%
           family={Duda},
           familyi={D\bibinitperiod},
           given={R.O.},
           giveni={R\bibinitperiod}}}%
        {{hash=6e8237ec5d708e2bc9d23660e4c4d0d2}{%
           family={Thompson},
           familyi={T\bibinitperiod},
           given={D.M.},
           giveni={D\bibinitperiod}}}%
        {{hash=1952cf9096ab291f3989ac1584600c50}{%
           family={Avendano},
           familyi={A\bibinitperiod},
           given={C.},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{8f09378186bc4879fc1bce3e3cc4dbfd}
      \strng{fullhash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{bibnamehash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{authorbibnamehash}{6afac7a32e3369071c9397ce0f3fa259}
      \strng{authornamehash}{8f09378186bc4879fc1bce3e3cc4dbfd}
      \strng{authorfullhash}{6afac7a32e3369071c9397ce0f3fa259}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes a public-domain database of high-spatial-resolution head-related transfer functions measured at the {UC} Davis {CIPIC} Interface Laboratory and the methods used to collect the data.. Release 1.0 (see http://interface.cipic.ucdavis.edu) includes head-related impulse responses for 45 subjects at 25 different azimuths and 50 different elevations (1250 directions) at approximately 5/spl deg/ angular increments. In addition, the database contains anthropometric measurements for each subject. Statistics of anthropometric parameters and correlations between anthropometry and some temporal and spectral features of the {HRTFs} are reported.}
      \field{eventtitle}{Proceedings of the 2001 {IEEE} Workshop on the Applications of Signal Processing to Audio and Acoustics (Cat. No.01TH8575)}
      \field{journaltitle}{Proceedings of the 2001 {IEEE} Workshop on the Applications of Signal Processing to Audio and Acoustics (Cat. No.01TH8575)}
      \field{month}{10}
      \field{title}{The {CIPIC} {HRTF} database}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2001}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{99\bibrangedash 102}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ASPAA.2001.969552
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/8YD4T6PV/969552.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/969552
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/969552
      \endverb
      \keyw{Acoustic scattering,Anthropometry,Azimuth,Ear,Laboratories,Microphones,Position measurement,Spatial databases,Statistics,Transfer functions}
    \endentry
    \entry{andreopoulou_inter-laboratory_2015}{article}{}
      \name{author}{3}{}{%
        {{hash=55dc7e67d0b42710d35285483e206c74}{%
           family={Andreopoulou},
           familyi={A\bibinitperiod},
           given={Areti},
           giveni={A\bibinitperiod}}}%
        {{hash=dfa51aad6297c09b374cdb5db24c39cd}{%
           family={Begault},
           familyi={B\bibinitperiod},
           given={Durand\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=e6171c131f25cca08030c538161a1e89}{%
           family={Katz},
           familyi={K\bibinitperiod},
           given={Brian\bibnamedelimb F.\bibnamedelimi G.},
           giveni={B\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{4339c7aeafbe2d556b29128f9f5791cf}
      \strng{fullhash}{bec448d0391c56f2442780d28de1ed80}
      \strng{bibnamehash}{bec448d0391c56f2442780d28de1ed80}
      \strng{authorbibnamehash}{bec448d0391c56f2442780d28de1ed80}
      \strng{authornamehash}{4339c7aeafbe2d556b29128f9f5791cf}
      \strng{authorfullhash}{bec448d0391c56f2442780d28de1ed80}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Head-Related Transfer Function ({HRTF}) measurements underlie the signal processing used in binaural auditory displays, but measurement techniques, equipment, and post-processing vary substantially between laboratories. This variation can result in significant differences in measured spectral and timing data taken from the same subject for the same sound source locations. An ongoing project for comparing databases from laboratories across the world (colloquially titled “Club Fritz”) employs a single dummy head microphone for measurements (Neumann {KU}-100) at various sites. The current study examines magnitude and timing differences between left and right ear data from 12 different {HRTF} sets taken from 10 different laboratories. Results revealed spectral magnitude variations up to 12.5 {dB} for frequency bands below 6 {kHz} and up to 23 {dB} above that, as well as large spectral left/right asymmetries (dcorr ≤ 0.4) for high-frequency content. Further subjective studies are necessary to determine the perceptual relevance of these findings. Nevertheless, the observed {ITD} variations of up to 235 μsec are alarming as they often exceeded reported {JND} values. Such findings highlight the potential impact of physical spaces, measurement routines, and equipment types on the collected {HRTF} data.}
      \field{issn}{1941-0484}
      \field{journaltitle}{{IEEE} Journal of Selected Topics in Signal Processing}
      \field{month}{8}
      \field{note}{Conference Name: {IEEE} Journal of Selected Topics in Signal Processing}
      \field{number}{5}
      \field{title}{Inter-Laboratory Round Robin {HRTF} Measurement Comparison}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{9}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{895\bibrangedash 906}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1109/JSTSP.2015.2400417
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/S29TAY72/7031925.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7031925
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7031925
      \endverb
      \keyw{Current measurement,Databases,Ear,{HRTF}/{HRIR},{ITD} variations,Laboratories,measurement,Microphones,Position measurement,repeatability,Spatial resolution,spatial symmetry,spectral variations}
    \endentry
    \entry{antoniuk_software_2024}{online}{}
      \name{author}{1}{}{%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{fullhash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{bibnamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authorbibnamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authornamehash}{6fd073df32a3491aff57beee7b376a5b}
      \strng{authorfullhash}{6fd073df32a3491aff57beee7b376a5b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Software Repository: Estimating Ensemble Location and Width in Binaural Recordings of Music with Convolutional Neural Networks}
      \field{titleaddon}{{GitHub}}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://github.com/pawel-antoniuk/ensemble-width-cnn
      \endverb
      \verb{url}
      \verb https://github.com/pawel-antoniuk/ensemble-width-cnn
      \endverb
    \endentry
    \entry{antoniuk_blind_2023}{article}{}
      \name{author}{2}{}{%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{fullhash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{bibnamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authorbibnamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authornamehash}{26dc0a365ecebb9e459841e8ed96c709}
      \strng{authorfullhash}{26dc0a365ecebb9e459841e8ed96c709}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Audio Engineering Society Conference: {AES} 2023 International Conference on Spatial and Immersive Audio}
      \field{month}{8}
      \field{title}{Blind estimation of ensemble width in binaural music recordings using ‘spatiograms’ under simulated anechoic conditions}
      \field{year}{2023}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=22203
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=22203
      \endverb
    \endentry
    \entry{armstrong_perceptual_2018}{article}{}
      \name{author}{4}{}{%
        {{hash=449b95deb7c92d6bae29642ceb26dc5e}{%
           family={Armstrong},
           familyi={A\bibinitperiod},
           given={Cal},
           giveni={C\bibinitperiod}}}%
        {{hash=cb50f92abb883437070abbef360527c9}{%
           family={Thresh},
           familyi={T\bibinitperiod},
           given={Lewis},
           giveni={L\bibinitperiod}}}%
        {{hash=87b7036648a4c8fbe903ee80e70271eb}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Damian},
           giveni={D\bibinitperiod}}}%
        {{hash=dab5abd81d8bb1f9db64d94c6bc03919}{%
           family={Kearney},
           familyi={K\bibinitperiod},
           given={Gavin},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{c61cace23ee2e710a415978552a6ad52}
      \strng{fullhash}{d5ea80979379f293fe29841fd9f24265}
      \strng{bibnamehash}{d5ea80979379f293fe29841fd9f24265}
      \strng{authorbibnamehash}{d5ea80979379f293fe29841fd9f24265}
      \strng{authornamehash}{c61cace23ee2e710a415978552a6ad52}
      \strng{authorfullhash}{d5ea80979379f293fe29841fd9f24265}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{As binaural audio continues to permeate immersive technologies, it is vital to develop a detailed understanding of the perceptual relevance of {HRTFs}. Previous research has explored the benefit of individual {HRTFs} with respect to localisation. However, localisation is only one metric with which it is possible to rate spatial audio. This paper evaluates the perceived timbral and spatial characteristics of both individual and non-individual {HRTFs} and compares the results to overall preference. To that end, the measurement and evaluation of a high-resolution multi-environment binaural Impulse Response database is presented for 20 subjects, including the {KU}100 and {KEMAR} binaural mannequins. Post-processing techniques, including low frequency compensation and diffuse field equalisation are discussed in relation to the 8802 unique {HRTFs} measured for each mannequin and 2818/2114 {HRTFs} measured for each human. Listening test results indicate that particular {HRTF} sets are preferred more generally by subjects over their own individual measurements.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{11}
      \field{note}{Number: 11 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{11}
      \field{shorttitle}{A Perceptual Evaluation of Individual and Non-Individual {HRTFs}}
      \field{title}{A Perceptual Evaluation of Individual and Non-Individual {HRTFs}: A Case Study of the {SADIE} {II} Database}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{8}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2029}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app8112029
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/JUFP5BZ5/Armstrong et al. - 2018 - A Perceptual Evaluation of Individual and Non-Indi.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/8/11/2029
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/8/11/2029
      \endverb
      \keyw{binaural,database,evaluation,{HRTF},measurement,perception,spatial audio,timbre}
    \endentry
    \entry{arthi_spatiogram_2021}{article}{}
      \name{author}{2}{}{%
        {{hash=822d8daa7259d9322d2f3b089f249eee}{%
           family={Arthi},
           familyi={A\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod}}}%
        {{hash=fa990077dcba214931346c504a586a96}{%
           family={Sreenivas},
           familyi={S\bibinitperiod},
           given={Thippur\bibnamedelima V.},
           giveni={T\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{fullhash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{bibnamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authorbibnamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authornamehash}{46ad25080ab1a6754b00ff3fe619eb57}
      \strng{authorfullhash}{46ad25080ab1a6754b00ff3fe619eb57}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Spatiogram: A phase based directional angular measure and perceptual weighting for ensemble source width}
      \field{volume}{abs/2112.07216}
      \field{year}{2021}
      \field{dateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/IRU2Y2LJ/S and T V - 2021 - Spatiogram A phase based directional angular meas.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:245131510
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:245131510
      \endverb
    \endentry
    \entry{benaroya_binaural_2018}{article}{}
      \name{author}{6}{}{%
        {{hash=3a604688c1793716f5fe6c3fbd26773d}{%
           family={Benaroya},
           familyi={B\bibinitperiod},
           given={Elie\bibnamedelima Laurent},
           giveni={E\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=65528959cd45c0dd00fa184216842d23}{%
           family={Obin},
           familyi={O\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod}}}%
        {{hash=0d687f9ad924001bf48b16f37f767d76}{%
           family={Liuni},
           familyi={L\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod}}}%
        {{hash=88a4a4281b192bf9abbdd5a5d27ca33b}{%
           family={Roebel},
           familyi={R\bibinitperiod},
           given={Axel},
           giveni={A\bibinitperiod}}}%
        {{hash=1da39a02a80a901382d4f7019d24107a}{%
           family={Raumel},
           familyi={R\bibinitperiod},
           given={Wilson},
           giveni={W\bibinitperiod}}}%
        {{hash=dbb8a822f42d7807b9fb1d66c5be15ab}{%
           family={Argentieri},
           familyi={A\bibinitperiod},
           given={Sylvain},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{c7f483dd5309c8d8b0e969b04de1b6cd}
      \strng{fullhash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{bibnamehash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{authorbibnamehash}{434bbd30f8bcba4350feac4726358cf8}
      \strng{authornamehash}{c7f483dd5309c8d8b0e969b04de1b6cd}
      \strng{authorfullhash}{434bbd30f8bcba4350feac4726358cf8}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents non-negative factorization of audio signals for the binaural localization of multiple sound sources within realistic and unknown sound environments. Non-negative tensor factorization (NTF) provides a sparse representation of multichannel audio signals in time, frequency, and space that can be exploited in computational audio scene analysis and robot audition for the separation and localization of sound sources. In the proposed formulation, each sound source is represented by means of spectral dictionaries, temporal activation, and its distribution within each channel (here, left and right ears). This distribution, being dependent on the frequency, can be interpreted as an explicit estimation of the Head-Related Transfer Function (HRTF) of a binaural head which can then be converted into the estimated sound source position. Moreover, the semisupervised formulation of the non-negative factorization allows us to integrate prior knowledge about some sound sources of interest whose dictionaries can be learned in advance, whereas the remaining sources are considered as background sound, which remains unknown and is estimated on the fly. The proposed NTF-based sound source localization is applied here to binaural sound source localization of multiple speakers within realistic sound environments.}
      \field{issn}{2329-9304}
      \field{journaltitle}{IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{month}{6}
      \field{note}{Conference Name: IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{number}{6}
      \field{title}{Binaural {Localization} of {Multiple} {Sound} {Sources} by {Non}-{Negative} {Tensor} {Factorization}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2018}
      \field{urldateera}{ce}
      \field{pages}{1072\bibrangedash 1082}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TASLP.2018.2806745
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/AGTH4VGH/8294267.html:text/html;Submitted Version:/Users/pawel/Zotero/storage/TERC7QZT/Benaroya et al. - 2018 - Binaural Localization of Multiple Sound Sources by.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8294267
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8294267
      \endverb
      \keyw{Binaural localization,computational audio scene analysis,Ear,Image analysis,non-negative tensor factorization,robot audition,Robot kinematics,Speech,Speech processing,Tensile stress}
    \endentry
    \entry{blauert_spatial_1996}{book}{}
      \name{author}{1}{}{%
        {{hash=72eeeae6cc10aacbef1120ffab7b6f6e}{%
           family={Blauert},
           familyi={B\bibinitperiod},
           given={Jens},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {The MIT Press}%
      }
      \strng{namehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{fullhash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{bibnamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authorbibnamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authornamehash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \strng{authorfullhash}{72eeeae6cc10aacbef1120ffab7b6f6e}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The field of spatial hearing has exploded in the decade or so since Jens Blauert's classic work on acoustics was first published in English. This revised edition adds a new chapter that describes developments in such areas as auditory virtual reality (an important field of application that is based mainly on the physics of spatial hearing), binaural technology (modeling speech enhancement by binaural hearing), and spatial sound-field mapping. The chapter also includes recent research on the precedence effect that provides clear experimental evidence that cognition plays a significant role in spatial hearing. The remaining four chapters in this comprehensive reference cover auditory research procedures and psychometric methods, spatial hearing with one sound source, spatial hearing with multiple sound sources and in enclosed spaces, and progress and trends from 1972 (the first German edition) to 1983 (the first English edition)—work that includes research on the physics of the external ear, and the application of signal processing theory to modeling the spatial hearing process. There is an extensive bibliography of more than 900 items.}
      \field{isbn}{978-0-262-26868-4}
      \field{month}{10}
      \field{title}{Spatial {Hearing}: {The} {Psychophysics} of {Human} {Sound} {Localization}}
      \field{year}{1996}
      \verb{doi}
      \verb 10.7551/mitpress/6391.001.0001
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.7551/mitpress/6391.001.0001
      \endverb
      \verb{url}
      \verb https://doi.org/10.7551/mitpress/6391.001.0001
      \endverb
    \endentry
    \entry{branke_evolutionary_1995}{article}{}
      \name{author}{1}{}{%
        {{hash=d9e8de881fe2db78bf10c2e152430ab7}{%
           family={Branke},
           familyi={B\bibinitperiod},
           given={Jürgen},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{fullhash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{bibnamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authorbibnamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authornamehash}{d9e8de881fe2db78bf10c2e152430ab7}
      \strng{authorfullhash}{d9e8de881fe2db78bf10c2e152430ab7}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Neural networks and genetic algorithms are two relatively young research areas that were subject to a steadily growing interest during the past years. Both models are inspired by nature, but whereas neural networks are concerned with learning of an individual (phenotypic learning), evolutionary algorithms deal with a population’s adaptation to a changing environment (genotypic learning). This paper focuses on the intersection of neural networks and evolutionary computation, namely on how evolutionary algorithms can be used to assist neural network design and training. The purpose of the paper is to set forth the general considerations that have to be made when designing an algorithm in this area and to give an overview on how researchers addressed these issues in the past.}
      \field{journaltitle}{Proceedings of the First Nordic Workshop on Genetic Algorithms and its Application}
      \field{title}{Evolutionary Algorithms for Neural Network Design and Training}
      \field{urlday}{23}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{1995}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{145\bibrangedash 163}
      \range{pages}{19}
      \verb{file}
      \verb Branke - 1995 - Evolutionary Algorithms for Neural Network Design .pdf:/home/pawel/Zotero/storage/H4Y8MXEH/Branke - 1995 - Evolutionary Algorithms for Neural Network Design .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.semanticscholar.org/paper/Evolutionary-Algorithms-for-Neural-Network-Design-Branke/af9612b51f0bcab7013b239c333d17cf398d20b8
      \endverb
      \verb{url}
      \verb https://www.semanticscholar.org/paper/Evolutionary-Algorithms-for-Neural-Network-Design-Branke/af9612b51f0bcab7013b239c333d17cf398d20b8
      \endverb
    \endentry
    \entry{braren_high-resolution_2020}{article}{}
      \name{author}{2}{}{%
        {{hash=1a7e6a0f3b97288c71c6a736c42124a7}{%
           family={Braren},
           familyi={B\bibinitperiod},
           given={Hark\bibnamedelima Simon},
           giveni={H\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=8c38bbd25743680ce3100d8b7ad619a0}{%
           family={Fels},
           familyi={F\bibinitperiod},
           given={Janina},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{fullhash}{7cee2f7474d4479b291b7271a5266846}
      \strng{bibnamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authorbibnamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authornamehash}{7cee2f7474d4479b291b7271a5266846}
      \strng{authorfullhash}{7cee2f7474d4479b291b7271a5266846}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{A High-Resolution Individual 3D Adult Head and Torso Model for {HRTF} Simulation and Validation: {HRTF} Measurement}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Braren and Fels - 2020 - A High-Resolution Individual 3D Adult Head and Tor.pdf:/home/pawel/Zotero/storage/KKR3ZBZ8/Braren and Fels - 2020 - A High-Resolution Individual 3D Adult Head and Tor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:234998299
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:234998299
      \endverb
    \endentry
    \entry{bregman_auditory_1990}{inbook}{}
      \name{author}{1}{}{%
        {{hash=51930ef3803ace57c0abead7f63071c3}{%
           family={Bregman},
           familyi={B\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press}%
      }
      \strng{namehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{fullhash}{51930ef3803ace57c0abead7f63071c3}
      \strng{bibnamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authorbibnamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authornamehash}{51930ef3803ace57c0abead7f63071c3}
      \strng{authorfullhash}{51930ef3803ace57c0abead7f63071c3}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Scitation is the online home of leading journals and conference proceedings from AIP Publishing and AIP Member Societies}
      \field{booktitle}{Journal of {The} {Acoustical} {Society} of {America} - {J} {ACOUST} {SOC} {AMER}}
      \field{month}{1}
      \field{note}{Journal Abbreviation: Journal of The Acoustical Society of America - J ACOUST SOC AMER}
      \field{shorttitle}{Auditory {Scene} {Analysis}}
      \field{title}{Auditory {Scene} {Analysis}: {The} {Perceptual} {Organization} of {Sound}}
      \field{volume}{95}
      \field{year}{1990}
      \verb{doi}
      \verb 10.1121/1.408434
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SR53ZIS7/Bregman - 1990 - Auditory Scene Analysis The Perceptual Organizati.pdf:application/pdf
      \endverb
    \endentry
    \entry{brinkmann_cross-evaluated_2019}{article}{}
      \name{author}{6}{}{%
        {{hash=ddaa65ee961b81796f483236881c13e8}{%
           family={Brinkmann},
           familyi={B\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=2fa348a6d87989d08218a99ed62290a4}{%
           family={Dinakaran},
           familyi={D\bibinitperiod},
           given={Manoj},
           giveni={M\bibinitperiod}}}%
        {{hash=072760f8145043507a447376c63fc5f6}{%
           family={Pelzer},
           familyi={P\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=797477a22ebb0c22bad97baeb0d02e6a}{%
           family={Grosche},
           familyi={G\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=f1a97300823078cc309d88918a011b60}{%
           family={Voss},
           familyi={V\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=7f6677631454c7c9baa854e96f9a6f6f}{%
           family={Weinzierl},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{fullhash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{bibnamehash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{authorbibnamehash}{68e288c0bed28cadd3b4d83316b7b32d}
      \strng{authornamehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{authorfullhash}{68e288c0bed28cadd3b4d83316b7b32d}
      \field{extraname}{1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{21}
      \field{issn}{15494950}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{9}
      \field{shortjournal}{J. Audio Eng. Soc.}
      \field{title}{A Cross-Evaluated Database of Measured and Simulated {HRTFs} Including 3D Head Meshes, Anthropometric Features, and Headphone Impulse Responses}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{67}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{705\bibrangedash 718}
      \range{pages}{14}
      \verb{doi}
      \verb 10.17743/jaes.2019.0024
      \endverb
      \verb{file}
      \verb Brinkmann et al. - 2019 - A Cross-Evaluated Database of Measured and Simulat.pdf:/Users/pawel/Zotero/storage/8RIN3L7T/Brinkmann et al. - 2019 - A Cross-Evaluated Database of Measured and Simulat.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=20546
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=20546
      \endverb
    \endentry
    \entry{brinkmann_high_2017}{article}{}
      \name{author}{7}{}{%
        {{hash=ddaa65ee961b81796f483236881c13e8}{%
           family={Brinkmann},
           familyi={B\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=d0754317d63a192dfdbc01acd3559f86}{%
           family={Lindau},
           familyi={L\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=efead5602621f126b0f182f07582af77}{%
           family={Weinzerl},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=190a306c874262a3e25d2b92b2154bb7}{%
           family={Van\bibnamedelimb De\bibnamedelima Par},
           familyi={V\bibinitperiod\bibinitdelim D\bibinitperiod\bibinitdelim P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=fc40aa5bf87724bfe7682ef1214c921a}{%
           family={Müller-Trapet},
           familyi={M\bibinithyphendelim T\bibinitperiod},
           given={Markus},
           giveni={M\bibinitperiod}}}%
        {{hash=9bff6d4192fd48fd0b4c02a2b7f8edb9}{%
           family={Opdam},
           familyi={O\bibinitperiod},
           given={Rob},
           giveni={R\bibinitperiod}}}%
        {{hash=d272335dbc7a4ad64546aa36b3c32fe9}{%
           family={Vorländer},
           familyi={V\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{fullhash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{bibnamehash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{authorbibnamehash}{de5dead1c533929de6de8ce13e8b5a35}
      \strng{authornamehash}{4ac924f751f5d6ba3ff844e36082805a}
      \strng{authorfullhash}{de5dead1c533929de6de8ce13e8b5a35}
      \field{extraname}{2}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{day}{30}
      \field{issn}{15494950}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{J. Audio Eng. Soc.}
      \field{title}{A High Resolution and Full-Spherical Head-Related Transfer Function Database for Different Head-Above-Torso Orientations}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{65}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{841\bibrangedash 848}
      \range{pages}{8}
      \verb{doi}
      \verb 10.17743/jaes.2017.0033
      \endverb
      \verb{file}
      \verb Brinkmann et al. - 2017 - A High Resolution and Full-Spherical Head-Related .pdf:/Users/pawel/Zotero/storage/GZFNE9CA/Brinkmann et al. - 2017 - A High Resolution and Full-Spherical Head-Related .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=19357
      \endverb
      \verb{url}
      \verb http://www.aes.org/e-lib/browse.cfm?elib=19357
      \endverb
    \endentry
    \entry{cherry_experiments_1953}{article}{}
      \name{author}{1}{}{%
        {{hash=c293bf3e2995baf349c18c7ac49b63b3}{%
           family={Cherry},
           familyi={C\bibinitperiod},
           given={E.\bibnamedelimi Colin},
           giveni={E\bibinitperiod\bibinitdelim C\bibinitperiod}}}%
      }
      \strng{namehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{fullhash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{bibnamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authorbibnamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authornamehash}{c293bf3e2995baf349c18c7ac49b63b3}
      \strng{authorfullhash}{c293bf3e2995baf349c18c7ac49b63b3}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Experiments are described which examine the separation of two speech signals by human operators. 3 procedures were employed: presentation of both messages to both ears; presentation of one message to one ear with simultaneous presentation of the second message to the other ear; and presentation of a single message alternately to the two ears. Of particular current interest is the second procedure. Here, a listener is able to separate the messages exceedingly well despite the fact that he can only identify the general statistical properties of the rejected message. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)}
      \field{issn}{0001-4966(Print)}
      \field{journaltitle}{Journal of the Acoustical Society of America}
      \field{note}{Place: {US} Publisher: Acoustical Society of American}
      \field{title}{Some experiments on the recognition of speech, with one and with two ears.}
      \field{volume}{25}
      \field{year}{1953}
      \field{dateera}{ce}
      \field{pages}{975\bibrangedash 979}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1121/1.1907229
      \endverb
    \endentry
    \entry{chollet_keras_2015}{online}{}
      \true{moreauthor}
      \true{morelabelname}
      \name{author}{1}{}{%
        {{hash=5836fc1fa037e340c8b5591da3207608}{%
           family={Chollet},
           familyi={C\bibinitperiod},
           given={Francois},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{94f467118488a03ed3386af37a329f60}
      \strng{fullhash}{94f467118488a03ed3386af37a329f60}
      \strng{bibnamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authorbibnamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authornamehash}{94f467118488a03ed3386af37a329f60}
      \strng{authorfullhash}{94f467118488a03ed3386af37a329f60}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Keras}
      \field{titleaddon}{{GitHub}}
      \field{urlday}{1}
      \field{urlmonth}{7}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb https://github.com/fchollet/keras
      \endverb
      \verb{url}
      \verb https://github.com/fchollet/keras
      \endverb
    \endentry
    \entry{chung_sound_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=d2858cf75bbc599eb93e546fdba33a88}{%
           family={Chung},
           familyi={C\bibinitperiod},
           given={Ming-An},
           giveni={M\bibinithyphendelim A\bibinitperiod}}}%
        {{hash=32595a352be28d8357df4725616e62c6}{%
           family={Chou},
           familyi={C\bibinitperiod},
           given={Hung-Chi},
           giveni={H\bibinithyphendelim C\bibinitperiod}}}%
        {{hash=77470cfec474923e449b355144ae5dd8}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Chia-Wei},
           giveni={C\bibinithyphendelim W\bibinitperiod}}}%
      }
      \strng{namehash}{029fc3f27f14ea1c30a940310b130bd4}
      \strng{fullhash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{bibnamehash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{authorbibnamehash}{7389c3168ed5a652eb147d04e2dc5c65}
      \strng{authornamehash}{029fc3f27f14ea1c30a940310b130bd4}
      \strng{authorfullhash}{7389c3168ed5a652eb147d04e2dc5c65}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound signals have been widely applied in various fields. One of the popular applications is sound localization, where the location and direction of a sound source are determined by analyzing the sound signal. In this study, two microphone linear arrays were used to locate the sound source in an indoor environment. The {TDOA} is also designed to deal with the problem of delay in the reception of sound signals from two microphone arrays by using the generalized cross-correlation algorithm to calculate the {TDOA}. The proposed microphone array system with the algorithm can successfully estimate the sound source’s location. The test was performed in a standardized chamber. This experiment used two microphone arrays, each with two microphones. The experimental results prove that the proposed method can detect the sound source and obtain good performance with a position error of about 2.0{\textasciitilde}2.3 cm and angle error of about 0.74 degrees. Therefore, the experimental results demonstrate the feasibility of the system.}
      \field{issn}{2079-9292}
      \field{journaltitle}{Electronics}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 6 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{6}
      \field{title}{Sound Localization Based on Acoustic Source Using Multiple Microphone Array in an Indoor Environment}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{11}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{890}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/electronics11060890
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/PX2QWICQ/Chung et al. - 2022 - Sound Localization Based on Acoustic Source Using .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2079-9292/11/6/890
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2079-9292/11/6/890
      \endverb
      \keyw{generalized cross-correlation algorithm,indoor localization,microphone array,sound localization,time difference of arrival}
    \endentry
    \entry{clifton_growth_1988}{article}{}
      \name{author}{5}{}{%
        {{hash=8ac910b18e1b6168ee4c16a81d68b5b6}{%
           family={Clifton},
           familyi={C\bibinitperiod},
           given={Rachel\bibnamedelima K.},
           giveni={R\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=7229b8690c40458b03fd3db56e888d52}{%
           family={Gwiazda},
           familyi={G\bibinitperiod},
           given={Jane},
           giveni={J\bibinitperiod}}}%
        {{hash=521b21ff6f925397afdeb4b6d2f148b6}{%
           family={Bauer},
           familyi={B\bibinitperiod},
           given={Joseph\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=1982c5e92a52a19a8a2eacc28a4a1b67}{%
           family={Clarkson},
           familyi={C\bibinitperiod},
           given={Marsha\bibnamedelima G.},
           giveni={M\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=804c09dda541271d714048d366f165c6}{%
           family={Held},
           familyi={H\bibinitperiod},
           given={Richard\bibnamedelima M.},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{6ebfe47222fc454662a799e5e49a6be5}
      \strng{fullhash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{bibnamehash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{authorbibnamehash}{f9e6d52df029b6d57972eab5cc617347}
      \strng{authornamehash}{6ebfe47222fc454662a799e5e49a6be5}
      \strng{authorfullhash}{f9e6d52df029b6d57972eab5cc617347}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We measured head circumference and interaural distance in infants between birth and 22 weeks of age. A small sample of preschool children and adults were measured for comparison over the life span. We used these data to calculate changing interaural time differences across ages. Large shifts in this important binaural cue suggest that an ongoing developmental process recalibrates the association between interaural time differences and spatial location. These new data confirmed the sex differences in head circumference described in the Berkeley Growth Study (Eichorn \& Bailey, 1962) and found no secular trend in this measure in the 60 years since the earlier data were collected. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)}
      \field{issn}{1939-0599(Electronic),0012-1649(Print)}
      \field{journaltitle}{Developmental Psychology}
      \field{note}{Place: {US} Publisher: American Psychological Association}
      \field{number}{4}
      \field{title}{Growth in head size during infancy: Implications for sound localization.}
      \field{volume}{24}
      \field{year}{1988}
      \field{dateera}{ce}
      \field{pages}{477\bibrangedash 483}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1037/0012-1649.24.4.477
      \endverb
      \keyw{*Auditory Localization,*Age Differences,*Head (Anatomy),*Human Sex Differences,Physical Development}
    \endentry
    \entry{dietz_auditory_2011}{article}{}
      \name{author}{3}{}{%
        {{hash=0fff3eaffb14ecf4d97558717c928bb0}{%
           family={Dietz},
           familyi={D\bibinitperiod},
           given={Mathias},
           giveni={M\bibinitperiod}}}%
        {{hash=050737b9308ff0c4cb360df0537314a5}{%
           family={Ewert},
           familyi={E\bibinitperiod},
           given={Stephan\bibnamedelima D.},
           giveni={S\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=9b5db11c0c442086b33b5c9b37a78d15}{%
           family={Hohmann},
           familyi={H\bibinitperiod},
           given={Volker},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{3f58be53a6babc8796060fe8ff170067}
      \strng{fullhash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{bibnamehash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{authorbibnamehash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \strng{authornamehash}{3f58be53a6babc8796060fe8ff170067}
      \strng{authorfullhash}{d272fb94f0bc3fd0c70ef312ffc729af}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Humans show a very robust ability to localize sounds in adverse conditions. Computational models of binaural sound localization and technical approaches of direction-of-arrival (DOA) estimation also show good performance, however, both their binaural feature extraction and the strategies for further analysis partly differ from what is currently known about the human auditory system. This study investigates auditory model based DOA estimation emphasizing known features and limitations of the auditory binaural processing such as (i) high temporal resolution, (ii) restricted frequency range to exploit temporal fine-structure, (iii) use of temporal envelope disparities, and (iv) a limited range to compensate for interaural time delay. DOA estimation performance was investigated for up to five concurrent speakers in free field and for up to three speakers in the presence of noise. The DOA errors in these conditions were always smaller than 5°. A condition with moving speakers was also tested and up to three moving speakers could be tracked simultaneously. Analysis of DOA performance as a function of the binaural temporal resolution showed that short time constants of about 5ms employed by the auditory model were crucial for robustness against concurrent sources.}
      \field{issn}{0167-6393}
      \field{journaltitle}{Speech Communication}
      \field{month}{5}
      \field{number}{5}
      \field{series}{Perceptual and {Statistical} {Audition}}
      \field{title}{Auditory model based direction estimation of concurrent speakers from binaural signals}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{53}
      \field{year}{2011}
      \field{urldateera}{ce}
      \field{pages}{592\bibrangedash 605}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1016/j.specom.2010.05.006
      \endverb
      \verb{file}
      \verb ScienceDirect Snapshot:/Users/pawel/Zotero/storage/B6MXZWGK/S016763931000097X.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S016763931000097X
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S016763931000097X
      \endverb
      \keyw{Auditory modeling,Binaural processing,Direction estimation}
    \endentry
    \entry{eisenman_check-n-run_2020}{article}{}
      \name{author}{8}{}{%
        {{hash=7340ee2f132a35281d3204fd988c70fe}{%
           family={Eisenman},
           familyi={E\bibinitperiod},
           given={Assaf},
           giveni={A\bibinitperiod}}}%
        {{hash=e13c63d4e13df53825c3bde8ed13bab2}{%
           family={Matam},
           familyi={M\bibinitperiod},
           given={Kiran\bibnamedelima Kumar},
           giveni={K\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=52983ec4513ef39b59ca37c0fefe5415}{%
           family={Ingram},
           familyi={I\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=7665aa4c66ae17e55251a67c635e7ad3}{%
           family={Mudigere},
           familyi={M\bibinitperiod},
           given={Dheevatsa},
           giveni={D\bibinitperiod}}}%
        {{hash=4a691df37485846988162c4f0639d2f0}{%
           family={Krishnamoorthi},
           familyi={K\bibinitperiod},
           given={Raghuraman},
           giveni={R\bibinitperiod}}}%
        {{hash=a0d10d48172f7b207c6fffcddb1db844}{%
           family={Annavaram},
           familyi={A\bibinitperiod},
           given={Murali},
           giveni={M\bibinitperiod}}}%
        {{hash=4266fa41481da32c5f77259e80ca615e}{%
           family={Nair},
           familyi={N\bibinitperiod},
           given={Krishnakumar},
           giveni={K\bibinitperiod}}}%
        {{hash=9e7183ff690cd4bd193b4b725fad9621}{%
           family={Smelyanskiy},
           familyi={S\bibinitperiod},
           given={Mikhail},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{0c10076539d27c95874c9e0b172336ac}
      \strng{fullhash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{bibnamehash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{authorbibnamehash}{e57138c5d70975bd51ebe0cb122122a6}
      \strng{authornamehash}{0c10076539d27c95874c9e0b172336ac}
      \strng{authorfullhash}{e57138c5d70975bd51ebe0cb122122a6}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Check-N-Run: A Checkpointing System for Training Recommendation Models}
      \field{volume}{abs/2010.08679}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Eisenman et al. - Check-N-Run a Checkpointing System for Training D.pdf:/Users/pawel/Zotero/storage/LW5BQQ8I/Eisenman et al. - Check-N-Run a Checkpointing System for Training D.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:224704491
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:224704491
      \endverb
    \endentry
    \entry{espi_exploiting_2015}{article}{}
      \name{author}{4}{}{%
        {{hash=3d606aa1ee1673fe0e177588f375cf1d}{%
           family={Espi},
           familyi={E\bibinitperiod},
           given={Miquel},
           giveni={M\bibinitperiod}}}%
        {{hash=7d117fe090853faf976a9b0ea7ea49c9}{%
           family={Fujimoto},
           familyi={F\bibinitperiod},
           given={Masakiyo},
           giveni={M\bibinitperiod}}}%
        {{hash=99b9d0400a15bba8addab471319a8863}{%
           family={Kinoshita},
           familyi={K\bibinitperiod},
           given={Keisuke},
           giveni={K\bibinitperiod}}}%
        {{hash=15ca5c62010c9e66000d4867c877580b}{%
           family={Nakatani},
           familyi={N\bibinitperiod},
           given={Tomohiro},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{dd3bd8dfb91e6e2ae1673829a6f45ad9}
      \strng{fullhash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{bibnamehash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{authorbibnamehash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \strng{authornamehash}{dd3bd8dfb91e6e2ae1673829a6f45ad9}
      \strng{authorfullhash}{f3a1fb02c20b670c3c8f55ce3ecbf457}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, deep learning has not only permeated the computer vision and speech recognition research fields but also fields such as acoustic event detection ({AED}). One of the aims of {AED} is to detect and classify non-speech acoustic events occurring in conversation scenes including those produced by both humans and the objects that surround us. In {AED}, deep learning has enabled modeling of detail-rich features, and among these, high resolution spectrograms have shown a significant advantage over existing predefined features (e.g., Mel-filter bank) that compress and reduce detail. In this paper, we further asses the importance of feature extraction for deep learning-based acoustic event detection. {AED}, based on spectrogram-input deep neural networks, exploits the fact that sounds have “global” spectral patterns, but sounds also have “local” properties such as being more transient or smoother in the time-frequency domain. These can be exposed by adjusting the time-frequency resolution used to compute the spectrogram, or by using a model that exploits locality leading us to explore two different feature extraction strategies in the context of deep learning: (1) using multiple resolution spectrograms simultaneously and analyzing the overall and event-wise influence to combine the results, and (2) introducing the use of convolutional neural networks ({CNN}), a state of the art 2D feature extraction model that exploits local structures, with log power spectrogram input for {AED}. An experimental evaluation shows that the approaches we describe outperform our state-of-the-art deep learning baseline with a noticeable gain in the {CNN} case and provides insights regarding {CNN}-based spectrogram characterization for {AED}.}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{1}
      \field{shortjournal}{J {AUDIO} {SPEECH} {MUSIC} {PROC}.}
      \field{title}{Exploiting spectro-temporal locality in deep learning based acoustic event detection}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2015}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{26}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-015-0069-2
      \endverb
      \verb{file}
      \verb Espi et al. - 2015 - Exploiting spectro-temporal locality in deep learn.pdf:/Users/pawel/Zotero/storage/29QSQYTI/Espi et al. - 2015 - Exploiting spectro-temporal locality in deep learn.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-015-0069-2
      \endverb
      \verb{url}
      \verb https://asmp-eurasipjournals.springeropen.com/articles/10.1186/s13636-015-0069-2
      \endverb
    \endentry
    \entry{gardne_hrtf_1994}{online}{}
      \name{author}{2}{}{%
        {{hash=5b1fc211a56a5f1de4b8aef6be7dcb6a}{%
           family={Gardner},
           familyi={G\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod}}}%
        {{hash=2835b0059a28532b6119ec1d156b7506}{%
           family={Martin},
           familyi={M\bibinitperiod},
           given={Keith},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{fullhash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{bibnamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authorbibnamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authornamehash}{493d5220c3023f74c46b515c0a0c9699}
      \strng{authorfullhash}{493d5220c3023f74c46b515c0a0c9699}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{HRTF} Measurements of a {KEMAR} Dummy-Head Microphone}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{1994}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb HRTF Measurements of a KEMAR Dummy-Head Microphone:/Users/pawel/Zotero/storage/4HFJMLXI/KEMAR.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://sound.media.mit.edu/resources/KEMAR.html
      \endverb
      \verb{url}
      \verb https://sound.media.mit.edu/resources/KEMAR.html
      \endverb
    \endentry
    \entry{garofolo_darpa_1993}{article}{}
      \name{author}{6}{}{%
        {{hash=44271afa307ac7503236cffe215ad4fe}{%
           family={Garofolo},
           familyi={G\bibinitperiod},
           given={John\bibnamedelima S.},
           giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=b210b37758f994ece79b9af4c9490e4d}{%
           family={Lamel},
           familyi={L\bibinitperiod},
           given={Lori},
           giveni={L\bibinitperiod}}}%
        {{hash=d8b228b8e55ccb45e125e295cd4ee49d}{%
           family={Fisher},
           familyi={F\bibinitperiod},
           given={William\bibnamedelima M.},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=5eb94c7444909f6544dafe84917447f3}{%
           family={Fiscus},
           familyi={F\bibinitperiod},
           given={Jonathan\bibnamedelima G.},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=20067c327d8a12d1e92c1a6023d59672}{%
           family={Pallett},
           familyi={P\bibinitperiod},
           given={David\bibnamedelima S.},
           giveni={D\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=b8370181dc059b845bee035b1aeb583b}{%
           family={Dahlgren},
           familyi={D\bibinitperiod},
           given={Nancy\bibnamedelima L.},
           giveni={N\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{cfe7640d7c6d82aa6b4ba6468064fc6e}
      \strng{fullhash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{bibnamehash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{authorbibnamehash}{c9162c13740b8e8387f4cd84f554bb54}
      \strng{authornamehash}{cfe7640d7c6d82aa6b4ba6468064fc6e}
      \strng{authorfullhash}{c9162c13740b8e8387f4cd84f554bb54}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{DARPA} {TIMIT}: acoustic-phonetic continuous speech corpus {CD}-{ROM}, {NIST} speech disc 1-1.1}
      \field{year}{1993}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:60884624
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:60884624
      \endverb
    \endentry
    \entry{hahmann_sound_2022}{article}{}
      \name{author}{4}{}{%
        {{hash=462effa97cee565bbd73d62c8de447f6}{%
           family={Hahmann},
           familyi={H\bibinitperiod},
           given={Manuel},
           giveni={M\bibinitperiod}}}%
        {{hash=7db6887530f3c844ba77d04c48e013e6}{%
           family={Fernandez-Grande},
           familyi={F\bibinithyphendelim G\bibinitperiod},
           given={Efren},
           giveni={E\bibinitperiod}}}%
        {{hash=bbde32c810b210de5d8021fde06c7003}{%
           family={Gunawan},
           familyi={G\bibinitperiod},
           given={Henrry},
           giveni={H\bibinitperiod}}}%
        {{hash=656ee498925f8094095f667d1dea6b55}{%
           family={Gerstoft},
           familyi={G\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{cd1fb091d0ef2ef9a1cd8397d605307b}
      \strng{fullhash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{bibnamehash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{authorbibnamehash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \strng{authornamehash}{cd1fb091d0ef2ef9a1cd8397d605307b}
      \strng{authorfullhash}{1da1aa7980c1d36aefe1e6939e60ff34}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization is crucial for communication and sound scene analysis. This study uses direction-of-arrival estimates of multiple ad hoc distributed microphone arrays to localize sound sources in a room. An affine mapping between the independent array estimates and the source coordinates is derived from a set of calibration points. Experiments show that the affine model is sufficient to locate a source and can be calibrated to physical dimensions. A projection of the local array estimates increases localization accuracy, particularly further away from the calibrated region. Localization tests in three dimensions compare the affine approach to a nonlinear neural network.}
      \field{issn}{2691-1191}
      \field{journaltitle}{{JASA} Express Letters}
      \field{month}{7}
      \field{number}{7}
      \field{shortjournal}{{JASA} Express Lett}
      \field{title}{Sound source localization using multiple ad hoc distributed microphone arrays}
      \field{volume}{2}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{pages}{074801}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1121/10.0011811
      \endverb
      \verb{file}
      \verb Full Text:/Users/pawel/Zotero/storage/5MD884GP/Hahmann et al. - 2022 - Sound source localization using multiple ad hoc di.pdf:application/pdf
      \endverb
      \keyw{Sound,Acoustics,Sound Localization}
    \endentry
    \entry{han_convolutional_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=4a1e25a86fbcddf1e82056630f705db9}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Yoonchang},
           giveni={Y\bibinitperiod}}}%
        {{hash=3f8b651bfedbe1c637184643e341f410}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Jeongsoon},
           giveni={J\bibinitperiod}}}%
        {{hash=0f47d6f8a9660c5c5bcdb2f43935a120}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Kyogu},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{3ef425317d659bd2c2d500f3b514208b}
      \strng{fullhash}{d7241d9dadb27f437922488280c79803}
      \strng{bibnamehash}{d7241d9dadb27f437922488280c79803}
      \strng{authorbibnamehash}{d7241d9dadb27f437922488280c79803}
      \strng{authornamehash}{3ef425317d659bd2c2d500f3b514208b}
      \strng{authorfullhash}{d7241d9dadb27f437922488280c79803}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Workshop on Detection and Classification of Acoustic Scenes and Events}
      \field{title}{Convolutional Neural Networks with Binaural Representations and Background Subtraction for Acoustic Scene Classification}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:52830611
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:52830611
      \endverb
    \endentry
    \entry{hirsh_binaural_1950}{article}{}
      \name{author}{1}{}{%
        {{hash=ba9301dcf14f75a44801567347475e0f}{%
           family={Hirsh},
           familyi={H\bibinitperiod},
           given={Ira\bibnamedelima J.},
           giveni={I\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{fullhash}{ba9301dcf14f75a44801567347475e0f}
      \strng{bibnamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authorbibnamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authornamehash}{ba9301dcf14f75a44801567347475e0f}
      \strng{authorfullhash}{ba9301dcf14f75a44801567347475e0f}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{issn}{0022-4677, 2163-6184}
      \field{journaltitle}{Journal of Speech and Hearing Disorders}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{2}
      \field{shortjournal}{J Speech Hear Disord}
      \field{shorttitle}{Binaural Hearing Aids}
      \field{title}{Binaural Hearing Aids: A Review Of Some Experiments}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{15}
      \field{year}{1950}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{114\bibrangedash 123}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1044/jshd.1502.114
      \endverb
      \verb{file}
      \verb Hirsh - 1950 - Binaural Hearing Aids A Review Of Some Experiment.pdf:/Users/pawel/Zotero/storage/WI3CH9LM/Hirsh - 1950 - Binaural Hearing Aids A Review Of Some Experiment.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://pubs.asha.org/doi/10.1044/jshd.1502.114
      \endverb
      \verb{url}
      \verb http://pubs.asha.org/doi/10.1044/jshd.1502.114
      \endverb
    \endentry
    \entry{noauthor_hrtf-database_2014}{online}{}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{title}{{HRTF}-Database}
      \field{titleaddon}{Austrian Academy of Sciences}
      \field{type}{Acoustic Research Institute}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb HRTF-Database:/Users/pawel/Zotero/storage/F6K6MNKB/hrtf-database.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.oeaw.ac.at/en/ari/das-institut/software/hrtf-database
      \endverb
      \verb{url}
      \verb https://www.oeaw.ac.at/en/ari/das-institut/software/hrtf-database
      \endverb
    \endentry
    \entry{ioffe_batch_2015}{inbook}{}
      \name{author}{2}{}{%
        {{hash=5543e82359e26b035efc009cb3efff9d}{%
           family={Ioffe},
           familyi={I\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
        {{hash=ed568d9c3bb059e6bf22899fbf170f86}{%
           family={Szegedy},
           familyi={S\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
      }
      \name{editor}{2}{}{%
        {{hash=93da2819ab01d8a5e7bae39ce6f17c1f}{%
           family={Bach},
           familyi={B\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
        {{hash=df034c01f40f9863f7986f0670e3f863}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Lille, France}%
      }
      \list{publisher}{1}{%
        {PMLR}%
      }
      \strng{namehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{fullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{bibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorbibnamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authornamehash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{authorfullhash}{7e8dee717d54c2984b1c6bd3f3c0561f}
      \strng{editorbibnamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editornamehash}{4188f673e8c288b53fdbccdd66b77f3f}
      \strng{editorfullhash}{4188f673e8c288b53fdbccdd66b77f3f}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.}
      \field{booktitle}{Proceedings of the 32nd International Conference on Machine Learning}
      \field{day}{7}
      \field{month}{7}
      \field{series}{Proceedings of Machine Learning Research}
      \field{title}{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}
      \field{volume}{37}
      \field{year}{2015}
      \field{dateera}{ce}
      \field{pages}{448\bibrangedash 456}
      \range{pages}{9}
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v37/ioffe15.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v37/ioffe15.html
      \endverb
    \endentry
    \entry{noauthor_itu-r_2023}{article}{}
      \list{location}{1}{%
        {Geneva, Switzerland}%
      }
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{journaltitle}{International Communications Union}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{{ITU}-R {BS}.1770-5: Algorithms to measure audio programme loudness and true-peak audio level}
      \field{year}{2023}
      \field{dateera}{ce}
      \verb{file}
      \verb Recommendation ITU-R BS.1770-5 (112023) Algorithm.pdf:/Users/pawel/Zotero/storage/KP326E9A/Recommendation ITU-R BS.1770-5 (112023) Algorithm.pdf:application/pdf
      \endverb
    \endentry
    \entry{kaveh_statistical_1986}{article}{}
      \name{author}{2}{}{%
        {{hash=e4dfdb3b9932151e9bc9aab6109e2bd2}{%
           family={Kaveh},
           familyi={K\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
        {{hash=fc0cdaa107f6eb96d3c987343c2b7640}{%
           family={Barabell},
           familyi={B\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{fullhash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{bibnamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authorbibnamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authornamehash}{4c571bfbcc0f052f1c3d4d6606191441}
      \strng{authorfullhash}{4c571bfbcc0f052f1c3d4d6606191441}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents an asymptotic statistical analysis of the null-spectra of two eigen-assisted methods, {MUSIC} [1] and Minimum-Norm [2], for resolving independent closely spaced plane waves in noise. Particular attention is paid to the average deviation of the null-spectra from zero at the true angles of arrival for the plane waves. These deviations are expressed as functions of signal-to-noise ratios, number of array elements, angular separation of emitters, and the number of snapshots. In the case of {MUSIC}. an approximate expression is derived for the resolution threshold of two plane waves with equal power in noise. This result is validated by Monte Carlo simulations.}
      \field{issn}{0096-3518}
      \field{journaltitle}{{IEEE} Transactions on Acoustics, Speech, and Signal Processing}
      \field{month}{4}
      \field{note}{Conference Name: {IEEE} Transactions on Acoustics, Speech, and Signal Processing}
      \field{number}{2}
      \field{title}{The statistical performance of the {MUSIC} and the minimum-norm algorithms in resolving plane waves in noise}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{34}
      \field{year}{1986}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{331\bibrangedash 341}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1109/TASSP.1986.1164815
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/1164815
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/1164815
      \endverb
      \keyw{Covariance matrix,Direction of arrival estimation,Monte Carlo methods,Multiple signal classification,Narrowband,Signal resolution,Signal to noise ratio,Spatial resolution,Spectral analysis,Statistical analysis}
    \endentry
    \entry{king_how_2001}{article}{}
      \name{author}{6}{}{%
        {{hash=5bebdadef6ad12d7772a2172344d6a1a}{%
           family={King},
           familyi={K\bibinitperiod},
           given={Andrew\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=3abeb505a9a92dab060ba5d85c85609f}{%
           family={Kacelnik},
           familyi={K\bibinitperiod},
           given={Oliver},
           giveni={O\bibinitperiod}}}%
        {{hash=7dd1fbd28e9d7acb14800c2e7a051498}{%
           family={Mrsic-Flogel},
           familyi={M\bibinithyphendelim F\bibinitperiod},
           given={Thomas\bibnamedelima D.},
           giveni={T\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=8a8cbf404ec598c9aa00c86bd3deb309}{%
           family={Schnupp},
           familyi={S\bibinitperiod},
           given={Jan\bibnamedelima W.H.},
           giveni={J\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=e9e414ad13eeba14f15b1e2aa9a5ecc8}{%
           family={Parsons},
           familyi={P\bibinitperiod},
           given={Carl\bibnamedelima H.},
           giveni={C\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=fde060dbbae04bcf9a34a857c2e89ac2}{%
           family={Moore},
           familyi={M\bibinitperiod},
           given={David\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \strng{namehash}{ba3f375f3114ce6dd193baa68dab40a2}
      \strng{fullhash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{bibnamehash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{authorbibnamehash}{95e9cd30031d56a560ad8bc16fad7e28}
      \strng{authornamehash}{ba3f375f3114ce6dd193baa68dab40a2}
      \strng{authorfullhash}{95e9cd30031d56a560ad8bc16fad7e28}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The location of a sound source is derived by the auditory system from spatial cues present in the signals at the two ears. These cues include interaural timing and level differences, as well as monaural spectral cues generated by the external ear. The values of these cues vary with individual differences in the shape and dimensions of the head and external ears. We have examined the neurophysiological consequences of these intersubject variations by recording the responses of neurons in ferret primary auditory cortex to virtual sound sources mimicking the animal’s own ears or those of other ferrets. For most neurons, the structure of the spatial response fields changed significantly when acoustic cues measured from another animal were presented. This is consistent with the finding that humans localize less accurately when listening to virtual sounds from other subjects. To examine the role of experience in shaping the ability to localize sound, we have studied the behavioural consequences of altering binaural cues by chronically plugging one ear. Ferrets raised and tested with one ear plugged learned to localize as accurately as control animals, which is consistent with previous findings that the representation of auditory space in the midbrain can accommodate abnormal sensory cues during development. Adaptive changes in behaviour were also observed in adults, particularly if they were provided with regular practice in the localization task. Together, these findings suggest that the neural circuits responsible for sound localization can be recalibrated throughout life.}
      \field{day}{8}
      \field{issn}{1420-3030}
      \field{journaltitle}{Audiology and Neurotology}
      \field{month}{11}
      \field{number}{4}
      \field{shortjournal}{Audiology and Neurotology}
      \field{title}{How Plastic Is Spatial Hearing?}
      \field{urlday}{24}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{6}
      \field{year}{2001}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{182\bibrangedash 186}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1159/000046829
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1159/000046829
      \endverb
      \verb{url}
      \verb https://doi.org/10.1159/000046829
      \endverb
    \endentry
    \entry{kingma_adam_2014}{article}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{fullhash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{bibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorbibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authornamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorfullhash}{a09df9f123146b8e2c7f1134c9496932}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{CoRR}}
      \field{title}{Adam: A Method for Stochastic Optimization}
      \field{volume}{abs/1412.6980}
      \field{year}{2014}
      \field{dateera}{ce}
      \verb{file}
      \verb Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:/home/pawel/Zotero/storage/78ZYK5H2/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:6628106
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:6628106
      \endverb
    \endentry
    \entry{krizhevsky_imagenet_2012}{article}{}
      \name{author}{3}{}{%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=813bd95fe553e6079cd53a567b238287}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey\bibnamedelima E},
           giveni={G\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Curran Associates, Inc.}%
      }
      \strng{namehash}{dd291871bfa8ee64447232f1cca429aa}
      \strng{fullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{bibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authorbibnamehash}{1a23c09aa65b3c2ade45ed18d8127375}
      \strng{authornamehash}{dd291871bfa8ee64447232f1cca429aa}
      \strng{authorfullhash}{1a23c09aa65b3c2ade45ed18d8127375}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{title}{{ImageNet} Classification with Deep Convolutional Neural Networks}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/NKTH38ND/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html
      \endverb
    \endentry
    \entry{kuhn_applied_2013}{book}{}
      \name{author}{2}{}{%
        {{hash=3305789acf03200ed22f154007d4fab9}{%
           family={Kuhn},
           familyi={K\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
        {{hash=8506bc0799a0f764e71f60c7bb5b7fd9}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Kjell},
           giveni={K\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {New York, {NY}}%
      }
      \list{publisher}{1}{%
        {Springer New York}%
      }
      \strng{namehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{fullhash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{bibnamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authorbibnamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authornamehash}{87ef0f02906001a3dbac62a9064e9c1e}
      \strng{authorfullhash}{87ef0f02906001a3dbac62a9064e9c1e}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-1-4614-6848-6 978-1-4614-6849-3}
      \field{langid}{english}
      \field{title}{Applied Predictive Modeling}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-1-4614-6849-3
      \endverb
      \verb{file}
      \verb Kuhn and Johnson - 2013 - Applied Predictive Modeling.pdf:/Users/pawel/Zotero/storage/5S7BX9K4/Kuhn and Johnson - 2013 - Applied Predictive Modeling.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-1-4614-6849-3
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-1-4614-6849-3
      \endverb
    \endentry
    \entry{lecun_handwritten_1989}{article}{}
      \name{author}{7}{}{%
        {{hash=6a1aa6b7eab12b931ca7c7e3f927231d}{%
           family={{LeCun}},
           familyi={L\bibinitperiod},
           given={Yann},
           giveni={Y\bibinitperiod}}}%
        {{hash=824ee0660bd2a40e283a9b8266f0868b}{%
           family={Boser},
           familyi={B\bibinitperiod},
           given={Bernhard},
           giveni={B\bibinitperiod}}}%
        {{hash=2e06fda0238979cad0d24113daf80ed5}{%
           family={Denker},
           familyi={D\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0444ce878492140cb17d6d4f19c2b24d}{%
           family={Henderson},
           familyi={H\bibinitperiod},
           given={Donnie},
           giveni={D\bibinitperiod}}}%
        {{hash=09c5a94a3b4d44c65e19cea92a351737}{%
           family={Howard},
           familyi={H\bibinitperiod},
           given={R.},
           giveni={R\bibinitperiod}}}%
        {{hash=494b3ee863ae780ea5237c5b09b80c0e}{%
           family={Hubbard},
           familyi={H\bibinitperiod},
           given={Wayne},
           giveni={W\bibinitperiod}}}%
        {{hash=4b8d7e185f2fbc444f33953aa1c0a385}{%
           family={Jackel},
           familyi={J\bibinitperiod},
           given={Lawrence},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan-Kaufmann}%
      }
      \strng{namehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{fullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{bibnamehash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{authorbibnamehash}{850352120a3ba111c2cfdcbcc36f7f30}
      \strng{authornamehash}{9e4c6012409dc8dd9b2aa198a2059804}
      \strng{authorfullhash}{850352120a3ba111c2cfdcbcc36f7f30}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present an application of back-propagation networks to hand(cid:173) written digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1 \% error rate and about a 9\% reject rate on zipcode digits provided by the U.S. Postal Service.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{title}{Handwritten Digit Recognition with a Back-Propagation Network}
      \field{urlday}{14}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/LQ2N3GLG/LeCun et al. - 1989 - Handwritten Digit Recognition with a Back-Propagat.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.neurips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
      \verb{url}
      \verb https://proceedings.neurips.cc/paper/1989/hash/53c3bce66e43be4f209556518c2fcb54-Abstract.html
      \endverb
    \endentry
    \entry{lin_network_2013}{article}{}
      \name{author}{3}{}{%
        {{hash=d2827b813d1d73df44360201e3296bea}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod}}}%
        {{hash=8b8805250fb5a57cfbae360547a18706}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=7a7a92b64300d6c39c3ae492b9ded385}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Shuicheng},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{8c2ac34b334a3f7f4ccec03dd423b93f}
      \strng{fullhash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{bibnamehash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{authorbibnamehash}{e1066eda6080c3fe3aab9eb7d6746493}
      \strng{authornamehash}{8c2ac34b334a3f7f4ccec03dd423b93f}
      \strng{authorfullhash}{e1066eda6080c3fe3aab9eb7d6746493}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{CoRR}}
      \field{title}{Network In Network}
      \field{volume}{abs/1312.4400}
      \field{year}{2013}
      \field{dateera}{ce}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/3FFXZK4D/Lin et al. - 2014 - Network In Network.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:16636683
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:16636683
      \endverb
    \endentry
    \entry{noauthor_listen_2023}{online}{}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{title}{{LISTEN} {HRTF} {DATABASE}}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb LISTEN HRTF DATABASE:/Users/pawel/Zotero/storage/66K5BKAI/listen.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://recherche.ircam.fr/equipes/salles/listen/
      \endverb
      \verb{url}
      \verb http://recherche.ircam.fr/equipes/salles/listen/
      \endverb
    \endentry
    \entry{liu_sound_2022}{article}{}
      \name{author}{5}{}{%
        {{hash=4d4148139979b7758963ba11cb70142c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Mengran},
           giveni={M\bibinitperiod}}}%
        {{hash=180fcc4a2bd4ddf6d1cec5f764615e72}{%
           family={Hu},
           familyi={H\bibinitperiod},
           given={Junhao},
           giveni={J\bibinitperiod}}}%
        {{hash=cbc415fc36c599555cb13b0e962f1c25}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=ebe4da51d11cda6425b1b66ec3051050}{%
           family={Jian},
           familyi={J\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod}}}%
        {{hash=f1f055060e271e0e54de057aad92a0df}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{d41c630f43e49f649bdfae6533c60aed}
      \strng{fullhash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{bibnamehash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{authorbibnamehash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \strng{authornamehash}{d41c630f43e49f649bdfae6533c60aed}
      \strng{authorfullhash}{8b184f02f5a2f58e5529a18ff4c7edaa}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Beamforming and its applications in steered-response power ({SRP}) technology, such as steered-response power delay and sum ({SRP}-{DAS}) and steered-response power phase transform ({SRP}-{PHAT}), are widely used in sound source localization. However, their resolution and accuracy still need improvement. A novel beamforming method combining {SRP} and multi-channel cross-correlation coefficient ({MCCC}), {SRP}-{MCCC}, is proposed in this paper to improve the accuracy of direction of arrival ({DOA}). Directional weight ({DW}) is obtained by calculating the {MCCC}. Based on {DW}, suppressed the non-incoming wave direction and gained the incoming wave direction to improve the beamforming capabilities. Then, sound source localizations based on the dual linear array under different conditions were simulated. Compared with {SRP}-{PHAT}, {SRP}-{MCCC} has the advantages of high positioning accuracy, strong spatial directivity and robustness under the different signal–noise ratios ({SNRs}). When the {SNR} is −10 {dB}, the average positioning error of the single-frequency sound source at different coordinates decreases by 5.69\%, and that of the mixed frequency sound sources at the same coordinate decreases by 5.77\%. Finally, the experimental verification was carried out. The results show that the average error of {SRP}-{MCCC} has been reduced by 8.14\% and the positioning accuracy has been significantly improved, which is consistent with the simulation results. This research provides a new idea for further engineering applications of sound source localization based on beamforming.}
      \field{issn}{2072-666X}
      \field{journaltitle}{Micromachines}
      \field{langid}{english}
      \field{month}{7}
      \field{note}{Number: 7 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{7}
      \field{title}{Sound Source Localization Based on Multi-Channel Cross-Correlation Weighted Beamforming}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{13}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1010}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/mi13071010
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/J597NXKN/Liu et al. - 2022 - Sound Source Localization Based on Multi-Channel C.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2072-666X/13/7/1010
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2072-666X/13/7/1010
      \endverb
      \keyw{beamforming,microphone array,multi-channel cross-correlation coefficient,sound source localization}
    \endentry
    \entry{liu_multiple_2018}{article}{}
      \name{author}{5}{}{%
        {{hash=7d8ff4df69095548fd14c2e6e040dfd2}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qingju},
           giveni={Q\bibinitperiod}}}%
        {{hash=8be7c3820bf2af64ef6797042404933a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Wenwu},
           giveni={W\bibinitperiod}}}%
        {{hash=28441c007bd61b6db752461d573f2a74}{%
           family={Campos},
           familyi={C\bibinitperiod},
           given={Teófilo},
           giveni={T\bibinitperiod},
           prefix={de},
           prefixi={d\bibinitperiod}}}%
        {{hash=f32004081bcf11ee769cd92302b54823}{%
           family={Jackson},
           familyi={J\bibinitperiod},
           given={Philip\bibnamedelimb J.\bibnamedelimi B.},
           giveni={P\bibinitperiod\bibinitdelim J\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=5dea3144ba12b0f069a5735888879d6d}{%
           family={Hilton},
           familyi={H\bibinitperiod},
           given={Adrian},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{97431020ac7db7ff55462430cba5b36e}
      \strng{fullhash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{bibnamehash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{authorbibnamehash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \strng{authornamehash}{97431020ac7db7ff55462430cba5b36e}
      \strng{authorfullhash}{9f4013b96d4f9ebb0dbc99d9f8c93497}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In the object-based spatial audio system, positions of the audio objects (e.g., speakers/talkers or voices) presented in the sound scene are required as important metadata attributes for object acquisition and reproduction. Binaural microphones are often used as a physical device to mimic human hearing and to monitor and analyze the scene, including localization and tracking of multiple speakers. The binaural audio tracker, however, is usually prone to the errors caused by room reverberation and background noise. To address this limitation, we present a multimodal tracking method by fusing the binaural audio with depth information (from a depth sensor, e.g., Kinect). More specifically, the probability hypothesis density ({PHD}) filtering framework is first applied to the depth stream, and a novel clutter intensity model is proposed to improve the robustness of the {PHD} filter when an object is occluded either by other objects or due to the limited field of view of the depth sensor. To compensate misdetections in the depth stream, a novel gap filling technique is presented to map audio azimuths obtained from the binaural audio tracker to 3D positions, using speaker-dependent spatial constraints learned from the depth stream. With our proposed method, both the errors in the binaural tracker and the misdetections in the depth tracker can be significantly reduced. Real-room recordings are used to show the improved performance of the proposed method in removing outliers and reducing misdetections.}
      \field{issn}{1941-0077}
      \field{journaltitle}{{IEEE} Transactions on Multimedia}
      \field{month}{7}
      \field{note}{Conference Name: {IEEE} Transactions on Multimedia}
      \field{number}{7}
      \field{title}{Multiple Speaker Tracking in Spatial Audio via {PHD} Filtering and Depth-Audio Fusion}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1767\bibrangedash 1780}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1109/TMM.2017.2777671
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/ETBEG7F9/8119824.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8119824
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8119824
      \endverb
      \keyw{Azimuth,binaural microphones,Clutter,depth and audio,depth sensor,Metadata,Microphones,Multi-person tracking,{PHD} filtering,spatial audio,Target tracking,Three-dimensional displays,Trajectory}
    \endentry
    \entry{ma16c_interspeech}{article}{}
      \name{author}{2}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{fullhash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{bibnamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authorbibnamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authornamehash}{9f93af7b144e77f1b4559cf7d976b821}
      \strng{authorfullhash}{9f93af7b144e77f1b4559cf7d976b821}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{2308-457X}
      \field{journaltitle}{Proc. Interspeech 2016}
      \field{title}{{Speech Localisation in a Multitalker Mixture by Humans and Machines}}
      \field{year}{2016}
      \field{pages}{3359\bibrangedash 3363}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2016-1149
      \endverb
    \endentry
    \entry{ma_robust_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=1230365d4e7c053d32ee1ce21caab89b}{%
           family={Gonzalez},
           familyi={G\bibinitperiod},
           given={Jose\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{fullhash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{bibnamehash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{authorbibnamehash}{10ef4aab764bb9514a44369ebdd82e1e}
      \strng{authornamehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{authorfullhash}{10ef4aab764bb9514a44369ebdd82e1e}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Despite there being a clear evidence for top-down (e.g., attentional) effects in biological spatial hearing, relatively few machine hearing systems exploit the top-down model-based knowledge in sound localization. This paper addresses this issue by proposing a novel framework for the binaural sound localization that combines the model-based information about the spectral characteristics of sound sources and deep neural networks ({DNNs}). A target source model and a background source model are first estimated during a training phase using spectral features extracted from sound signals in isolation. When the identity of the background source is not available, a universal background model can be used. During testing, the source models are used jointly to explain the mixed observations and improve the localization process by selectively weighting source azimuth posteriors output by a {DNN}-based localization system. To address the possible mismatch between the training and testing, a model adaptation process is further employed the on-the-fly during testing, which adapts the background model parameters directly from the noisy observations in an iterative manner. The proposed system, therefore, combines the model-based and data-driven information flow within a single computational framework. The evaluation task involved localization of a target speech source in the presence of an interfering source and room reverberation. Our experiments show that by exploiting the model-based information in this way, the sound localization performance can be improved substantially under various noisy and reverberant conditions.}
      \field{issn}{2329-9304}
      \field{journaltitle}{{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{month}{11}
      \field{note}{Conference Name: {IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{number}{11}
      \field{title}{Robust Binaural Localization of a Target Sound Source by Combining Spectral Source Models and Deep Neural Networks}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{26}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2122\bibrangedash 2131}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASLP.2018.2855960
      \endverb
      \verb{file}
      \verb Accepted Version:/Users/pawel/Zotero/storage/LZQN43AY/Ma et al. - 2018 - Robust Binaural Localization of a Target Sound Sou.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8410799
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8410799
      \endverb
      \keyw{Adaptation models,Auditory system,Azimuth,Binaural source localisation,Biological system modeling,Computational modeling,machine hearing,masking,reverberation,sound source combination,Speech processing,Time-frequency analysis}
    \endentry
    \entry{ma_exploiting_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{fullhash}{c581f172961308c31ced8958a27e3765}
      \strng{bibnamehash}{c581f172961308c31ced8958a27e3765}
      \strng{authorbibnamehash}{c581f172961308c31ced8958a27e3765}
      \strng{authornamehash}{58b0fab47aa83132cfe45c4295606152}
      \strng{authorfullhash}{c581f172961308c31ced8958a27e3765}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents a novel machine-hearing system that exploits deep neural networks (DNNs) and head movements for robust binaural localisation of multiple sources in reverberant environments. DNNs are used to learn the relationship between the source azimuth and binaural cues, consisting of the complete cross-correlation function (CCF) and interaural level differences (ILDs). In contrast to many previous binaural hearing systems, the proposed approach is not restricted to localisation of sound sources in the frontal hemifield. Due to the similarity of binaural cues in the frontal and rear hemifields, front-back confusions often occur. To address this, a head movement strategy is incorporated in the localisation model to help reduce the front-back errors. The proposed DNN system is compared to a Gaussian mixture model (GMM) based system that employs interaural time differences (ITDs) and ILDs as localisation features. Our experiments show that the DNN is able to exploit information in the CCF that is not available in the ITD cue, which together with head movements substantially improves localisation accuracies under challenging acoustic scenarios in which multiple talkers and room reverberation are present.}
      \field{annotation}{Comment: 10 pages}
      \field{issn}{2329-9290, 2329-9304}
      \field{journaltitle}{IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{month}{12}
      \field{note}{arXiv:1904.03001 [cs, eess]}
      \field{number}{12}
      \field{title}{Exploiting {Deep} {Neural} {Networks} and {Head} {Movements} for {Robust} {Binaural} {Localisation} of {Multiple} {Sources} in {Reverberant} {Environments}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{25}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{2444\bibrangedash 2453}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASLP.2017.2750760
      \endverb
      \verb{file}
      \verb arXiv Fulltext PDF:/Users/pawel/Zotero/storage/Q8KYT7PT/Ma et al. - 2017 - Exploiting Deep Neural Networks and Head Movements.pdf:application/pdf;arXiv.org Snapshot:/Users/pawel/Zotero/storage/NXKLQ8NH/1904.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1904.03001
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1904.03001
      \endverb
      \keyw{Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{may_robust_2015}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{bibnamehash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{authorbibnamehash}{240fedddeebda9c63ac23acdd7cdedf0}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{240fedddeebda9c63ac23acdd7cdedf0}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper addresses the problem of localising multiple competing speakers in the presence of room reverberation, where sound sources can be positioned at any azimuth on the horizontal plane. To reduce the amount of front-back confusions which can occur due to the similarity of interaural time differences (ITDs) and interaural level differences (ILDs) in the front and rear hemifield, a machine hearing system is presented which combines supervised learning of binaural cues using multi-conditional training (MCT) with a head movement strategy. A systematic evaluation showed that this approach substantially reduced the amount of front-back confusions in challenging acoustic scenarios. Moreover, the system was able to generalise to a variety of different acoustic conditions not seen during training.}
      \field{journaltitle}{2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})}
      \field{month}{4}
      \field{note}{ISSN: 2379-190X}
      \field{title}{Robust localisation of multiple speakers exploiting head movements and multi-conditional training of binaural cues}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{2679\bibrangedash 2683}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2015.7178457
      \endverb
      \verb{file}
      \verb Accepted Version:/Users/pawel/Zotero/storage/UUF7ABAN/May et al. - 2015 - Robust localisation of multiple speakers exploitin.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/VAZXWS4I/7178457.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/7178457
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/7178457
      \endverb
      \keyw{Acoustics,Auditory system,Azimuth,binaural sound source localisation,generalisation,head movements,Magnetic heads,multi-conditional training,Robustness,Speech,Training}
    \endentry
    \entry{may_probabilistic_2011}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=0973c5121defb9080da8617ef19641f2}{%
           family={Kohlrausch},
           familyi={K\bibinitperiod},
           given={Armin},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{fa2cd709d65b45f32c673018401a4171}
      \strng{bibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authorbibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{fa2cd709d65b45f32c673018401a4171}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Although extensive research has been done in the field of machine-based localization, the degrading effect of reverberation and the presence of multiple sources on localization performance has remained a major problem. Motivated by the ability of the human auditory system to robustly analyze complex acoustic scenes, the associated peripheral stage is used in this paper as a front-end to estimate the azimuth of sound sources based on binaural signals. One classical approach to localize an acoustic source in the horizontal plane is to estimate the interaural time difference (ITD) between both ears by searching for the maximum in the cross-correlation function. Apart from ITDs, the interaural level difference (ILD) can contribute to localization, especially at higher frequencies where the wavelength becomes smaller than the diameter of the head, leading to ambiguous ITD information. The interdependency of ITD and ILD on azimuth is a complex pattern that depends also on the room acoustics, and is therefore learned by azimuth-dependent Gaussian mixture models (GMMs). Multiconditional training is performed to take into account the variability of the binaural features which results from multiple sources and the effect of reverberation. The proposed localization model outperforms state-of-the-art localization techniques in simulated adverse acoustic conditions.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{1}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{1}
      \field{title}{A {Probabilistic} {Model} for {Robust} {Localization} {Based} on a {Binaural} {Auditory} {Front}-{End}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{19}
      \field{year}{2011}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 13}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/TASL.2010.2042128
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/5406118
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/5406118
      \endverb
      \keyw{auditory scene analysis (ASA),Auditory system,Azimuth,binaural,Degradation,Ear,Frequency,Humans,interaural level difference (ILD),interaural time difference (ITD),Layout,Localization,reverberation,Reverberation,Robustness,Signal analysis}
    \endentry
    \entry{may_binaural_2012}{article}{}
      \name{author}{3}{}{%
        {{hash=2a5132ceaf8d99a9f7e5a2646bd2a24d}{%
           family={May},
           familyi={M\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=0973c5121defb9080da8617ef19641f2}{%
           family={Kohlrausch},
           familyi={K\bibinitperiod},
           given={Armin},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{fullhash}{fa2cd709d65b45f32c673018401a4171}
      \strng{bibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authorbibnamehash}{fa2cd709d65b45f32c673018401a4171}
      \strng{authornamehash}{eee598b8bc0119d5883b990d271c6bcd}
      \strng{authorfullhash}{fa2cd709d65b45f32c673018401a4171}
      \field{extraname}{3}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this study, we present a binaural scene analyzer that is able to simultaneously localize, detect and identify a known number of target speakers in the presence of spatially positioned noise sources and reverberation. In contrast to many other binaural cocktail party processors, the proposed system does not require a priori knowledge about the azimuth position of the target speakers. The proposed system consists of three main building blocks: binaural localization, speech source detection, and automatic speaker identification. First, a binaural front-end is used to robustly localize relevant sound source activity. Second, a speech detection module based on missing data classification is employed to determine whether detected sound source activity corresponds to a speaker or to an interfering noise source using a binary mask that is based on spatial evidence supplied by the binaural front-end. Third, a second missing data classifier is used to recognize the speaker identities of all detected speech sources. The proposed system is systematically evaluated in simulated adverse acoustic scenarios. Compared to state-of-the art MFCC recognizers, the proposed model achieves significant speaker recognition accuracy improvements.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{9}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{7}
      \field{title}{A {Binaural} {Scene} {Analyzer} for {Joint} {Localization} and {Recognition} of {Speakers} in the {Presence} of {Interfering} {Noise} {Sources} and {Reverberation}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{2016\bibrangedash 2030}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TASL.2012.2193391
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6178270
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6178270
      \endverb
      \keyw{Acoustics,Auditory system,Automatic speaker recognition,binaural processing,computational auditory scene analysis (CASA),Humans,mask estimation,missing data,Noise,Speech,Speech recognition,Target recognition}
    \endentry
    \entry{miikkulainen_evolving_2017}{article}{}
      \name{author}{11}{}{%
        {{hash=70ad9af6f97993f2ea5c1f65e1985520}{%
           family={Miikkulainen},
           familyi={M\bibinitperiod},
           given={Risto},
           giveni={R\bibinitperiod}}}%
        {{hash=1b3f44c190a77da248d20f1e934c0ccf}{%
           family={Liang},
           familyi={L\bibinitperiod},
           given={Jason\bibnamedelima Zhi},
           giveni={J\bibinitperiod\bibinitdelim Z\bibinitperiod}}}%
        {{hash=b3dd11e9d67e706e42c999b4bdcef69c}{%
           family={Meyerson},
           familyi={M\bibinitperiod},
           given={Elliot},
           giveni={E\bibinitperiod}}}%
        {{hash=f3b9c9f26d0a6f42c13be4baf0a5ab3c}{%
           family={Rawal},
           familyi={R\bibinitperiod},
           given={Aditya},
           giveni={A\bibinitperiod}}}%
        {{hash=b7b839a822e2d965311274b4623951a4}{%
           family={Fink},
           familyi={F\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=414eef3c9431b90ce30abb176cbdf974}{%
           family={Francon},
           familyi={F\bibinitperiod},
           given={Olivier},
           giveni={O\bibinitperiod}}}%
        {{hash=568757b2b2f5c93108afb3d702bdccc7}{%
           family={Raju},
           familyi={R\bibinitperiod},
           given={Bala\bibnamedelima Eshwar},
           giveni={B\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=05d587b2e6ac4c141ba1cbfa4ccc8c8a}{%
           family={Shahrzad},
           familyi={S\bibinitperiod},
           given={Hormoz},
           giveni={H\bibinitperiod}}}%
        {{hash=445863110210846e31553e61b5964e2e}{%
           family={Navruzyan},
           familyi={N\bibinitperiod},
           given={Arshak},
           giveni={A\bibinitperiod}}}%
        {{hash=566d63cf439fdbdbad68beef36f1442d}{%
           family={Duffy},
           familyi={D\bibinitperiod},
           given={Nigel\bibnamedelima P.},
           giveni={N\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=2a778911b7c85660920d24cb845b1b54}{%
           family={Hodjat},
           familyi={H\bibinitperiod},
           given={Babak},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{4c5a30e5bf8c182a99cfb6fa672b76e0}
      \strng{fullhash}{41d1285cb5f435886098946b6735d74b}
      \strng{bibnamehash}{41d1285cb5f435886098946b6735d74b}
      \strng{authorbibnamehash}{41d1285cb5f435886098946b6735d74b}
      \strng{authornamehash}{4c5a30e5bf8c182a99cfb6fa672b76e0}
      \strng{authorfullhash}{41d1285cb5f435886098946b6735d74b}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Evolving Deep Neural Networks}
      \field{volume}{abs/1703.00548}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{file}
      \verb Miikkulainen et al. - 2017 - Evolving Deep Neural Networks.pdf:/home/pawel/Zotero/storage/HMMY2GVB/Miikkulainen et al. - 2017 - Evolving Deep Neural Networks.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:215763844
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:215763844
      \endverb
    \endentry
    \entry{morgan_generalization_1989}{article}{}
      \name{author}{2}{}{%
        {{hash=bc51862d34f106d30f6213c8de089806}{%
           family={Morgan},
           familyi={M\bibinitperiod},
           given={N.},
           giveni={N\bibinitperiod}}}%
        {{hash=0fd43d8b190039eeb3ca2aec409bc50b}{%
           family={Bourlard},
           familyi={B\bibinitperiod},
           given={H.},
           giveni={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Morgan-Kaufmann}%
      }
      \strng{namehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{fullhash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{bibnamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authorbibnamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authornamehash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \strng{authorfullhash}{8c6dca0b4fdd6cec05a0c652ffa8cdb5}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We have done an empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization perfor(cid:173) mance. Two experiments are reported. In one, we use simulated data sets with well-controlled parameters, such as the signal-to-noise ratio of continuous-valued data. In the second, we train the network on vector-quantized mel cepstra from real speech samples. In each case, we use back-propagation to train the feedforward net to discriminate in a multiple class pattern classification problem. We report the results of these studies, and show the application of cross-validation techniques to prevent overfitting.}
      \field{journaltitle}{Advances in Neural Information Processing Systems}
      \field{shorttitle}{Generalization and Parameter Estimation in Feedforward Nets}
      \field{title}{Generalization and Parameter Estimation in Feedforward Nets: Some Experiments}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SZJLY474/Morgan and Bourlard - 1989 - Generalization and Parameter Estimation in Feedfor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://papers.nips.cc/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html
      \endverb
      \verb{url}
      \verb https://papers.nips.cc/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html
      \endverb
    \endentry
    \entry{pan_multi-tone_2021}{article}{}
      \name{author}{5}{}{%
        {{hash=3e268f8b3015c8c1e15220388b8e6695}{%
           family={Pan},
           familyi={P\bibinitperiod},
           given={Zihan},
           giveni={Z\bibinitperiod}}}%
        {{hash=3dac66e08d525d33721786bb7c8dc77b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Malu},
           giveni={M\bibinitperiod}}}%
        {{hash=dc50f1bbfa42a577b5868615c7c55ade}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Jibin},
           giveni={J\bibinitperiod}}}%
        {{hash=b98fe8d59bba1ea85e482bb0551e165e}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jiadong},
           giveni={J\bibinitperiod}}}%
        {{hash=f397ee85433a25b75738faa0b764e496}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haizhou},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{0ec26c86fdd002eb74f730668321f7b8}
      \strng{fullhash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{bibnamehash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{authorbibnamehash}{66ca05c73e797af3bf13ea2862f044c4}
      \strng{authornamehash}{0ec26c86fdd002eb74f730668321f7b8}
      \strng{authorfullhash}{66ca05c73e797af3bf13ea2862f044c4}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mammals exhibit remarkable capability of detecting and localizing sound sources in complex acoustic environments by using binaural cues in the spiking manner. Emulating the auditory process for sound source localization ({SSL}) by mammals, we propose a computational model for accurate and robust {SSL} under the neuromorphic spiking neural network ({SNN}) framework. The center of this model is a Multi-Tone Phase Coding ({MTPC}) scheme, which encodes the interaural time difference ({ITD}) between binaural pure tones into discriminative spike patterns that can be directly classified by {SNNs}. As such, {SSL} can be implemented as an event-driven task on highly efficient, neuromorphic parallel processors. We evaluate the proposed computational model on a directional audio dataset recorded from a microphone array in a realistic acoustic environment with background noise, obstruction, reflection, and other interferences. We report superior localization capability with a mean absolute error ({MAE}) of 1.02° or 100\% classification accuracy with an angle resolution of 5°, which surpasses other {SNN}-based biologically plausible neuromorphic approaches by a relatively large margin and on par with human performance in similar tasks. This study opens up many application opportunities in human-robot interaction where energy efficiency is crucial. As a case study, we successfully deploy the proposed {SSL} system in a robotic platform to track the speaker and orient the robot's attention.}
      \field{issn}{2329-9304}
      \field{journaltitle}{{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{note}{Conference Name: {IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing}
      \field{title}{Multi-Tone Phase Coding of Interaural Time Difference for Sound Source Localization With Spiking Neural Networks}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{29}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2656\bibrangedash 2670}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TASLP.2021.3100684
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/8CJB3YFJ/9502013.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9502013
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9502013
      \endverb
      \keyw{Acoustics,Biological neural networks,Computational modeling,Ear,Encoding,Location awareness,Neural phase coding,Neurons,sound source localization,spiking neural network}
    \endentry
    \entry{pang_multitask_2019}{article}{}
      \name{author}{3}{}{%
        {{hash=1f7d3450b7db4cfe1c10baea8e7141cf}{%
           family={Pang},
           familyi={P\bibinitperiod},
           given={Cheng},
           giveni={C\bibinitperiod}}}%
        {{hash=44a453a69684789133e3b3393f75ef31}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Hong},
           giveni={H\bibinitperiod}}}%
        {{hash=4c142d712e762cc45c88046b8de422c0}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Xiaofei},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{32b0ccc80983b9263a24724cb08d9504}
      \strng{fullhash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{bibnamehash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{authorbibnamehash}{773549cc332fb20a6c3d29a6ba8cc067}
      \strng{authornamehash}{32b0ccc80983b9263a24724cb08d9504}
      \strng{authorfullhash}{773549cc332fb20a6c3d29a6ba8cc067}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization (SSL) is an important technique for many audio processing systems, such as speech enhancement/recognition and human-robot interaction. Although many methods have been proposed for SSL, it still remains a challenging task to achieve accurate localization under adverse acoustic scenarios. In this paper, a novel binaural SSL method based on time-frequency convolutional neural network (TF-CNN) with multitask learning is proposed to simultaneously localize azimuth and elevation under unknown acoustic conditions. First, the interaural phase difference and interaural level difference are extracted from the received binaural signals, which are taken as the input of the proposed SSL neural network. Then, an SSL neural network is designed to map the interaural cues to sound direction, which consists of TF-CNN module and multitask neural network. The TF-CNN module learns and combines the time-frequency information of extracted interaural cues to generate the shared feature for multitask SSL. With the shared feature, a multitask neural network is designed to simultaneously estimate azimuth and elevation through multitask learning, which generates the posterior probability for candidate directions. Finally, the candidate direction with the highest probability is taken as the final direction estimation. The experiments based on public head-related transfer function (HRTF) database demonstrate that the proposed method achieves preferable localization performance compared with other popular methods.}
      \field{issn}{2169-3536}
      \field{journaltitle}{IEEE Access}
      \field{note}{Conference Name: IEEE Access}
      \field{title}{Multitask {Learning} of {Time}-{Frequency} {CNN} for {Sound} {Source} {Localization}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{7}
      \field{year}{2019}
      \field{urldateera}{ce}
      \field{pages}{40725\bibrangedash 40737}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1109/ACCESS.2019.2905617
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8668414
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8668414
      \endverb
      \keyw{Acoustics,Azimuth,convolutional neural network,Estimation,Feature extraction,multitask learning,Neural networks,Noise measurement,Sound source localization,time-frequency,Time-frequency analysis}
    \endentry
    \entry{pavlidi_real-time_2012}{article}{}
      \name{author}{4}{}{%
        {{hash=ce41077d0c7ff5f13f6ad5950ed7da4f}{%
           family={Pavlidi},
           familyi={P\bibinitperiod},
           given={Despoina},
           giveni={D\bibinitperiod}}}%
        {{hash=309b667b2eb9e7c7ef9729c4627a5bb7}{%
           family={Puigt},
           familyi={P\bibinitperiod},
           given={Matthieu},
           giveni={M\bibinitperiod}}}%
        {{hash=dcabc8007736b7781481c464d9a8d076}{%
           family={Griffin},
           familyi={G\bibinitperiod},
           given={Anthony},
           giveni={A\bibinitperiod}}}%
        {{hash=a7ec2ff0e227539444a272f917e98ca2}{%
           family={Mouchtaris},
           familyi={M\bibinitperiod},
           given={Athanasios},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{222f5e3d5aea109f4e0c1fd142bbf9d9}
      \strng{fullhash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{bibnamehash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{authorbibnamehash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \strng{authornamehash}{222f5e3d5aea109f4e0c1fd142bbf9d9}
      \strng{authorfullhash}{a4aee0ed2f54af47223a1e4ec2a72a9b}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a novel real-time adaptative localization approach for multiple sources using a circular array, in order to suppress the localization ambiguities faced with linear arrays, and assuming a weak sound source sparsity which is derived from blind source separation methods. Our proposed method performs very well both in simulations and in real conditions at 50\% real-time.}
      \field{journaltitle}{2012 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{month}{3}
      \field{note}{{ISSN}: 2379-190X}
      \field{title}{Real-time multiple sound source localization using a circular microphone array based on single-source confidence measures}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2625\bibrangedash 2628}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/ICASSP.2012.6288455
      \endverb
      \verb{file}
      \verb Full Text:/home/pawel/Zotero/storage/FXAAV3EW/Pavlidi et al. - 2012 - Real-time multiple sound source localization using.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pawel/Zotero/storage/RI3ZVKSY/6288455.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6288455
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6288455
      \endverb
      \keyw{Speech,Microphones,Estimation,Direction of arrival estimation,multiple source localization,Array signal processing,Arrays,direction of arrival estimation,Real time systems,Time frequency analysis}
    \endentry
    \entry{pocock_practical_1989}{article}{}
      \name{author}{2}{}{%
        {{hash=94d45180df1a571f03dcaec9e8bf020a}{%
           family={Pocock},
           familyi={P\bibinitperiod},
           given={Stuart\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=03eaeecba521abd860ab61c902215778}{%
           family={Hughes},
           familyi={H\bibinitperiod},
           given={Michael\bibnamedelima D.},
           giveni={M\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \strng{namehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{fullhash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{bibnamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authorbibnamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authornamehash}{b89283f0ce6f20bd7fb178b367341b4e}
      \strng{authorfullhash}{b89283f0ce6f20bd7fb178b367341b4e}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article considers some of the practical problems inherent in interim analyses and stopping rules for randomized clinical trials. Topics covered include group sequential designs, trials with unplanned interim analyses, estimation problems in clinical trials with planned interim analyses, and the balance between individual and collective ethics. Particular attention is paid to the fact that clinical trials that stop early are prone to exaggerate the magnitude of treatment effect. Accordingly, a Bayesian "shrinkage" method of analysis is proposed to help quantify the extent to which surprisingly large point and interval estimates of treatment difference in clinical trials that stop early should be moderated.}
      \field{issn}{01972456}
      \field{journaltitle}{Controlled Clinical Trials}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{Controlled Clinical Trials}
      \field{title}{Practical problems in interim analyses, with particular regard to estimation}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{1989}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{209\bibrangedash 221}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1016/0197-2456(89)90059-7
      \endverb
      \verb{file}
      \verb Pocock and Hughes - 1989 - Practical problems in interim analyses, with parti.pdf:/Users/pawel/Zotero/storage/QB3HUWB9/Pocock and Hughes - 1989 - Practical problems in interim analyses, with parti.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/0197245689900597
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/0197245689900597
      \endverb
    \endentry
    \entry{porschmann_spherical_2017}{article}{}
      \name{author}{3}{}{%
        {{hash=3f462ed5d0345dfd7827690f8a2f09b0}{%
           family={Pörschmann},
           familyi={P\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=30e04e0e75a0808329faeec6bd13e328}{%
           family={Arend},
           familyi={A\bibinitperiod},
           given={Johannes},
           giveni={J\bibinitperiod}}}%
        {{hash=3a1c97076f4883503f752159d27936bc}{%
           family={Neidhardt},
           familyi={N\bibinitperiod},
           given={Annika},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{5d7752b4a43e98d9fcd7e4cfe5de4512}
      \strng{fullhash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{bibnamehash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{authorbibnamehash}{a7ed40f485293df8c57f781d2d0e0435}
      \strng{authornamehash}{5d7752b4a43e98d9fcd7e4cfe5de4512}
      \strng{authorfullhash}{a7ed40f485293df8c57f781d2d0e0435}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Head-related transfer functions ({HRTFs}) describe the directional filtering caused by the head, pinna, and torso and are an essential component of binaural synthesis systems. Currently most of these systems are based on far-field {HRTFs} and thus do not consider acoustical specifics of nearby sound sources. One reason might be that full spherical near-field {HRTF} sets are rarely available. In this paper we present an {HRTF} set of a Neumann {KU}100 dummy head and a technical evaluation of the set. The set is freely available for download and contains post-processed impulse responses, captured on a circular and full spherical grid at distances between 0.25 m and 1.50 m. It can be used for psychoacoustic research and for applications where nearby virtual sound sources shall be auralized. Engineering Brief 322 http://www.aes.org/e-lib/browse.cfm?elib=18697}
      \field{day}{21}
      \field{month}{5}
      \field{title}{A Spherical Near-Field {HRTF} Set for Auralization and Psychoacoustic Research}
      \field{year}{2017}
      \field{dateera}{ce}
    \endentry
    \entry{raake_computational_2016}{software}{}
      \name{author}{1}{}{%
        {{hash=2ce4c604978ac9c6ebe8ba1ccfbc5115}{%
           family={Raake},
           familyi={R\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{fullhash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{bibnamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authorbibnamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authornamehash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \strng{authorfullhash}{2ce4c604978ac9c6ebe8ba1ccfbc5115}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{shorttitle}{Two!Eears}
      \field{title}{A computational framework for modelling active exploratory listening that assigns meaning to auditory scenes—reading the world with two ears}
      \field{urlday}{11}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Two!Ears - Project:/Users/pawel/Zotero/storage/ZNPGKEQD/project.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://twoears.eu/project/
      \endverb
      \verb{url}
      \verb http://twoears.eu/project/
      \endverb
    \endentry
    \entry{rumsey_spatial_2002}{article}{}
      \name{author}{1}{}{%
        {{hash=28f5fb444dbefd9ef75d97d49e2e7a11}{%
           family={Rumsey},
           familyi={R\bibinitperiod},
           given={Francis},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{fullhash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{bibnamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authorbibnamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authornamehash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \strng{authorfullhash}{28f5fb444dbefd9ef75d97d49e2e7a11}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Spatial quality in reproduced sound is a subset of the broad topic of sound quality. In the past it has been studied less rigorously than other aspects of reproduced sound quality, leading to a lack of clarity in standard definitions of subjective attributes. Rigor in the physical measurement of sound signals should be matched by equal rigor in semantics relating to subjective evaluation. A scene-based paradigm for the description and assessment of spatial quality is described, which enables clear distinctions to be made between elements of a reproduced sound scene and will assist in the search for related physical parameters.}
      \field{day}{1}
      \field{journaltitle}{Journal of the Audio Engineering Society}
      \field{month}{9}
      \field{shortjournal}{Journal of the Audio Engineering Society}
      \field{shorttitle}{Spatial Quality Evaluation for Reproduced Sound}
      \field{title}{Spatial Quality Evaluation for Reproduced Sound: Terminology, Meaning, and a Scene-Based Paradigm}
      \field{volume}{50}
      \field{year}{2002}
      \field{dateera}{ce}
      \field{pages}{651\bibrangedash 666}
      \range{pages}{16}
    \endentry
    \entry{sainath_deep_2013}{article}{}
      \name{author}{4}{}{%
        {{hash=28a3d000e5cd60656250014708db8ec1}{%
           family={Sainath},
           familyi={S\bibinitperiod},
           given={Tara\bibnamedelima N.},
           giveni={T\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=0d87a656f9bdc99e921c45f73da515b8}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdel-rahman},
           giveni={A\bibinithyphendelim r\bibinitperiod}}}%
        {{hash=8f101126b3acf3a5a0f51d86f0fe89b8}{%
           family={Kingsbury},
           familyi={K\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=e958692c2ffac06aacd0b29bb1482fc8}{%
           family={Ramabhadran},
           familyi={R\bibinitperiod},
           given={Bhuvana},
           giveni={B\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Vancouver, {BC}, Canada}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{217b1453ee030fd4f6f9f33e942041bd}
      \strng{fullhash}{673a11632a92363541f683dee595e107}
      \strng{bibnamehash}{673a11632a92363541f683dee595e107}
      \strng{authorbibnamehash}{673a11632a92363541f683dee595e107}
      \strng{authornamehash}{217b1453ee030fd4f6f9f33e942041bd}
      \strng{authorfullhash}{673a11632a92363541f683dee595e107}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Convolutional Neural Networks ({CNNs}) are an alternative type of neural network that can be used to reduce spectral variations and model spectral correlations which exist in signals. Since speech signals exhibit both of these properties, {CNNs} are a more effective model for speech compared to Deep Neural Networks ({DNNs}). In this paper, we explore applying {CNNs} to large vocabulary speech tasks. First, we determine the appropriate architecture to make {CNNs} effective compared to {DNNs} for {LVCSR} tasks. Speciﬁcally, we focus on how many convolutional layers are needed, what is the optimal number of hidden units, what is the best pooling strategy, and the best input feature type for {CNNs}. We then explore the behavior of neural network features extracted from {CNNs} on a variety of {LVCSR} tasks, comparing {CNNs} to {DNNs} and {GMMs}. We ﬁnd that {CNNs} offer between a 13-30\% relative improvement over {GMMs}, and a 4-12\% relative improvement over {DNNs}, on a 400-hr Broadcast News and 300-hr Switchboard task.}
      \field{eventtitle}{{ICASSP} 2013 - 2013 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{isbn}{978-1-4799-0356-6}
      \field{journaltitle}{2013 {IEEE} International Conference on Acoustics, Speech and Signal Processing}
      \field{langid}{english}
      \field{month}{5}
      \field{title}{Deep convolutional neural networks for {LVCSR}}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{8614\bibrangedash 8618}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2013.6639347
      \endverb
      \verb{file}
      \verb Sainath et al. - 2013 - Deep convolutional neural networks for LVCSR.pdf:/Users/pawel/Zotero/storage/VPCY5FCK/Sainath et al. - 2013 - Deep convolutional neural networks for LVCSR.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6639347/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6639347/
      \endverb
    \endentry
    \entry{senior_mixing_2023}{online}{}
      \name{author}{1}{}{%
        {{hash=9e061e8b013f909e23acd61a09283bba}{%
           family={Senior},
           familyi={S\bibinitperiod},
           given={Mike},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{fullhash}{9e061e8b013f909e23acd61a09283bba}
      \strng{bibnamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authorbibnamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authornamehash}{9e061e8b013f909e23acd61a09283bba}
      \strng{authorfullhash}{9e061e8b013f909e23acd61a09283bba}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{note}{Music recording repository}
      \field{title}{The 'Mixing Secrets' Free Multitrack Download Library}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb The 'Mixing Secrets' Free Multitrack Download Library:/home/pawel/Zotero/storage/C6X26KMY/mtk.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://cambridge-mt.com/ms/mtk/
      \endverb
      \verb{url}
      \verb https://cambridge-mt.com/ms/mtk/
      \endverb
    \endentry
    \entry{shafiee_deep_2016}{article}{}
      \name{author}{3}{}{%
        {{hash=ef3a8fc81a4a7c94dc7f847b2acaac7a}{%
           family={Shafiee},
           familyi={S\bibinitperiod},
           given={Mohammad\bibnamedelima Javad},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=c26b812b70e0f680cfd787bce19ce677}{%
           family={Mishra},
           familyi={M\bibinitperiod},
           given={Akshaya\bibnamedelima Kumar},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=323f171aa619b4a38b71f29bc7608261}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{f39b83ba0ced09aa5f98c27216da1625}
      \strng{fullhash}{dadca4a43c74d58400fd62408e726275}
      \strng{bibnamehash}{dadca4a43c74d58400fd62408e726275}
      \strng{authorbibnamehash}{dadca4a43c74d58400fd62408e726275}
      \strng{authornamehash}{f39b83ba0ced09aa5f98c27216da1625}
      \strng{authorfullhash}{dadca4a43c74d58400fd62408e726275}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Neural Processing Letters}
      \field{title}{Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks}
      \field{volume}{48}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{pages}{603\bibrangedash 613}
      \range{pages}{11}
      \verb{file}
      \verb Shafiee et al. - 2017 - Deep Learning with Darwin Evolutionary Synthesis .pdf:/home/pawel/Zotero/storage/8DVHJEJP/Shafiee et al. - 2017 - Deep Learning with Darwin Evolutionary Synthesis .pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:8106771
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:8106771
      \endverb
    \endentry
    \entry{spagnol_viking_2020}{article}{}
      \name{author}{3}{}{%
        {{hash=8f15119fd3a0cd98fd0a5caa95280a64}{%
           family={Spagnol},
           familyi={S\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
        {{hash=d25396b244a57d3e2dc694a2ea4583dc}{%
           family={Miccini},
           familyi={M\bibinitperiod},
           given={Riccardo},
           giveni={R\bibinitperiod}}}%
        {{hash=7199e3a9f216c59a5316c586e01ce692}{%
           family={Unnthorsson},
           familyi={U\bibinitperiod},
           given={Runar},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{fullhash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{bibnamehash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{authorbibnamehash}{91e03d1b7af2b20377effa7aa2f3d450}
      \strng{authornamehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{authorfullhash}{91e03d1b7af2b20377effa7aa2f3d450}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{The Viking {HRTF} Dataset v2}
      \field{year}{2020}
      \field{dateera}{ce}
      \verb{file}
      \verb Spagnol et al. - The Viking HRTF Dataset v2.pdf:/Users/pawel/Zotero/storage/HSJ5D7ZM/Spagnol et al. - The Viking HRTF Dataset v2.pdf:application/pdf
      \endverb
    \endentry
    \entry{spagnol_viking_2019}{article}{}
      \name{author}{4}{}{%
        {{hash=8f15119fd3a0cd98fd0a5caa95280a64}{%
           family={Spagnol},
           familyi={S\bibinitperiod},
           given={Simone},
           giveni={S\bibinitperiod}}}%
        {{hash=84e308ec54121553762a47530bfc1049}{%
           family={Purkhús},
           familyi={P\bibinitperiod},
           given={Kristján\bibnamedelima Bjarki},
           giveni={K\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=3113cf33f941597ff346efc2ebdbeb6a}{%
           family={Unnthórsson},
           familyi={U\bibinitperiod},
           given={Rúnar},
           giveni={R\bibinitperiod}}}%
        {{hash=d12aa906b87c8ab46f44480f545bf962}{%
           family={Björnsson},
           familyi={B\bibinitperiod},
           given={Sverrir\bibnamedelima Karl},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{fullhash}{76cac25650a0a227f54918f87b8f930b}
      \strng{bibnamehash}{76cac25650a0a227f54918f87b8f930b}
      \strng{authorbibnamehash}{76cac25650a0a227f54918f87b8f930b}
      \strng{authornamehash}{6d480d1a63fa07fae3b5f3cb34e6c179}
      \strng{authorfullhash}{76cac25650a0a227f54918f87b8f930b}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes the Viking {HRTF} dataset, a collection of head-related transfer functions ({HRTFs}) measured at the University of Iceland. The dataset includes fullsphere {HRTFs} measured on a dense spatial grid (1513 positions) with a {KEMAR} mannequin with 20 different artiﬁcial left pinnae attached, one at a time. The artiﬁcial pinnae were previously obtained through a custom molding procedure from 20 different lifelike human heads. The analyses of results reported here suggest that the collected acoustical measurements are robust, reproducible, and faithful to reference {KEMAR} {HRTFs}, and that material hardness has a negligible impact on the measurements compared to pinna shape. The purpose of the present collection, which is available for free download, is to provide accurate input data for future investigations on the relation between {HRTFs} and anthropometric data through machine learning techniques or other state-of-the-art methodologies.}
      \field{langid}{english}
      \field{title}{{THE} {VIKING} {HRTF} {DATASET}}
      \field{year}{2019}
      \field{dateera}{ce}
      \verb{file}
      \verb Spagnol et al. - THE VIKING HRTF DATASET.pdf:/Users/pawel/Zotero/storage/58JKR5Y6/Spagnol et al. - THE VIKING HRTF DATASET.pdf:application/pdf
      \endverb
    \endentry
    \entry{srivastava_dropout_2014}{article}{}
      \name{author}{5}{}{%
        {{hash=6a147afa4569ce6cf23c0436e65d8486}{%
           family={Srivastava},
           familyi={S\bibinitperiod},
           given={Nitish},
           giveni={N\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
        {{hash=c5e3a676e2ac1164b3afcd539c131fc9}{%
           family={Krizhevsky},
           familyi={K\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod}}}%
        {{hash=8d569d1d5b8b5a7836017a98b430f959}{%
           family={Sutskever},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{fullhash}{2850768171a28ccacd146c300f66f57d}
      \strng{bibnamehash}{2850768171a28ccacd146c300f66f57d}
      \strng{authorbibnamehash}{2850768171a28ccacd146c300f66f57d}
      \strng{authornamehash}{4d6dba595c04c09619c7c1c0038d5b6b}
      \strng{authorfullhash}{2850768171a28ccacd146c300f66f57d}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{56}
      \field{title}{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}
      \field{volume}{15}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{pages}{1929\bibrangedash 1958}
      \range{pages}{30}
      \verb{urlraw}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
      \verb{url}
      \verb http://jmlr.org/papers/v15/srivastava14a.html
      \endverb
    \endentry
    \entry{stanley_evolving_2002}{article}{}
      \name{author}{2}{}{%
        {{hash=cd20c341249f4e0cd9cb16431e439823}{%
           family={Stanley},
           familyi={S\bibinitperiod},
           given={Kenneth\bibnamedelima O.},
           giveni={K\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=70ad9af6f97993f2ea5c1f65e1985520}{%
           family={Miikkulainen},
           familyi={M\bibinitperiod},
           given={Risto},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{fullhash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{bibnamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authorbibnamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authornamehash}{3546041f24ccbba148011c7ca7e4a95c}
      \strng{authorfullhash}{3546041f24ccbba148011c7ca7e4a95c}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, {NeuroEvolution} of Augmenting Topologies ({NEAT}), which outperforms the best ﬁxed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efﬁciency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is signiﬁcantly faster learning. {NEAT} is also an important contribution to {GAs} because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.}
      \field{issn}{1063-6560, 1530-9304}
      \field{journaltitle}{Evolutionary Computation}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{2}
      \field{shortjournal}{Evolutionary Computation}
      \field{title}{Evolving Neural Networks through Augmenting Topologies}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2002}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{99\bibrangedash 127}
      \range{pages}{29}
      \verb{doi}
      \verb 10.1162/106365602320169811
      \endverb
      \verb{file}
      \verb Stanley and Miikkulainen - 2002 - Evolving Neural Networks through Augmenting Topolo.pdf:/Users/pawel/Zotero/storage/TWUN8YPM/Stanley and Miikkulainen - 2002 - Evolving Neural Networks through Augmenting Topolo.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://direct.mit.edu/evco/article/10/2/99-127/1123
      \endverb
      \verb{url}
      \verb https://direct.mit.edu/evco/article/10/2/99-127/1123
      \endverb
    \endentry
    \entry{MATLAB_Audio_Toolbox}{software}{}
      \name{author}{1}{}{%
        {{hash=8687eae34a3830fc0c113d9d65382e90}{%
           family={{The MathWorks Inc.}},
           familyi={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Natick, Massachusetts, United States}%
      }
      \strng{namehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{fullhash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{bibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorbibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authornamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorfullhash}{8687eae34a3830fc0c113d9d65382e90}
      \field{extraname}{1}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradate}{1}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Audio Toolbox version: 9.13.0 (R2022b)}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.mathworks.com
      \endverb
      \verb{url}
      \verb https://www.mathworks.com
      \endverb
    \endentry
    \entry{MATLAB}{software}{}
      \name{author}{1}{}{%
        {{hash=8687eae34a3830fc0c113d9d65382e90}{%
           family={{The MathWorks Inc.}},
           familyi={T\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Natick, Massachusetts, United States}%
      }
      \strng{namehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{fullhash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{bibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorbibnamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authornamehash}{8687eae34a3830fc0c113d9d65382e90}
      \strng{authorfullhash}{8687eae34a3830fc0c113d9d65382e90}
      \field{extraname}{2}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradate}{2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{MATLAB version: 9.13.0 (R2022b)}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.mathworks.com
      \endverb
      \verb{url}
      \verb https://www.mathworks.com
      \endverb
    \endentry
    \entry{thiemann_speech_2016}{article}{}
      \name{author}{5}{}{%
        {{hash=1f5ffdd0f478e16fd042ef7d550cc264}{%
           family={Thiemann},
           familyi={T\bibinitperiod},
           given={Joachim},
           giveni={J\bibinitperiod}}}%
        {{hash=28c765657da3a93ef91cad6817ebab3f}{%
           family={Müller},
           familyi={M\bibinitperiod},
           given={Menno},
           giveni={M\bibinitperiod}}}%
        {{hash=fc3f4e6ea75c65c0ab0fbe963d608418}{%
           family={Marquardt},
           familyi={M\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=dd004cfd0c0feeb261ad0f703e2bbc8c}{%
           family={Doclo},
           familyi={D\bibinitperiod},
           given={Simon},
           giveni={S\bibinitperiod}}}%
        {{hash=ed4d810aedd1c67697714e13a4d3573b}{%
           family={Par},
           familyi={P\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod},
           prefix={van\bibnamedelima de},
           prefixi={v\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
      }
      \strng{namehash}{b6c6be5145f8265399211b85b86f06d3}
      \strng{fullhash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{bibnamehash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{authorbibnamehash}{617c87d8c04985002c1c4d5a637ed37b}
      \strng{authornamehash}{b6c6be5145f8265399211b85b86f06d3}
      \strng{authorfullhash}{617c87d8c04985002c1c4d5a637ed37b}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Modern binaural hearing aids utilize multimicrophone speech enhancement algorithms to enhance signals in terms of signal-to-noise ratio, but they may distort the interaural cues that allow the user to localize sources, in particular, suppressed interfering sources or background noise. In this paper, we present a novel algorithm that enhances the target signal while aiming to maintain the correct spatial rendering of both the target signal as well as the background noise. We use a bimodal approach, where a signal-to-noise ratio (SNR) estimator controls a binary decision mask, switching between the output signals of a binaural minimum variance distortionless response (MVDR) beamformer and scaled reference microphone signals. We show that the proposed selective binaural beamformer (SBB) can enhance the target signal while maintaining the overall spatial rendering of the acoustic scene.}
      \field{issn}{1687-6180}
      \field{journaltitle}{EURASIP Journal on Advances in Signal Processing}
      \field{month}{2}
      \field{number}{1}
      \field{title}{Speech enhancement for multimicrophone binaural hearing aids aiming to preserve the spatial auditory scene}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2016}
      \field{year}{2016}
      \field{urldateera}{ce}
      \field{pages}{12}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13634-016-0314-6
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/HK2UGN3E/Thiemann et al. - 2016 - Speech enhancement for multimicrophone binaural he.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/MPJJ7SUT/s13634-016-0314-6.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13634-016-0314-6
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13634-016-0314-6
      \endverb
      \keyw{Bilateral hearing aids,Binaural hearing aids,Binaural MVDR,Hearing aids}
    \endentry
    \entry{thomas_analyzing_2014}{article}{}
      \name{author}{4}{}{%
        {{hash=0a327007a0b097a2d8bfa1b4eb2086d1}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod}}}%
        {{hash=e8ffe1c362ac7ce7c88ccafa53a92285}{%
           family={Ganapathy},
           familyi={G\bibinitperiod},
           given={Sriram},
           giveni={S\bibinitperiod}}}%
        {{hash=ce2fc3785ea81b5ffeca97427d45bbab}{%
           family={Saon},
           familyi={S\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=b20d63e6bf6d2e637b4f5915a4accb2f}{%
           family={Soltau},
           familyi={S\bibinitperiod},
           given={Hagen},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Florence, Italy}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{7c9d94120dea55e4ba058bbef333f39d}
      \strng{fullhash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{bibnamehash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{authorbibnamehash}{c1dc657ec4b58b8289ba2098adba0488}
      \strng{authornamehash}{7c9d94120dea55e4ba058bbef333f39d}
      \strng{authorfullhash}{c1dc657ec4b58b8289ba2098adba0488}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Convolutional neural networks ({CNN}) are extensions to deep neural networks ({DNN}) which are used as alternate acoustic models with state-of-the-art performances for speech recognition. In this paper, {CNNs} are used as acoustic models for speech activity detection ({SAD}) on data collected over noisy radio communication channels. When these {SAD} models are tested on audio recorded from radio channels not seen during training, there is severe performance degradation. We attribute this degradation to mismatches between the two dimensional ﬁlters learnt in the initial {CNN} layers and the novel channel data. Using a small amount of supervised data from the novel channels, the ﬁlters can be adapted to provide signiﬁcant improvements in {SAD} performance. In mismatched acoustic conditions, the adapted models provide signiﬁcant improvements (about 10-25\%) relative to conventional {DNN}-based {SAD} systems. These results illustrate that {CNNs} have a considerable advantage in fast adaptation for acoustic modeling in these settings.}
      \field{eventtitle}{{ICASSP} 2014 - 2014 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{isbn}{978-1-4799-2893-4}
      \field{journaltitle}{2014 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{langid}{english}
      \field{month}{5}
      \field{title}{Analyzing convolutional neural networks for speech activity detection in mismatched acoustic conditions}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2519\bibrangedash 2523}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2014.6854054
      \endverb
      \verb{file}
      \verb Thomas et al. - 2014 - Analyzing convolutional neural networks for speech.pdf:/Users/pawel/Zotero/storage/RAIR3LKP/Thomas et al. - 2014 - Analyzing convolutional neural networks for speech.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6854054/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6854054/
      \endverb
    \endentry
    \entry{python}{book}{}
      \name{author}{2}{}{%
        {{hash=e504145eff12cd8803c227c919ccfacd}{%
           family={Van\bibnamedelima Rossum},
           familyi={V\bibinitperiod\bibinitdelim R\bibinitperiod},
           given={Guido},
           giveni={G\bibinitperiod}}}%
        {{hash=0b735fb6ad359aa95b3bac4d5567af6f}{%
           family={Drake},
           familyi={D\bibinitperiod},
           given={Fred\bibnamedelima L.},
           giveni={F\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Scotts Valley, CA}%
      }
      \list{publisher}{1}{%
        {CreateSpace}%
      }
      \strng{namehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{fullhash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{bibnamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authorbibnamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authornamehash}{190e2e6e0d73bf5671d8927d221674e7}
      \strng{authorfullhash}{190e2e6e0d73bf5671d8927d221674e7}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{1441412697}
      \field{title}{Python 3 Reference Manual}
      \field{year}{2009}
    \endentry
    \entry{vecchiotti_end--end_2019}{article}{}
      \name{author}{4}{}{%
        {{hash=dd2688b271dbbecf993a80c6a385c9b2}{%
           family={Vecchiotti},
           familyi={V\bibinitperiod},
           given={Paolo},
           giveni={P\bibinitperiod}}}%
        {{hash=bc16016f182e265b79ec758885f45f27}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Ning},
           giveni={N\bibinitperiod}}}%
        {{hash=a2f00650504fc0bb5efb1ec394adbaa4}{%
           family={Squartini},
           familyi={S\bibinitperiod},
           given={Stefano},
           giveni={S\bibinitperiod}}}%
        {{hash=8bbee333c5da8578412d448adc4f0ae0}{%
           family={Brown},
           familyi={B\bibinitperiod},
           given={Guy\bibnamedelima J.},
           giveni={G\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \strng{namehash}{c41b65bcb2cf677a54f2d74dc2937514}
      \strng{fullhash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{bibnamehash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{authorbibnamehash}{cc087543c1a49a288ee1cffbe889f286}
      \strng{authornamehash}{c41b65bcb2cf677a54f2d74dc2937514}
      \strng{authorfullhash}{cc087543c1a49a288ee1cffbe889f286}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})}
      \field{title}{End-to-end Binaural Sound Localisation from the Raw Waveform}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{pages}{451\bibrangedash 455}
      \range{pages}{5}
      \verb{file}
      \verb arXiv Fulltext PDF:/home/pawel/Zotero/storage/73M9MTKE/Vecchiotti et al. - 2019 - End-to-end Binaural Sound Localisation from the Ra.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:102481341
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:102481341
      \endverb
    \endentry
    \entry{vera-diaz_towards_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=2f436749ac56ef83f981f1f136ac6ab8}{%
           family={Vera-Diaz},
           familyi={V\bibinithyphendelim D\bibinitperiod},
           given={Juan\bibnamedelima Manuel},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=688214d07bf58f2c70a1687eb96b152c}{%
           family={Pizarro},
           familyi={P\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=da7e2e93106543998c55fdde339f7460}{%
           family={Macias-Guarasa},
           familyi={M\bibinithyphendelim G\bibinitperiod},
           given={Javier},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{c4883035c38b3126265735ffe52e988a}
      \strng{fullhash}{66cad649c3e2462c3be1928092d78848}
      \strng{bibnamehash}{66cad649c3e2462c3be1928092d78848}
      \strng{authorbibnamehash}{66cad649c3e2462c3be1928092d78848}
      \strng{authornamehash}{c4883035c38b3126265735ffe52e988a}
      \strng{authorfullhash}{66cad649c3e2462c3be1928092d78848}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper presents a novel approach for indoor acoustic source localization using microphone arrays, based on a Convolutional Neural Network ({CNN}). In the proposed solution, the {CNN} is designed to directly estimate the three-dimensional position of a single acoustic source using the raw audio signal as the input information and avoiding the use of hand-crafted audio features. Given the limited amount of available localization data, we propose, in this paper, a training strategy based on two steps. We first train our network using semi-synthetic data generated from close talk speech recordings. We simulate the time delays and distortion suffered in the signal that propagate from the source to the array of microphones. We then fine tune this network using a small amount of real data. Our experimental results, evaluated on a publicly available dataset recorded in a real room, show that this approach is able to produce networks that significantly improve existing localization methods based on {SRP}-{PHAT} strategies and also those presented in very recent proposals based on Convolutional Recurrent Neural Networks ({CRNN}). In addition, our experiments show that the performance of our {CNN} method does not show a relevant dependency on the speaker’s gender, nor on the size of the signal window being used.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{langid}{english}
      \field{month}{10}
      \field{note}{Number: 10 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{10}
      \field{shorttitle}{Towards End-to-End Acoustic Localization Using Deep Learning}
      \field{title}{Towards End-to-End Acoustic Localization Using Deep Learning: From Audio Signals to Source Position Coordinates}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{18}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3418}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/s18103418
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/QWRE2HZA/Vera-Diaz et al. - 2018 - Towards End-to-End Acoustic Localization Using Dee.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/18/10/3418
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/18/10/3418
      \endverb
      \keyw{convolutional neural networks,deep learning,acoustic source localization,microphone arrays}
    \endentry
    \entry{2020SciPy-NMeth}{article}{}
      \name{author}{35}{}{%
        {{hash=18703a2bb6a62484483c193a212da2f8}{%
           family={Virtanen},
           familyi={V\bibinitperiod},
           given={Pauli},
           giveni={P\bibinitperiod}}}%
        {{hash=646fbfe08374cc41c2f9bd971d8c4725}{%
           family={Gommers},
           familyi={G\bibinitperiod},
           given={Ralf},
           giveni={R\bibinitperiod}}}%
        {{hash=d500f4849030f34359cdb3e1513acf83}{%
           family={Oliphant},
           familyi={O\bibinitperiod},
           given={Travis\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=35bb9c71f55048509a3e9018c349ed73}{%
           family={Haberland},
           familyi={H\bibinitperiod},
           given={Matt},
           giveni={M\bibinitperiod}}}%
        {{hash=fbb0c40f5d70be8ce47ce9daafdf5749}{%
           family={Reddy},
           familyi={R\bibinitperiod},
           given={Tyler},
           giveni={T\bibinitperiod}}}%
        {{hash=9fd9ed8466bbb96364ae008f2a665e6e}{%
           family={Cournapeau},
           familyi={C\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=09a667aa6a26526bfcccb2676a494e55}{%
           family={Burovski},
           familyi={B\bibinitperiod},
           given={Evgeni},
           giveni={E\bibinitperiod}}}%
        {{hash=3d6efaaa3d9682e20787eb06ff70a3d7}{%
           family={Peterson},
           familyi={P\bibinitperiod},
           given={Pearu},
           giveni={P\bibinitperiod}}}%
        {{hash=4c7e4c94b846fa41e2fc0a88e0dc656d}{%
           family={Weckesser},
           familyi={W\bibinitperiod},
           given={Warren},
           giveni={W\bibinitperiod}}}%
        {{hash=7447cb057596bc2645d3980bb04f5c78}{%
           family={Bright},
           familyi={B\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod}}}%
        {{hash=1b5d87f5a394ee92a6edb4c1de058cab}{%
           family={{van der Walt}},
           familyi={v\bibinitperiod},
           given={Stéfan\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=626cc151613864abeb653c0d8172d98c}{%
           family={Brett},
           familyi={B\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=57849e8550281b202bd611bf6f11e14b}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Joshua},
           giveni={J\bibinitperiod}}}%
        {{hash=b053969d2c6a9ec8689980fb6463cd56}{%
           family={Millman},
           familyi={M\bibinitperiod},
           given={K.\bibnamedelimi Jarrod},
           giveni={K\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=fbaf80580622bd40577f4a6d38021c0a}{%
           family={Mayorov},
           familyi={M\bibinitperiod},
           given={Nikolay},
           giveni={N\bibinitperiod}}}%
        {{hash=7bcf847eaccba039f7a4523540673aea}{%
           family={Nelson},
           familyi={N\bibinitperiod},
           given={Andrew\bibnamedelimb R.\bibnamedelimi J.},
           giveni={A\bibinitperiod\bibinitdelim R\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=4b3d26f886661aa723985bcfd835ba18}{%
           family={Jones},
           familyi={J\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=9ad1d38817acd2f00cb7f324ec7d37ea}{%
           family={Kern},
           familyi={K\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=8d336f110675c46226ece1db501ce712}{%
           family={Larson},
           familyi={L\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
        {{hash=65b1934a87acb0abe09c469aaf11c326}{%
           family={Carey},
           familyi={C\bibinitperiod},
           given={C\bibnamedelima J},
           giveni={C\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=9989e8a18827e34b15112d671f52bd35}{%
           family={Polat},
           familyi={P\bibinitperiod},
           given={İlhan},
           giveni={İ\bibinitperiod}}}%
        {{hash=b8b88d61c79de60e6e1b5d44e03f5dec}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=bf4be16325cb4f641345ca394443fd18}{%
           family={Moore},
           familyi={M\bibinitperiod},
           given={Eric\bibnamedelima W.},
           giveni={E\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=0fd9a0e34f1b2adda41357c948d14986}{%
           family={{VanderPlas}},
           familyi={V\bibinitperiod},
           given={Jake},
           giveni={J\bibinitperiod}}}%
        {{hash=c6a95a8ced3b86b4e7e60a74bc6ebf5a}{%
           family={Laxalde},
           familyi={L\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod}}}%
        {{hash=85242652d69220e83cf71ceb8d90a8cb}{%
           family={Perktold},
           familyi={P\bibinitperiod},
           given={Josef},
           giveni={J\bibinitperiod}}}%
        {{hash=5bca159e697db439e23b8947dfa4b614}{%
           family={Cimrman},
           familyi={C\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
        {{hash=70b659f5067a8a2efbee66f770681598}{%
           family={Henriksen},
           familyi={H\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=fa5163c76600eb11a4d07a28f0701cb0}{%
           family={Quintero},
           familyi={Q\bibinitperiod},
           given={E.\bibnamedelimi A.},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=db2b4761cc46be347b418e68660c9554}{%
           family={Harris},
           familyi={H\bibinitperiod},
           given={Charles\bibnamedelima R.},
           giveni={C\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
        {{hash=7d86aea5ad1f2b4e27f2f014c71712c2}{%
           family={Archibald},
           familyi={A\bibinitperiod},
           given={Anne\bibnamedelima M.},
           giveni={A\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=3876f7c3dbbb1a17823dcd135d07cfc6}{%
           family={Ribeiro},
           familyi={R\bibinitperiod},
           given={Antônio\bibnamedelima H.},
           giveni={A\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=bab4e5caee2d67831e464ce575022b37}{%
           family={Pedregosa},
           familyi={P\bibinitperiod},
           given={Fabian},
           giveni={F\bibinitperiod}}}%
        {{hash=8928c27c900ec0b05492cbba126c5196}{%
           family={{van Mulbregt}},
           familyi={v\bibinitperiod},
           given={Paul},
           giveni={P\bibinitperiod}}}%
        {{hash=aa8bf7a30651c7bc3d20ff02fc843dd9}{%
           family={{SciPy 1.0 Contributors}},
           familyi={S\bibinitperiod}}}%
      }
      \strng{namehash}{f252038edd7f112d75da3bf0c1edecbc}
      \strng{fullhash}{371a3f5cdbab4f8c68cab2e17d157950}
      \strng{bibnamehash}{0cdbee7bc557397e3e6f406a603f21f7}
      \strng{authorbibnamehash}{0cdbee7bc557397e3e6f406a603f21f7}
      \strng{authornamehash}{f252038edd7f112d75da3bf0c1edecbc}
      \strng{authorfullhash}{371a3f5cdbab4f8c68cab2e17d157950}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Nature Methods}
      \field{title}{{{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in Python}}
      \field{volume}{17}
      \field{year}{2020}
      \field{pages}{261\bibrangedash 272}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1038/s41592-019-0686-2
      \endverb
    \endentry
    \entry{wang_binaural_2020}{article}{}
      \name{author}{5}{}{%
        {{hash=49a19e08791a3dc09c932ff975949361}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jing},
           giveni={J\bibinitperiod}}}%
        {{hash=57cf8531003f9d0c22b8a30358523ffc}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Jin},
           giveni={J\bibinitperiod}}}%
        {{hash=81e718542697d8cb9b28022566aa3a73}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Kai},
           giveni={K\bibinitperiod}}}%
        {{hash=e6a4eb28abe7c87f188cdfbca1e0d60b}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod}}}%
        {{hash=74f843d34d0fc73c4784f6fb01462125}{%
           family={Kuang},
           familyi={K\bibinitperiod},
           given={Jingming},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{bb255b96d1bb6f677f7841b684efd08c}
      \strng{fullhash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{bibnamehash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{authorbibnamehash}{9b8aa841b860cee3f7ee3708c718fd42}
      \strng{authornamehash}{bb255b96d1bb6f677f7841b684efd08c}
      \strng{authorfullhash}{9b8aa841b860cee3f7ee3708c718fd42}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Binaural sound source localization is an important and widely used perceptually based method and it has been applied to machine learning studies by many researchers based on head-related transfer function ({HRTF}). Because the {HRTF} is closely related to human physiological structure, the {HRTFs} vary between individuals. Related machine learning studies to date tend to focus on binaural localization in reverberant or noisy environments, or in conditions with multiple simultaneously active sound sources. In contrast, mismatched {HRTF} condition, in which the {HRTFs} used to generate the training and test sets are different, is rarely studied. This mismatch leads to a degradation of localization performance. A basic solution to this problem is to introduce more data to improve generalization performance, which requires a lot. However, simply increasing the data volume will result in data-inefficiency. In this paper, we propose a data-efficient method based on deep neural network ({DNN}) and clustering to improve binaural localization performance in the mismatched {HRTF} condition. Firstly, we analyze the relationship between binaural cues and the sound source localization with a classification {DNN}. Different {HRTFs} are used to generate training and test sets, respectively. On this basis, we study the localization performance of {DNN} model trained by each training set on different test sets. The result shows that the localization performance of the same model on different test sets is different, while the localization performance of different models on the same test set may be similar. The result also shows a clustering trend. Secondly, different {HRTFs} are divided into several clusters. Finally, the corresponding {HRTFs} of each cluster center are selected to generate a new training set and to train a more generalized {DNN} model. The experimental results show that the proposed method achieves better generalization performance than the baseline methods in the mismatched {HRTF} condition and has almost equal performance to the {DNN} trained with a large number of {HRTFs}, which means the proposed method is data-efficient.}
      \field{day}{10}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{month}{2}
      \field{number}{1}
      \field{shortjournal}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{title}{Binaural sound localization based on deep neural network and affinity propagation clustering in mismatched {HRTF} condition}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2020}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-020-0171-y
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/AXJ7NQJI/Wang et al. - 2020 - Binaural sound localization based on deep neural n.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/HXP2Q4IJ/s13636-020-0171-y.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13636-020-0171-y
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13636-020-0171-y
      \endverb
      \keyw{Affinity propagation,Binaural localization,Clustering,Deep neural network}
    \endentry
    \entry{watanabe_dataset_2014}{article}{}
      \name{author}{5}{}{%
        {{hash=e2cddc8be765eeab771c7cee269f7a0c}{%
           family={Watanabe},
           familyi={W\bibinitperiod},
           given={Kanji},
           giveni={K\bibinitperiod}}}%
        {{hash=100e04c7fb95463997399ecb8faf93ea}{%
           family={Iwaya},
           familyi={I\bibinitperiod},
           given={Yukio},
           giveni={Y\bibinitperiod}}}%
        {{hash=8746e9aeb5407651bfca91873dcf4d66}{%
           family={Suzuki},
           familyi={S\bibinitperiod},
           given={Yôiti},
           giveni={Y\bibinitperiod}}}%
        {{hash=2a79543e343d481672d9ce4aae3b248b}{%
           family={Takane},
           familyi={T\bibinitperiod},
           given={Shouichi},
           giveni={S\bibinitperiod}}}%
        {{hash=cf330fd18c81c9b809b81f5380e424ea}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Sojun},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{85f27c56550690dcdab68eeec123a1d7}
      \strng{fullhash}{ed1ff829f95686106003ddf865222379}
      \strng{bibnamehash}{ed1ff829f95686106003ddf865222379}
      \strng{authorbibnamehash}{ed1ff829f95686106003ddf865222379}
      \strng{authornamehash}{85f27c56550690dcdab68eeec123a1d7}
      \strng{authorfullhash}{ed1ff829f95686106003ddf865222379}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we describe a dataset of head-related transfer functions ({HRTFs}) measured at the Research Institute of Electrical Communications, Tohoku University. The current dataset includes {HRTFs} for 105 subjects at 72 azimuths Â 13 elevations of spherical coordinates. Anthropometric data for 39 subjects are also included. The measurement and postprocessing methods are outlined in this paper. These data will be freely accessible for nonproﬁt academic purposes via the Internet. Moreover, this dataset will be included in an international joint project to gather several {HRTF} datasets in a uniﬁed data format.}
      \field{issn}{1346-3969, 1347-5177}
      \field{journaltitle}{Acoustical Science and Technology}
      \field{langid}{english}
      \field{number}{3}
      \field{shortjournal}{Acoust. Sci. \& Tech.}
      \field{title}{Dataset of head-related transfer functions measured with a circular loudspeaker array}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{35}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{159\bibrangedash 165}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1250/ast.35.159
      \endverb
      \verb{file}
      \verb Watanabe et al. - 2014 - Dataset of head-related transfer functions measure.pdf:/Users/pawel/Zotero/storage/5TRRD52B/Watanabe et al. - 2014 - Dataset of head-related transfer functions measure.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.jstage.jst.go.jp/article/ast/35/3/35_E1368/_article
      \endverb
      \verb{url}
      \verb https://www.jstage.jst.go.jp/article/ast/35/3/35_E1368/_article
      \endverb
    \endentry
    \entry{wierstorf_free_2011}{article}{}
      \name{author}{4}{}{%
        {{hash=ea78b534b437498b9114de2c16a7bc2c}{%
           family={Wierstorf},
           familyi={W\bibinitperiod},
           given={Hagen},
           giveni={H\bibinitperiod}}}%
        {{hash=d747d219bd1d7019668b2219cf5f8bb2}{%
           family={Geier},
           familyi={G\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=2ce4c604978ac9c6ebe8ba1ccfbc5115}{%
           family={Raake},
           familyi={R\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=f9f8c9d3d45c27b5bb486e79b41d175a}{%
           family={Spors},
           familyi={S\bibinitperiod},
           given={Sascha},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{08484feb6b130f3073d0342d895a30ea}
      \strng{fullhash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{bibnamehash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{authorbibnamehash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \strng{authornamehash}{08484feb6b130f3073d0342d895a30ea}
      \strng{authorfullhash}{b40cb93bcb9fd1d52abe98cce6df56fd}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A freely available collection of Head-Related Impulse Response ({HRIR}) measurements is introduced. The impulse responses were acquired in an anechoic chamber using a {KEMAR} manikin at four diﬀerent loudspeaker distances – 3 m, 2 m, 1 m and 0.5 m – reaching from the far ﬁeld to the near ﬁeld. The loudspeaker was positioned at ear height and the manikin was rotated with a high-precision stepper motor in one degree increments. Besides the raw {HRIRs} also datasets are available which have been compensated for the use with speciﬁc headphone models.}
      \field{langid}{english}
      \field{title}{A Free Database of Head-Related Impulse Response Measurements in the Horizontal Plane with Multiple Distances}
      \field{year}{2011}
      \field{dateera}{ce}
      \verb{file}
      \verb Wierstorf et al. - 2011 - A Free Database of Head-Related Impulse Response M.pdf:/Users/pawel/Zotero/storage/A66C4WXR/Wierstorf et al. - 2011 - A Free Database of Head-Related Impulse Response M.pdf:application/pdf
      \endverb
    \endentry
    \entry{woodruff_binaural_2012}{article}{}
      \name{author}{2}{}{%
        {{hash=7d546bf7dc4d1dd29f8aa15f0a06bbff}{%
           family={Woodruff},
           familyi={W\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0a1bd97b59cb3cf65dc849873adf0d25}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={DeLiang},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{fullhash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{bibnamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authorbibnamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authornamehash}{04534bf25b92e9e93d01c70d4417fda2}
      \strng{authorfullhash}{04534bf25b92e9e93d01c70d4417fda2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sound source localization from a binaural input is a challenging problem, particularly when multiple sources are active simultaneously and reverberation or background noise are present. In this work, we investigate a multi-source localization framework in which monaural source segregation is used as a mechanism to increase the robustness of azimuth estimates from a binaural input. We demonstrate performance improvement relative to binaural only methods assuming a known number of spatially stationary sources. We also propose a flexible azimuth-dependent model of binaural features that independently captures characteristics of the binaural setup and environmental conditions, allowing for adaptation to new environments or calibration to an unseen binaural setup. Results with both simulated and recorded impulse responses show that robust performance can be achieved with limited prior training.}
      \field{issn}{1558-7924}
      \field{journaltitle}{IEEE Transactions on Audio, Speech, and Language Processing}
      \field{month}{7}
      \field{note}{Conference Name: IEEE Transactions on Audio, Speech, and Language Processing}
      \field{number}{5}
      \field{title}{Binaural {Localization} of {Multiple} {Sources} in {Reverberant} and {Noisy} {Environments}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{20}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{1503\bibrangedash 1512}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/TASL.2012.2183869
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/9CW9FT7X/6129395.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/6129395
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/6129395
      \endverb
      \keyw{Adaptation models,Azimuth,Binaural sound localization,computational auditory scene analysis (CASA),Estimation,Feature extraction,monaural grouping,Noise measurement,reverberation,Reverberation,Time frequency analysis}
    \endentry
    \entry{yang_deepear_2022}{article}{}
      \name{author}{2}{}{%
        {{hash=55242d2a60270145342841e4d4238da0}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=124d6abeaddbcd28f90e637a266faed6}{%
           family={Zheng},
           familyi={Z\bibinitperiod},
           given={Yuanqing},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{fullhash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{bibnamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authorbibnamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authornamehash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \strng{authorfullhash}{28472b2a6d3ab72ea80cb6ada89a8d43}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Binaural microphones, referring to two microphones with artificial human-shaped ears, are pervasively used in humanoid robots and hearing aids improving sound quality. In many applications, it is crucial for such robots to interact with humans by finding the voice direction. However, sound source localization with binaural microphones remains challenging, especially in multi-source scenarios. Prior works utilize microphone arrays to deal with the multi-source localization problem. Extra arrays yet incur higher deployment costs and take up more space. However, human brains have evolved to locate multiple sound sources with only two ears. Inspired by this fact, we propose DeepEar, a binaural microphone-based localization system that can locate multiple sounds. To this end, we develop a neural network to mimic the acoustic signal processing pipeline of the human auditory system. Different from hand-crafted features used in prior works, DeepEar can automatically extract useful features for localization. More importantly, the trained neural networks can be extended and adapted to new environments with a minimum amount of extra training data. Experiment results show that DeepEar can substantially outperform the state-of-the-art deep learning approach, with a sound detection accuracy of 93.3\% and an azimuth estimation error of 7.4 degrees in multisource scenarios.}
      \field{journaltitle}{{IEEE} {INFOCOM} 2022 - {IEEE} {Conference} on {Computer} {Communications}}
      \field{month}{5}
      \field{note}{ISSN: 2641-9874}
      \field{shorttitle}{{DeepEar}}
      \field{title}{{DeepEar}: {Sound} {Localization} with {Binaural} {Microphones}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{year}{2022}
      \field{urldateera}{ce}
      \field{pages}{960\bibrangedash 969}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/INFOCOM48880.2022.9796850
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/Users/pawel/Zotero/storage/IN9CQI5D/9796850.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9796850
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9796850
      \endverb
      \keyw{Auditory system,Binaural localization,Deep learning,Ear,Earable computing,Feature extraction,Location awareness,Multi-source localization,Training data,Transfer learning}
    \endentry
    \entry{yu_near-field_2018}{article}{}
      \name{author}{4}{}{%
        {{hash=6d7b4f7bd9d585630f805592564163ea}{%
           family={Yu},
           familyi={Y\bibinitperiod},
           given={Guangzheng},
           giveni={G\bibinitperiod}}}%
        {{hash=de022b50859cc45f0a667828b655f5a9}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Ruixing},
           giveni={R\bibinitperiod}}}%
        {{hash=93c82128aca25c57cfb17e90d02136d5}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod}}}%
        {{hash=6a7c0aeaee82d36dc36bda3cbe6df178}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Bosun},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{e2925dc79d25212c49ec479f617e3db7}
      \strng{fullhash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{bibnamehash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{authorbibnamehash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \strng{authornamehash}{e2925dc79d25212c49ec479f617e3db7}
      \strng{authorfullhash}{d9dd6c1880d43c3bc36c73a120f975e9}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Near-ﬁeld head-related transfer functions ({HRTFs}) of human subjects are essential to those researching spatial hearing. By using a carefully designed measurement system, near-ﬁeld {HRTFs} of human subjects were measured and a database was constructed. The database includes 56 Chinese human subjects, seven source distances from 0.2 to 1.0 m, and 685 directions at each distance for each subject. In the present work, the technique of near-ﬁeld {HRTF} measurement is outlined, the performance of the measurement system is assessed and validated, and the resultant database is reported. The database can provide fundamental data for future research.}
      \field{day}{1}
      \field{issn}{0001-4966, 1520-8524}
      \field{journaltitle}{The Journal of the Acoustical Society of America}
      \field{langid}{english}
      \field{month}{3}
      \field{number}{3}
      \field{title}{Near-field head-related transfer-function measurement and database of human subjects}
      \field{urlday}{19}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{143}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{EL194\bibrangedash EL198}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1121/1.5027019
      \endverb
      \verb{file}
      \verb Yu et al. - 2018 - Near-field head-related transfer-function measurem.pdf:/Users/pawel/Zotero/storage/U66CIAPL/Yu et al. - 2018 - Near-field head-related transfer-function measurem.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://pubs.aip.org/jasa/article/143/3/EL194/609761/Near-field-head-related-transfer-function
      \endverb
      \verb{url}
      \verb https://pubs.aip.org/jasa/article/143/3/EL194/609761/Near-field-head-related-transfer-function
      \endverb
    \endentry
    \entry{zhang_finding_2018}{article}{}
      \name{author}{3}{}{%
        {{hash=ebc15088b58cb9590a0800452d89d813}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Honglei},
           giveni={H\bibinitperiod}}}%
        {{hash=88fcbfc7f3b82fa8bcc91190c133d9f0}{%
           family={Kiranyaz},
           familyi={K\bibinitperiod},
           given={Serkan},
           giveni={S\bibinitperiod}}}%
        {{hash=db18464e8dc36880c4cad237f133c939}{%
           family={Gabbouj},
           familyi={G\bibinitperiod},
           given={M.},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{390ff0787732875904593a9006891cf1}
      \strng{fullhash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{bibnamehash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{authorbibnamehash}{d33aed6d23ec7a975cf5c1279adc6076}
      \strng{authornamehash}{390ff0787732875904593a9006891cf1}
      \strng{authorfullhash}{d33aed6d23ec7a975cf5c1279adc6076}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{ArXiv}}
      \field{title}{Finding Better Topologies for Deep Convolutional Neural Networks by Evolution}
      \field{volume}{abs/1809.03242}
      \field{year}{2018}
      \field{dateera}{ce}
      \verb{file}
      \verb Zhang et al. - 2018 - Finding Better Topologies for Deep Convolutional N.pdf:/home/pawel/Zotero/storage/VEYS75L8/Zhang et al. - 2018 - Finding Better Topologies for Deep Convolutional N.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://api.semanticscholar.org/CorpusID:52182383
      \endverb
      \verb{url}
      \verb https://api.semanticscholar.org/CorpusID:52182383
      \endverb
    \endentry
    \entry{zhang_surround_2017}{article}{}
      \name{author}{4}{}{%
        {{hash=3fa0b98bdb0330cc0ea22e655fd964c2}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Wen},
           giveni={W\bibinitperiod}}}%
        {{hash=9ade3cb1e0a7e8284fca38d3e90135c2}{%
           family={Samarasinghe},
           familyi={S\bibinitperiod},
           given={Parasanga\bibnamedelima N.},
           giveni={P\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=71fbb76b73ac3e704b70533e80605c2e}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Hanchi},
           giveni={H\bibinitperiod}}}%
        {{hash=63baacfeb0128db6195531efd5b55099}{%
           family={Abhayapala},
           familyi={A\bibinitperiod},
           given={Thushara\bibnamedelima D.},
           giveni={T\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
      }
      \list{language}{1}{%
        {en}%
      }
      \strng{namehash}{6842b5fbca42689fb0276e5d0ca4a2a4}
      \strng{fullhash}{13f666b838cdf981966802da926757e8}
      \strng{bibnamehash}{13f666b838cdf981966802da926757e8}
      \strng{authorbibnamehash}{13f666b838cdf981966802da926757e8}
      \strng{authornamehash}{6842b5fbca42689fb0276e5d0ca4a2a4}
      \strng{authorfullhash}{13f666b838cdf981966802da926757e8}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this article, a systematic overview of various recording and reproduction techniques for spatial audio is presented. While binaural recording and rendering is designed to resemble the human two-ear auditory system and reproduce sounds specifically for a listener’s two ears, soundfield recording and reproduction using a large number of microphones and loudspeakers replicate an acoustic scene within a region. These two fundamentally different types of techniques are discussed in the paper. A recent popular area, multi-zone reproduction, is also briefly reviewed in the paper. The paper is concluded with a discussion of the current state of the field and open problems.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{month}{5}
      \field{note}{Number: 5 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{5}
      \field{shorttitle}{Surround by {Sound}}
      \field{title}{Surround by {Sound}: {A} {Review} of {Spatial} {Audio} {Recording} and {Reproduction}}
      \field{urlday}{7}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{7}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{532}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app7050532
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/8AJ5DLMH/Zhang et al. - 2017 - Surround by Sound A Review of Spatial Audio Recor.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/7/5/532
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/7/5/532
      \endverb
      \keyw{binaural recording,binaural rendering,multi-zone reproduction,soundfield recording,soundfield reproduction,spatial audio}
    \endentry
    \entry{zielinski_spatial_2022}{article}{}
      \name{author}{3}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{bibnamehash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{authorbibnamehash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{83edf9ee39a31cf0e68ad22ffaa30e01}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradate}{1}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The automatic localization of audio sources distributed symmetrically with respect to coronal or transverse planes using binaural signals still poses a challenging task, due to the front–back and up–down confusion effects. This paper demonstrates that the convolutional neural network ({CNN}) can be used to automatically localize music ensembles panned to the front, back, up, or down positions. The network was developed using the repository of the binaural excerpts obtained by the convolution of multi-track music recordings with the selected sets of head-related transfer functions ({HRTFs}). They were generated in such a way that a music ensemble (of circular shape in terms of its boundaries) was positioned in one of the following four locations with respect to the listener: front, back, up, and down. According to the obtained results, {CNN} identified the location of the ensembles with the average accuracy levels of 90.7\% and 71.4\% when tested under the {HRTF}-dependent and {HRTF}-independent conditions, respectively. For {HRTF}-dependent tests, the accuracy decreased monotonically with the increase in the ensemble size. A modified image occlusion sensitivity technique revealed selected frequency bands as being particularly important in terms of the localization process. These frequency bands are largely in accordance with the psychoacoustical literature.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 3 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{3}
      \field{shorttitle}{Spatial Audio Scene Characterization ({SASC})}
      \field{title}{Spatial Audio Scene Characterization ({SASC}): Automatic Localization of Front-, Back-, Up-, and Down-Positioned Music Ensembles in Binaural Recordings}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{12}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1569}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app12031569
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/HDGFITDN/Zieliński et al. - 2022 - Spatial Audio Scene Characterization (SASC) Autom.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/12/3/1569
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/12/3/1569
      \endverb
      \keyw{convolutional neural networks,deep learning,spatial audio information retrieval,spatial audio scene characterization}
    \endentry
    \entry{zielinski_automatic_2022}{article}{}
      \name{author}{4}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
        {{hash=cd0916f500f4baa33b5d6ef4873ac6a7}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Dale},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{c2290f4156a242be9065e01da047598f}
      \strng{bibnamehash}{c2290f4156a242be9065e01da047598f}
      \strng{authorbibnamehash}{c2290f4156a242be9065e01da047598f}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{c2290f4156a242be9065e01da047598f}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradate}{2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{One of the greatest challenges in the development of binaural machine audition systems is the disambiguation between front and back audio sources, particularly in complex spatial audio scenes. The goal of this work was to develop a method for discriminating between front and back located ensembles in binaural recordings of music. To this end, 22, 496 binaural excerpts, representing either front or back located ensembles, were synthesized by convolving multi-track music recordings with 74 sets of head-related transfer functions ({HRTF}). The discrimination method was developed based on the traditional approach, involving hand-engineering of features, as well as using a deep learning technique incorporating the convolutional neural network ({CNN}). According to the results obtained under {HRTF}-dependent test conditions, {CNN} showed a very high discrimination accuracy (99.4\%), slightly outperforming the traditional method. However, under the {HRTF}-independent test scenario, {CNN} performed worse than the traditional algorithm, highlighting the importance of testing the algorithms under {HRTF}-independent conditions and indicating that the traditional method might be more generalizable than {CNN}. A minimum of 20 {HRTFs} are required to achieve a satisfactory generalization performance for the traditional algorithm and 30 {HRTFs} for {CNN}. The minimum duration of audio excerpts required by both the traditional and {CNN}-based methods was assessed as 3 s. Feature importance analysis, based on a gradient attribution mapping technique, revealed that for both the traditional and the deep learning methods, a frequency band between 5 and 6 {kHz} is particularly important in terms of the discrimination between front and back ensemble locations. Linear-frequency cepstral coefficients, interaural level differences, and audio bandwidth were identified as the key descriptors facilitating the discrimination process using the traditional approach.}
      \field{day}{15}
      \field{issn}{1687-4722}
      \field{journaltitle}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{{EURASIP} Journal on Audio, Speech, and Music Processing}
      \field{title}{Automatic discrimination between front and back ensemble locations in {HRTF}-convolved binaural recordings of music}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{2022}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13636-021-00235-2
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/4G5WL8AM/Zieliński et al. - 2022 - Automatic discrimination between front and back en.pdf:application/pdf;Snapshot:/Users/pawel/Zotero/storage/SI2K4EJ6/s13636-021-00235-2.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1186/s13636-021-00235-2
      \endverb
      \verb{url}
      \verb https://doi.org/10.1186/s13636-021-00235-2
      \endverb
      \keyw{Binaural recordings,Feature engineering,{HRTF},Spatial audio information retrieval}
    \endentry
    \entry{zielinski_comparison_2020}{article}{}
      \name{author}{4}{}{%
        {{hash=37c963277bf5c21a431df68a1edd74dc}{%
           family={Zieliński},
           familyi={Z\bibinitperiod},
           given={Sławomir\bibnamedelima K.},
           giveni={S\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
        {{hash=f450cdb72b7441f0ca8c220388d2d888}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Hyunkook},
           giveni={H\bibinitperiod}}}%
        {{hash=6fd073df32a3491aff57beee7b376a5b}{%
           family={Antoniuk},
           familyi={A\bibinitperiod},
           given={Paweł},
           giveni={P\bibinitperiod}}}%
        {{hash=4646616032fe7363c0b456e94407a61f}{%
           family={Dadan},
           familyi={D\bibinitperiod},
           given={Oskar},
           giveni={O\bibinitperiod}}}%
      }
      \strng{namehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{fullhash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{bibnamehash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{authorbibnamehash}{24da28f4ac8efc816b4e64b8ba826d17}
      \strng{authornamehash}{9bb0b51d366ed079cac7896c903db004}
      \strng{authorfullhash}{24da28f4ac8efc816b4e64b8ba826d17}
      \field{extraname}{3}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The purpose of this paper is to compare the performance of human listeners against the selected machine learning algorithms in the task of the classification of spatial audio scenes in binaural recordings of music under practical conditions. The three scenes were subject to classification: (1) music ensemble (a group of musical sources) located in the front, (2) music ensemble located at the back, and (3) music ensemble distributed around a listener. In the listening test, undertaken remotely over the Internet, human listeners reached the classification accuracy of 42.5\%. For the listeners who passed the post-screening test, the accuracy was greater, approaching 60\%. The above classification task was also undertaken automatically using four machine learning algorithms: convolutional neural network, support vector machines, extreme gradient boosting framework, and logistic regression. The machine learning algorithms substantially outperformed human listeners, with the classification accuracy reaching 84\%, when tested under the binaural-room-impulse-response ({BRIR}) matched conditions. However, when the algorithms were tested under the {BRIR} mismatched scenario, the accuracy obtained by the algorithms was comparable to that exhibited by the listeners who passed the post-screening test, implying that the machine learning algorithms capability to perform in unknown electro-acoustic conditions needs to be further improved.}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 17 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{17}
      \field{title}{A Comparison of Human against Machine-Classification of Spatial Audio Scenes in Binaural Recordings of Music}
      \field{urlday}{10}
      \field{urlmonth}{6}
      \field{urlyear}{2024}
      \field{volume}{10}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{5956}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app10175956
      \endverb
      \verb{file}
      \verb Full Text PDF:/Users/pawel/Zotero/storage/SC5RHNYP/Zieliński et al. - 2020 - A Comparison of Human against Machine-Classificati.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/10/17/5956
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/10/17/5956
      \endverb
      \keyw{convolutional neural networks,deep learning,spatial audio information retrieval,spatial audio scene classification}
    \endentry
  \enddatalist
\endrefsection
\endinput

